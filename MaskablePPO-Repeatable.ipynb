{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af3f4ed2-8d77-42c5-acd6-9c9ed22e6c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import json\n",
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch as th\n",
    "\n",
    "from sb3_contrib import MaskablePPO\n",
    "from sb3_contrib.common.maskable.callbacks import MaskableEvalCallback\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv, DummyVecEnv\n",
    "from stable_baselines3.common.logger import configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8bd801b-9f17-4af9-9841-79fb1c9bd5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scheduler_env.customEnv_repeat import SchedulingEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a317f6aa-61e1-4254-b275-a6833ceb7e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# 특정 경고를 무시하도록 필터를 설정합니다.\n",
    "warnings.filterwarnings(\"ignore\", category=Warning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "107ff2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env(repeat, env_fn, test_mode=False):\n",
    "    # Create the environment\n",
    "    num_machines = 8\n",
    "    num_jobs = 10\n",
    "    max_repeats = 5\n",
    "    cost_list = [5, 1, 2, 10]\n",
    "    profit_per_time = 10\n",
    "    max_time = 50\n",
    "\n",
    "    return env_fn(\n",
    "        machine_config_path=f\"instances/Machines/v0-{str(num_machines)}x{str(num_jobs)}.json\",\n",
    "        job_config_path=f\"instances/Jobs/v0-{str(num_machines)}x{str(num_jobs)}.json\",\n",
    "        job_repeats_params=repeat,\n",
    "        render_mode=\"seaborn\",\n",
    "        cost_deadline_per_time=cost_list[0],\n",
    "        cost_hole_per_time=cost_list[1],\n",
    "        cost_processing_per_time=cost_list[2],\n",
    "        cost_makespan_per_time=cost_list[3],\n",
    "        profit_per_time=profit_per_time,\n",
    "        target_time=None,\n",
    "        test_mode=test_mode,\n",
    "        max_time=max_time,\n",
    "        num_of_types=5,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07fd4a0b-41db-4522-be3d-4d761ec9c560",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_list = [5, 2, 1, 10]\n",
    "profit_per_time = 10\n",
    "max_time = 50\n",
    "repeat = [[3, 1] for _ in range(10)]\n",
    "\n",
    "train_env = make_env(repeat, SchedulingEnv, test_mode=False)\n",
    "\n",
    "vec_env = copy.deepcopy(train_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5334ff25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Repeats\t\t\t:\t[2, 2, 2, 1, 4, 1, 1, 3, 2, 2]\n",
      "Goal reached! Final score\t:\t10.70\n",
      "Total revenue\t\t\t:\t1140.00 - 1018.00 = 122.00\n",
      "Sum of Costs\t\t\t:\t1018.00\n",
      "Cost Deadline\t\t\t:\t450.00\n",
      "Cost Hole\t\t\t:\t50.00\n",
      "Cost Processing\t\t\t:\t228.00\n",
      "Cost Makespan\t\t\t:\t290.00\n",
      "Finish Time / Target Time\t:\t2900 / 1425\n",
      "Average Tardiness:\t360.00\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# random policy\n",
    "\n",
    "obs, info = train_env.reset()\n",
    "while True:\n",
    "    action = train_env.action_space.sample()\n",
    "    obs, reward, terminated, truncated, info = train_env.step(action)\n",
    "    done = terminated or truncated\n",
    "    if done:\n",
    "        # print(\"Goal reached!\", \"final score=\", reward)\n",
    "        # print('job_deadline', info['job_deadline'])\n",
    "        # print('job_time_exceeded', info['job_time_exceeded'])\n",
    "        # print('current_repeats', info['current_repeats'])\n",
    "        # print(env1.target_time)\n",
    "        info[\"reward\"] = reward\n",
    "        info[\"env\"] = train_env\n",
    "        info[\"profit_ratio\"] = train_env.profit_per_time\n",
    "        train_env.print_result(info, detail_mode=False)\n",
    "        train_env.render()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8baf8248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./logs/tmp/1\n"
     ]
    }
   ],
   "source": [
    "log_path = \"./logs/tmp/1\"\n",
    "# set up logger\n",
    "new_logger = configure(log_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "\n",
    "eval_env = make_env(repeat, SchedulingEnv, test_mode=False)\n",
    "\n",
    "\n",
    "def env1_lambda(): return eval_env\n",
    "\n",
    "\n",
    "env_list = [env1_lambda]\n",
    "# Create the evaluation environment\n",
    "eval_env = SubprocVecEnv(env_list)\n",
    "\n",
    "# Create the EvalCallback\n",
    "eval_callback = MaskableEvalCallback(eval_env, best_model_save_path=log_path,\n",
    "                                     log_path=log_path, eval_freq=10000, n_eval_episodes=10,\n",
    "                                     deterministic=True, render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acf76220-8c02-4ac4-b4e9-0b39f25492a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "MaskableMultiInputActorCriticPolicy(\n",
      "  (features_extractor): CombinedExtractor(\n",
      "    (extractors): ModuleDict(\n",
      "      (action_masks): Flatten(start_dim=1, end_dim=-1)\n",
      "      (cost_factor_per_time): Flatten(start_dim=1, end_dim=-1)\n",
      "      (cur_estimated_tardiness_per_job): Flatten(start_dim=1, end_dim=-1)\n",
      "      (current_costs): Flatten(start_dim=1, end_dim=-1)\n",
      "      (current_repeats): Flatten(start_dim=1, end_dim=-1)\n",
      "      (earliest_start_per_operation): Flatten(start_dim=1, end_dim=-1)\n",
      "      (hole_length_per_machine): Flatten(start_dim=1, end_dim=-1)\n",
      "      (job_deadline): Flatten(start_dim=1, end_dim=-1)\n",
      "      (last_finish_time_per_machine): Flatten(start_dim=1, end_dim=-1)\n",
      "      (machine_ability): Flatten(start_dim=1, end_dim=-1)\n",
      "      (mappable_machine_count_per_type): Flatten(start_dim=1, end_dim=-1)\n",
      "      (mean_deadline_per_job): Flatten(start_dim=1, end_dim=-1)\n",
      "      (mean_estimated_tardiness_per_job): Flatten(start_dim=1, end_dim=-1)\n",
      "      (mean_operation_duration_per_job): Flatten(start_dim=1, end_dim=-1)\n",
      "      (mean_operation_duration_per_type): Flatten(start_dim=1, end_dim=-1)\n",
      "      (mean_real_tardiness_per_job): Flatten(start_dim=1, end_dim=-1)\n",
      "      (num_operations_per_job): Flatten(start_dim=1, end_dim=-1)\n",
      "      (op_duration): Flatten(start_dim=1, end_dim=-1)\n",
      "      (op_type): Flatten(start_dim=1, end_dim=-1)\n",
      "      (remaining_repeats): Flatten(start_dim=1, end_dim=-1)\n",
      "      (schedule_buffer_job_repeat): Flatten(start_dim=1, end_dim=-1)\n",
      "      (schedule_buffer_operation_index): Flatten(start_dim=1, end_dim=-1)\n",
      "      (schedule_heatmap): Flatten(start_dim=1, end_dim=-1)\n",
      "      (std_deadline_per_job): Flatten(start_dim=1, end_dim=-1)\n",
      "      (std_estimated_tardiness_per_job): Flatten(start_dim=1, end_dim=-1)\n",
      "      (std_operation_duration_per_job): Flatten(start_dim=1, end_dim=-1)\n",
      "      (std_operation_duration_per_type): Flatten(start_dim=1, end_dim=-1)\n",
      "      (std_real_tardiness_per_job): Flatten(start_dim=1, end_dim=-1)\n",
      "      (total_count_per_type): Flatten(start_dim=1, end_dim=-1)\n",
      "      (total_length_per_job): Flatten(start_dim=1, end_dim=-1)\n",
      "    )\n",
      "  )\n",
      "  (pi_features_extractor): CombinedExtractor(\n",
      "    (extractors): ModuleDict(\n",
      "      (action_masks): Flatten(start_dim=1, end_dim=-1)\n",
      "      (cost_factor_per_time): Flatten(start_dim=1, end_dim=-1)\n",
      "      (cur_estimated_tardiness_per_job): Flatten(start_dim=1, end_dim=-1)\n",
      "      (current_costs): Flatten(start_dim=1, end_dim=-1)\n",
      "      (current_repeats): Flatten(start_dim=1, end_dim=-1)\n",
      "      (earliest_start_per_operation): Flatten(start_dim=1, end_dim=-1)\n",
      "      (hole_length_per_machine): Flatten(start_dim=1, end_dim=-1)\n",
      "      (job_deadline): Flatten(start_dim=1, end_dim=-1)\n",
      "      (last_finish_time_per_machine): Flatten(start_dim=1, end_dim=-1)\n",
      "      (machine_ability): Flatten(start_dim=1, end_dim=-1)\n",
      "      (mappable_machine_count_per_type): Flatten(start_dim=1, end_dim=-1)\n",
      "      (mean_deadline_per_job): Flatten(start_dim=1, end_dim=-1)\n",
      "      (mean_estimated_tardiness_per_job): Flatten(start_dim=1, end_dim=-1)\n",
      "      (mean_operation_duration_per_job): Flatten(start_dim=1, end_dim=-1)\n",
      "      (mean_operation_duration_per_type): Flatten(start_dim=1, end_dim=-1)\n",
      "      (mean_real_tardiness_per_job): Flatten(start_dim=1, end_dim=-1)\n",
      "      (num_operations_per_job): Flatten(start_dim=1, end_dim=-1)\n",
      "      (op_duration): Flatten(start_dim=1, end_dim=-1)\n",
      "      (op_type): Flatten(start_dim=1, end_dim=-1)\n",
      "      (remaining_repeats): Flatten(start_dim=1, end_dim=-1)\n",
      "      (schedule_buffer_job_repeat): Flatten(start_dim=1, end_dim=-1)\n",
      "      (schedule_buffer_operation_index): Flatten(start_dim=1, end_dim=-1)\n",
      "      (schedule_heatmap): Flatten(start_dim=1, end_dim=-1)\n",
      "      (std_deadline_per_job): Flatten(start_dim=1, end_dim=-1)\n",
      "      (std_estimated_tardiness_per_job): Flatten(start_dim=1, end_dim=-1)\n",
      "      (std_operation_duration_per_job): Flatten(start_dim=1, end_dim=-1)\n",
      "      (std_operation_duration_per_type): Flatten(start_dim=1, end_dim=-1)\n",
      "      (std_real_tardiness_per_job): Flatten(start_dim=1, end_dim=-1)\n",
      "      (total_count_per_type): Flatten(start_dim=1, end_dim=-1)\n",
      "      (total_length_per_job): Flatten(start_dim=1, end_dim=-1)\n",
      "    )\n",
      "  )\n",
      "  (vf_features_extractor): CombinedExtractor(\n",
      "    (extractors): ModuleDict(\n",
      "      (action_masks): Flatten(start_dim=1, end_dim=-1)\n",
      "      (cost_factor_per_time): Flatten(start_dim=1, end_dim=-1)\n",
      "      (cur_estimated_tardiness_per_job): Flatten(start_dim=1, end_dim=-1)\n",
      "      (current_costs): Flatten(start_dim=1, end_dim=-1)\n",
      "      (current_repeats): Flatten(start_dim=1, end_dim=-1)\n",
      "      (earliest_start_per_operation): Flatten(start_dim=1, end_dim=-1)\n",
      "      (hole_length_per_machine): Flatten(start_dim=1, end_dim=-1)\n",
      "      (job_deadline): Flatten(start_dim=1, end_dim=-1)\n",
      "      (last_finish_time_per_machine): Flatten(start_dim=1, end_dim=-1)\n",
      "      (machine_ability): Flatten(start_dim=1, end_dim=-1)\n",
      "      (mappable_machine_count_per_type): Flatten(start_dim=1, end_dim=-1)\n",
      "      (mean_deadline_per_job): Flatten(start_dim=1, end_dim=-1)\n",
      "      (mean_estimated_tardiness_per_job): Flatten(start_dim=1, end_dim=-1)\n",
      "      (mean_operation_duration_per_job): Flatten(start_dim=1, end_dim=-1)\n",
      "      (mean_operation_duration_per_type): Flatten(start_dim=1, end_dim=-1)\n",
      "      (mean_real_tardiness_per_job): Flatten(start_dim=1, end_dim=-1)\n",
      "      (num_operations_per_job): Flatten(start_dim=1, end_dim=-1)\n",
      "      (op_duration): Flatten(start_dim=1, end_dim=-1)\n",
      "      (op_type): Flatten(start_dim=1, end_dim=-1)\n",
      "      (remaining_repeats): Flatten(start_dim=1, end_dim=-1)\n",
      "      (schedule_buffer_job_repeat): Flatten(start_dim=1, end_dim=-1)\n",
      "      (schedule_buffer_operation_index): Flatten(start_dim=1, end_dim=-1)\n",
      "      (schedule_heatmap): Flatten(start_dim=1, end_dim=-1)\n",
      "      (std_deadline_per_job): Flatten(start_dim=1, end_dim=-1)\n",
      "      (std_estimated_tardiness_per_job): Flatten(start_dim=1, end_dim=-1)\n",
      "      (std_operation_duration_per_job): Flatten(start_dim=1, end_dim=-1)\n",
      "      (std_operation_duration_per_type): Flatten(start_dim=1, end_dim=-1)\n",
      "      (std_real_tardiness_per_job): Flatten(start_dim=1, end_dim=-1)\n",
      "      (total_count_per_type): Flatten(start_dim=1, end_dim=-1)\n",
      "      (total_length_per_job): Flatten(start_dim=1, end_dim=-1)\n",
      "    )\n",
      "  )\n",
      "  (mlp_extractor): MlpExtractor(\n",
      "    (policy_net): Sequential(\n",
      "      (0): Linear(in_features=722, out_features=512, bias=True)\n",
      "      (1): Tanh()\n",
      "      (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "      (3): Tanh()\n",
      "      (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (5): Tanh()\n",
      "    )\n",
      "    (value_net): Sequential(\n",
      "      (0): Linear(in_features=722, out_features=512, bias=True)\n",
      "      (1): Tanh()\n",
      "      (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "      (3): Tanh()\n",
      "      (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (5): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (action_net): Linear(in_features=128, out_features=80, bias=True)\n",
      "  (value_net): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# params = {\n",
    "#     \"policy_kwargs\": dict(net_arch=[dict(pi=[1024, 256, 128], vf=[1024, 256, 64])]),\n",
    "#     \"gamma\": 0.99,\n",
    "#     \"clip_range\": 0.1,\n",
    "#     # \"n_steps\": 4096,\n",
    "#     \"learning_rate\": 3e-5,\n",
    "# }\n",
    "def increasing_clip_range(progress_remaining):\n",
    "    return 0.1 + 0.2 * (1 - progress_remaining)\n",
    "\n",
    "\n",
    "def exponential_schedule(progress_remaining):\n",
    "    initial_learning_rate = 0.0003\n",
    "    final_learning_rate = 0.00003\n",
    "    return np.exp(\n",
    "        np.log(final_learning_rate / initial_learning_rate) * (1 - progress_remaining)\n",
    "    ) * initial_learning_rate\n",
    "\n",
    "\n",
    "params = {\n",
    "    \"policy_kwargs\": dict(\n",
    "        # activation_fn=th.nn.LeakyReLU,\n",
    "        net_arch=dict(\n",
    "            pi=[512, 256, 128],\n",
    "            vf=[512, 256, 128]\n",
    "        ),\n",
    "    ),\n",
    "    \"learning_rate\": 5e-5,\n",
    "    \"gamma\": 0.95,\n",
    "    # \"gae_lambda\": 0.99,\n",
    "    \"n_steps\": 4096,\n",
    "    \"batch_size\": 128,\n",
    "    \"clip_range\": 0.1,\n",
    "}\n",
    "\n",
    "model = MaskablePPO('MultiInputPolicy', vec_env,\n",
    "                    policy_kwargs=params[\"policy_kwargs\"],\n",
    "                    learning_rate=params[\"learning_rate\"],\n",
    "                    gamma=params[\"gamma\"],\n",
    "                    # gae_lambda=params[\"gae_lambda\"],\n",
    "                    n_steps=params[\"n_steps\"],\n",
    "                    batch_size=params[\"batch_size\"],\n",
    "                    clip_range=params[\"clip_range\"],\n",
    "                    verbose=True\n",
    "                    )\n",
    "\n",
    "print(model.policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fc58fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.1     |\n",
      "|    ep_rew_mean     | 2.36     |\n",
      "| time/              |          |\n",
      "|    fps             | 534      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 4096     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 79           |\n",
      "|    ep_rew_mean          | 4.76         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 465          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020218275 |\n",
      "|    clip_fraction        | 0.0522       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.64        |\n",
      "|    explained_variance   | 0.0175       |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 7.35         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00667     |\n",
      "|    value_loss           | 12.7         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=19.94 +/- 3.65\n",
      "Episode length: 77.90 +/- 9.98\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 77.9         |\n",
      "|    mean_reward          | 19.9         |\n",
      "|    std_reward           | 3.65         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 10000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019027991 |\n",
      "|    clip_fraction        | 0.0382       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.64        |\n",
      "|    explained_variance   | 0.57         |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 1.08         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00589     |\n",
      "|    value_loss           | 7.62         |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78       |\n",
      "|    ep_rew_mean     | 5.76     |\n",
      "| time/              |          |\n",
      "|    fps             | 423      |\n",
      "|    iterations      | 3        |\n",
      "|    time_elapsed    | 29       |\n",
      "|    total_timesteps | 12288    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.7        |\n",
      "|    ep_rew_mean          | 10.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 425         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002171163 |\n",
      "|    clip_fraction        | 0.0573      |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.61       |\n",
      "|    explained_variance   | 0.751       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 1.46        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00705    |\n",
      "|    value_loss           | 5.47        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=-19.50 +/- 10.58\n",
      "Episode length: 88.40 +/- 6.47\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88.4         |\n",
      "|    mean_reward          | -19.5        |\n",
      "|    std_reward           | 10.6         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 20000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027398411 |\n",
      "|    clip_fraction        | 0.0713       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.62        |\n",
      "|    explained_variance   | 0.779        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 1.46         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00652     |\n",
      "|    value_loss           | 6.1          |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.1     |\n",
      "|    ep_rew_mean     | 16.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 413      |\n",
      "|    iterations      | 5        |\n",
      "|    time_elapsed    | 49       |\n",
      "|    total_timesteps | 20480    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 77.5         |\n",
      "|    ep_rew_mean          | 17.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 417          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 58           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023836386 |\n",
      "|    clip_fraction        | 0.0581       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.6         |\n",
      "|    explained_variance   | 0.803        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 2.73         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.00601     |\n",
      "|    value_loss           | 6.34         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 79.3         |\n",
      "|    ep_rew_mean          | 20.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 418          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 68           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028339005 |\n",
      "|    clip_fraction        | 0.0855       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.61        |\n",
      "|    explained_variance   | 0.82         |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 3.85         |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00809     |\n",
      "|    value_loss           | 5.49         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=-29.00 +/- 14.86\n",
      "Episode length: 77.40 +/- 7.75\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 77.4         |\n",
      "|    mean_reward          | -29          |\n",
      "|    std_reward           | 14.9         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 30000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024850504 |\n",
      "|    clip_fraction        | 0.0714       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.62        |\n",
      "|    explained_variance   | 0.874        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 1.09         |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.0073      |\n",
      "|    value_loss           | 2.75         |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 80.3     |\n",
      "|    ep_rew_mean     | 21.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 412      |\n",
      "|    iterations      | 8        |\n",
      "|    time_elapsed    | 79       |\n",
      "|    total_timesteps | 32768    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78.4         |\n",
      "|    ep_rew_mean          | 24.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 413          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 89           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022521447 |\n",
      "|    clip_fraction        | 0.0588       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.59        |\n",
      "|    explained_variance   | 0.872        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 3.38         |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00618     |\n",
      "|    value_loss           | 3.69         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=-19.81 +/- 9.10\n",
      "Episode length: 77.20 +/- 6.11\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 77.2         |\n",
      "|    mean_reward          | -19.8        |\n",
      "|    std_reward           | 9.1          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 40000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020812154 |\n",
      "|    clip_fraction        | 0.054        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.6         |\n",
      "|    explained_variance   | 0.897        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 1.23         |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.007       |\n",
      "|    value_loss           | 3.21         |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.4     |\n",
      "|    ep_rew_mean     | 23.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 410      |\n",
      "|    iterations      | 10       |\n",
      "|    time_elapsed    | 99       |\n",
      "|    total_timesteps | 40960    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 76.6         |\n",
      "|    ep_rew_mean          | 24.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 411          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 109          |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023960718 |\n",
      "|    clip_fraction        | 0.0707       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.57        |\n",
      "|    explained_variance   | 0.907        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 1.31         |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.00693     |\n",
      "|    value_loss           | 2.78         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 77.2         |\n",
      "|    ep_rew_mean          | 26.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 412          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 119          |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023745277 |\n",
      "|    clip_fraction        | 0.06         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.55        |\n",
      "|    explained_variance   | 0.898        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 1.66         |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00598     |\n",
      "|    value_loss           | 3.98         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=-27.85 +/- 11.25\n",
      "Episode length: 76.50 +/- 7.32\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 76.5         |\n",
      "|    mean_reward          | -27.8        |\n",
      "|    std_reward           | 11.3         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 50000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022544318 |\n",
      "|    clip_fraction        | 0.0513       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.53        |\n",
      "|    explained_variance   | 0.926        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.356        |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00694     |\n",
      "|    value_loss           | 2.21         |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.7     |\n",
      "|    ep_rew_mean     | 27.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 409      |\n",
      "|    iterations      | 13       |\n",
      "|    time_elapsed    | 130      |\n",
      "|    total_timesteps | 53248    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 77.7         |\n",
      "|    ep_rew_mean          | 26.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 410          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 139          |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020345068 |\n",
      "|    clip_fraction        | 0.0629       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.54        |\n",
      "|    explained_variance   | 0.941        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 1.18         |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.0071      |\n",
      "|    value_loss           | 1.74         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=-28.58 +/- 15.83\n",
      "Episode length: 82.90 +/- 10.70\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 82.9         |\n",
      "|    mean_reward          | -28.6        |\n",
      "|    std_reward           | 15.8         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 60000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019820547 |\n",
      "|    clip_fraction        | 0.0501       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.52        |\n",
      "|    explained_variance   | 0.934        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.986        |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.006       |\n",
      "|    value_loss           | 1.94         |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.4     |\n",
      "|    ep_rew_mean     | 26       |\n",
      "| time/              |          |\n",
      "|    fps             | 408      |\n",
      "|    iterations      | 15       |\n",
      "|    time_elapsed    | 150      |\n",
      "|    total_timesteps | 61440    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 79           |\n",
      "|    ep_rew_mean          | 25           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 409          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 160          |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017428268 |\n",
      "|    clip_fraction        | 0.0322       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.52        |\n",
      "|    explained_variance   | 0.944        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.162        |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.00586     |\n",
      "|    value_loss           | 1.28         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 77.2         |\n",
      "|    ep_rew_mean          | 26.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 410          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 169          |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024719266 |\n",
      "|    clip_fraction        | 0.0726       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.52        |\n",
      "|    explained_variance   | 0.948        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.134        |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.0078      |\n",
      "|    value_loss           | 1.11         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=-16.93 +/- 15.07\n",
      "Episode length: 80.50 +/- 7.75\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 80.5         |\n",
      "|    mean_reward          | -16.9        |\n",
      "|    std_reward           | 15.1         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 70000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021680114 |\n",
      "|    clip_fraction        | 0.0737       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.51        |\n",
      "|    explained_variance   | 0.956        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0686       |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00668     |\n",
      "|    value_loss           | 1.04         |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.8     |\n",
      "|    ep_rew_mean     | 27.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 408      |\n",
      "|    iterations      | 18       |\n",
      "|    time_elapsed    | 180      |\n",
      "|    total_timesteps | 73728    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 77.5         |\n",
      "|    ep_rew_mean          | 27.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 409          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 190          |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023308413 |\n",
      "|    clip_fraction        | 0.0618       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.52        |\n",
      "|    explained_variance   | 0.95         |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.779        |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00674     |\n",
      "|    value_loss           | 1.33         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=-30.55 +/- 17.02\n",
      "Episode length: 78.30 +/- 9.11\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 78.3         |\n",
      "|    mean_reward          | -30.6        |\n",
      "|    std_reward           | 17           |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 80000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022778257 |\n",
      "|    clip_fraction        | 0.0631       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.49        |\n",
      "|    explained_variance   | 0.95         |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.114        |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.00781     |\n",
      "|    value_loss           | 1.04         |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.2     |\n",
      "|    ep_rew_mean     | 25.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 407      |\n",
      "|    iterations      | 20       |\n",
      "|    time_elapsed    | 201      |\n",
      "|    total_timesteps | 81920    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 79.8         |\n",
      "|    ep_rew_mean          | 26.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 407          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 210          |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022610882 |\n",
      "|    clip_fraction        | 0.0509       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.51        |\n",
      "|    explained_variance   | 0.953        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.323        |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.00671     |\n",
      "|    value_loss           | 0.924        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=90000, episode_reward=-12.02 +/- 17.80\n",
      "Episode length: 77.00 +/- 6.75\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 77          |\n",
      "|    mean_reward          | -12         |\n",
      "|    std_reward           | 17.8        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 90000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002219014 |\n",
      "|    clip_fraction        | 0.057       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.53       |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.146       |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.00696    |\n",
      "|    value_loss           | 0.735       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.1     |\n",
      "|    ep_rew_mean     | 28.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 406      |\n",
      "|    iterations      | 22       |\n",
      "|    time_elapsed    | 221      |\n",
      "|    total_timesteps | 90112    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78.5         |\n",
      "|    ep_rew_mean          | 28.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 407          |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 231          |\n",
      "|    total_timesteps      | 94208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023787706 |\n",
      "|    clip_fraction        | 0.0657       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.52        |\n",
      "|    explained_variance   | 0.961        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.152        |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00778     |\n",
      "|    value_loss           | 1.01         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78.5         |\n",
      "|    ep_rew_mean          | 28           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 408          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 240          |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019116271 |\n",
      "|    clip_fraction        | 0.0432       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.51        |\n",
      "|    explained_variance   | 0.964        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.121        |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.00606     |\n",
      "|    value_loss           | 0.954        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=-15.05 +/- 17.76\n",
      "Episode length: 78.20 +/- 11.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 78.2         |\n",
      "|    mean_reward          | -15          |\n",
      "|    std_reward           | 17.8         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 100000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023471091 |\n",
      "|    clip_fraction        | 0.0594       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.51        |\n",
      "|    explained_variance   | 0.971        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0677       |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.00812     |\n",
      "|    value_loss           | 0.782        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.1     |\n",
      "|    ep_rew_mean     | 28.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 406      |\n",
      "|    iterations      | 25       |\n",
      "|    time_elapsed    | 251      |\n",
      "|    total_timesteps | 102400   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78.6         |\n",
      "|    ep_rew_mean          | 28.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 407          |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 261          |\n",
      "|    total_timesteps      | 106496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019119066 |\n",
      "|    clip_fraction        | 0.0592       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.51        |\n",
      "|    explained_variance   | 0.969        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.404        |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.00764     |\n",
      "|    value_loss           | 0.723        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=110000, episode_reward=-6.21 +/- 25.56\n",
      "Episode length: 73.40 +/- 9.47\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 73.4         |\n",
      "|    mean_reward          | -6.21        |\n",
      "|    std_reward           | 25.6         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 110000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020092644 |\n",
      "|    clip_fraction        | 0.0499       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.5         |\n",
      "|    explained_variance   | 0.965        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0613       |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.00742     |\n",
      "|    value_loss           | 0.701        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.5     |\n",
      "|    ep_rew_mean     | 27.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 406      |\n",
      "|    iterations      | 27       |\n",
      "|    time_elapsed    | 272      |\n",
      "|    total_timesteps | 110592   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 77.1         |\n",
      "|    ep_rew_mean          | 26.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 406          |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 281          |\n",
      "|    total_timesteps      | 114688       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019699535 |\n",
      "|    clip_fraction        | 0.0443       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.51        |\n",
      "|    explained_variance   | 0.964        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.178        |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.00718     |\n",
      "|    value_loss           | 0.67         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 77.7         |\n",
      "|    ep_rew_mean          | 26.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 407          |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 291          |\n",
      "|    total_timesteps      | 118784       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019005996 |\n",
      "|    clip_fraction        | 0.0507       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.51        |\n",
      "|    explained_variance   | 0.962        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.11         |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.00769     |\n",
      "|    value_loss           | 0.69         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=120000, episode_reward=-3.71 +/- 17.66\n",
      "Episode length: 77.50 +/- 9.73\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 77.5       |\n",
      "|    mean_reward          | -3.71      |\n",
      "|    std_reward           | 17.7       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 120000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00221739 |\n",
      "|    clip_fraction        | 0.0599     |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -2.48      |\n",
      "|    explained_variance   | 0.962      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | 0.362      |\n",
      "|    n_updates            | 290        |\n",
      "|    policy_gradient_loss | -0.00916   |\n",
      "|    value_loss           | 0.682      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.6     |\n",
      "|    ep_rew_mean     | 27.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 406      |\n",
      "|    iterations      | 30       |\n",
      "|    time_elapsed    | 302      |\n",
      "|    total_timesteps | 122880   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78.5         |\n",
      "|    ep_rew_mean          | 27.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 406          |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 312          |\n",
      "|    total_timesteps      | 126976       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024406258 |\n",
      "|    clip_fraction        | 0.0712       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.49        |\n",
      "|    explained_variance   | 0.962        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0737       |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.00831     |\n",
      "|    value_loss           | 0.778        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=130000, episode_reward=-3.68 +/- 14.75\n",
      "Episode length: 75.20 +/- 6.10\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 75.2        |\n",
      "|    mean_reward          | -3.68       |\n",
      "|    std_reward           | 14.8        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 130000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002054208 |\n",
      "|    clip_fraction        | 0.0497      |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.47       |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0817      |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.00757    |\n",
      "|    value_loss           | 0.736       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.1     |\n",
      "|    ep_rew_mean     | 28.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 406      |\n",
      "|    iterations      | 32       |\n",
      "|    time_elapsed    | 322      |\n",
      "|    total_timesteps | 131072   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 77.7         |\n",
      "|    ep_rew_mean          | 28.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 406          |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 332          |\n",
      "|    total_timesteps      | 135168       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022122015 |\n",
      "|    clip_fraction        | 0.074        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.49        |\n",
      "|    explained_variance   | 0.971        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0702       |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.00866     |\n",
      "|    value_loss           | 0.547        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78.4         |\n",
      "|    ep_rew_mean          | 27.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 406          |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 342          |\n",
      "|    total_timesteps      | 139264       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021580956 |\n",
      "|    clip_fraction        | 0.0534       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.48        |\n",
      "|    explained_variance   | 0.967        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0573       |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.00786     |\n",
      "|    value_loss           | 0.666        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=140000, episode_reward=-5.50 +/- 13.93\n",
      "Episode length: 77.20 +/- 8.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 77.2         |\n",
      "|    mean_reward          | -5.5         |\n",
      "|    std_reward           | 13.9         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 140000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018835358 |\n",
      "|    clip_fraction        | 0.0428       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.47        |\n",
      "|    explained_variance   | 0.955        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0616       |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.00846     |\n",
      "|    value_loss           | 0.537        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.1     |\n",
      "|    ep_rew_mean     | 27       |\n",
      "| time/              |          |\n",
      "|    fps             | 406      |\n",
      "|    iterations      | 35       |\n",
      "|    time_elapsed    | 353      |\n",
      "|    total_timesteps | 143360   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.8        |\n",
      "|    ep_rew_mean          | 29.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 406         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 362         |\n",
      "|    total_timesteps      | 147456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001935934 |\n",
      "|    clip_fraction        | 0.0427      |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.47       |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0689      |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.00756    |\n",
      "|    value_loss           | 0.587       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=150000, episode_reward=-20.07 +/- 16.66\n",
      "Episode length: 77.60 +/- 7.74\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 77.6         |\n",
      "|    mean_reward          | -20.1        |\n",
      "|    std_reward           | 16.7         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 150000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021370372 |\n",
      "|    clip_fraction        | 0.0535       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.48        |\n",
      "|    explained_variance   | 0.976        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.155        |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.00908     |\n",
      "|    value_loss           | 0.503        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.5     |\n",
      "|    ep_rew_mean     | 30.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 405      |\n",
      "|    iterations      | 37       |\n",
      "|    time_elapsed    | 373      |\n",
      "|    total_timesteps | 151552   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 79.2         |\n",
      "|    ep_rew_mean          | 27.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 406          |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 383          |\n",
      "|    total_timesteps      | 155648       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022852202 |\n",
      "|    clip_fraction        | 0.0696       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.47        |\n",
      "|    explained_variance   | 0.978        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0685       |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.00914     |\n",
      "|    value_loss           | 0.506        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78           |\n",
      "|    ep_rew_mean          | 27.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 406          |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 392          |\n",
      "|    total_timesteps      | 159744       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021702868 |\n",
      "|    clip_fraction        | 0.0652       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.49        |\n",
      "|    explained_variance   | 0.961        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0636       |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.00954     |\n",
      "|    value_loss           | 0.552        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=-5.06 +/- 14.22\n",
      "Episode length: 73.60 +/- 9.12\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 73.6         |\n",
      "|    mean_reward          | -5.06        |\n",
      "|    std_reward           | 14.2         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 160000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020691273 |\n",
      "|    clip_fraction        | 0.0421       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.47        |\n",
      "|    explained_variance   | 0.967        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.104        |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.00799     |\n",
      "|    value_loss           | 0.542        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.7     |\n",
      "|    ep_rew_mean     | 27.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 405      |\n",
      "|    iterations      | 40       |\n",
      "|    time_elapsed    | 403      |\n",
      "|    total_timesteps | 163840   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78.5         |\n",
      "|    ep_rew_mean          | 27.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 406          |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 413          |\n",
      "|    total_timesteps      | 167936       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022143186 |\n",
      "|    clip_fraction        | 0.0695       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.46        |\n",
      "|    explained_variance   | 0.967        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0733       |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | -0.0102      |\n",
      "|    value_loss           | 0.543        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=170000, episode_reward=-6.75 +/- 20.66\n",
      "Episode length: 77.80 +/- 10.01\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 77.8         |\n",
      "|    mean_reward          | -6.75        |\n",
      "|    std_reward           | 20.7         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 170000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022632526 |\n",
      "|    clip_fraction        | 0.0603       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.48        |\n",
      "|    explained_variance   | 0.96         |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.093        |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.00939     |\n",
      "|    value_loss           | 0.596        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.3     |\n",
      "|    ep_rew_mean     | 28.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 405      |\n",
      "|    iterations      | 42       |\n",
      "|    time_elapsed    | 424      |\n",
      "|    total_timesteps | 172032   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78           |\n",
      "|    ep_rew_mean          | 28.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 406          |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 433          |\n",
      "|    total_timesteps      | 176128       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027895495 |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.47        |\n",
      "|    explained_variance   | 0.973        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0676       |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.0108      |\n",
      "|    value_loss           | 0.466        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=180000, episode_reward=-6.64 +/- 9.84\n",
      "Episode length: 79.80 +/- 7.25\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 79.8         |\n",
      "|    mean_reward          | -6.64        |\n",
      "|    std_reward           | 9.84         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 180000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021250087 |\n",
      "|    clip_fraction        | 0.0712       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.48        |\n",
      "|    explained_variance   | 0.971        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.111        |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.00872     |\n",
      "|    value_loss           | 0.506        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.2     |\n",
      "|    ep_rew_mean     | 28.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 405      |\n",
      "|    iterations      | 44       |\n",
      "|    time_elapsed    | 444      |\n",
      "|    total_timesteps | 180224   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78.7         |\n",
      "|    ep_rew_mean          | 29.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 405          |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 454          |\n",
      "|    total_timesteps      | 184320       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025554802 |\n",
      "|    clip_fraction        | 0.0785       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.45        |\n",
      "|    explained_variance   | 0.97         |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0794       |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.0101      |\n",
      "|    value_loss           | 0.492        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78.8         |\n",
      "|    ep_rew_mean          | 30           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 406          |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 463          |\n",
      "|    total_timesteps      | 188416       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024321491 |\n",
      "|    clip_fraction        | 0.0751       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.47        |\n",
      "|    explained_variance   | 0.975        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0432       |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.00948     |\n",
      "|    value_loss           | 0.445        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=190000, episode_reward=-16.59 +/- 15.93\n",
      "Episode length: 79.30 +/- 7.38\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 79.3        |\n",
      "|    mean_reward          | -16.6       |\n",
      "|    std_reward           | 15.9        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 190000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002231161 |\n",
      "|    clip_fraction        | 0.0657      |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.48       |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0729      |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    value_loss           | 0.46        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 80.4     |\n",
      "|    ep_rew_mean     | 29.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 405      |\n",
      "|    iterations      | 47       |\n",
      "|    time_elapsed    | 474      |\n",
      "|    total_timesteps | 192512   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.6        |\n",
      "|    ep_rew_mean          | 29          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 405         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 484         |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002534938 |\n",
      "|    clip_fraction        | 0.0783      |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.49       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0532      |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    value_loss           | 0.364       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=200000, episode_reward=6.50 +/- 19.61\n",
      "Episode length: 76.00 +/- 9.27\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 76          |\n",
      "|    mean_reward          | 6.5         |\n",
      "|    std_reward           | 19.6        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 200000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002190937 |\n",
      "|    clip_fraction        | 0.0653      |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.46       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0546      |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    value_loss           | 0.482       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 76.1     |\n",
      "|    ep_rew_mean     | 30.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 405      |\n",
      "|    iterations      | 49       |\n",
      "|    time_elapsed    | 495      |\n",
      "|    total_timesteps | 200704   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 77.2         |\n",
      "|    ep_rew_mean          | 29.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 405          |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 504          |\n",
      "|    total_timesteps      | 204800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022448488 |\n",
      "|    clip_fraction        | 0.0727       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.46        |\n",
      "|    explained_variance   | 0.976        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0338       |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -0.0107      |\n",
      "|    value_loss           | 0.473        |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 79.8       |\n",
      "|    ep_rew_mean          | 29.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 406        |\n",
      "|    iterations           | 51         |\n",
      "|    time_elapsed         | 514        |\n",
      "|    total_timesteps      | 208896     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00263737 |\n",
      "|    clip_fraction        | 0.083      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -2.48      |\n",
      "|    explained_variance   | 0.972      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | 0.0849     |\n",
      "|    n_updates            | 500        |\n",
      "|    policy_gradient_loss | -0.0112    |\n",
      "|    value_loss           | 0.44       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=210000, episode_reward=-0.97 +/- 11.94\n",
      "Episode length: 75.70 +/- 7.25\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 75.7         |\n",
      "|    mean_reward          | -0.967       |\n",
      "|    std_reward           | 11.9         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 210000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024553454 |\n",
      "|    clip_fraction        | 0.0733       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.48        |\n",
      "|    explained_variance   | 0.981        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0388       |\n",
      "|    n_updates            | 510          |\n",
      "|    policy_gradient_loss | -0.00971     |\n",
      "|    value_loss           | 0.418        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.9     |\n",
      "|    ep_rew_mean     | 29.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 405      |\n",
      "|    iterations      | 52       |\n",
      "|    time_elapsed    | 525      |\n",
      "|    total_timesteps | 212992   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 77.8         |\n",
      "|    ep_rew_mean          | 29.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 405          |\n",
      "|    iterations           | 53           |\n",
      "|    time_elapsed         | 534          |\n",
      "|    total_timesteps      | 217088       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024131204 |\n",
      "|    clip_fraction        | 0.0639       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.46        |\n",
      "|    explained_variance   | 0.967        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0787       |\n",
      "|    n_updates            | 520          |\n",
      "|    policy_gradient_loss | -0.00915     |\n",
      "|    value_loss           | 0.49         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=220000, episode_reward=-2.66 +/- 20.75\n",
      "Episode length: 79.40 +/- 7.85\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 79.4         |\n",
      "|    mean_reward          | -2.66        |\n",
      "|    std_reward           | 20.7         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 220000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026423149 |\n",
      "|    clip_fraction        | 0.0795       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.43        |\n",
      "|    explained_variance   | 0.974        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0379       |\n",
      "|    n_updates            | 530          |\n",
      "|    policy_gradient_loss | -0.0112      |\n",
      "|    value_loss           | 0.462        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78       |\n",
      "|    ep_rew_mean     | 29.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 405      |\n",
      "|    iterations      | 54       |\n",
      "|    time_elapsed    | 545      |\n",
      "|    total_timesteps | 221184   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78.3         |\n",
      "|    ep_rew_mean          | 29.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 405          |\n",
      "|    iterations           | 55           |\n",
      "|    time_elapsed         | 555          |\n",
      "|    total_timesteps      | 225280       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026167557 |\n",
      "|    clip_fraction        | 0.0843       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.43        |\n",
      "|    explained_variance   | 0.976        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.264        |\n",
      "|    n_updates            | 540          |\n",
      "|    policy_gradient_loss | -0.0109      |\n",
      "|    value_loss           | 0.439        |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 78.9       |\n",
      "|    ep_rew_mean          | 28.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 405        |\n",
      "|    iterations           | 56         |\n",
      "|    time_elapsed         | 565        |\n",
      "|    total_timesteps      | 229376     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00260798 |\n",
      "|    clip_fraction        | 0.0964     |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -2.43      |\n",
      "|    explained_variance   | 0.976      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | 0.0639     |\n",
      "|    n_updates            | 550        |\n",
      "|    policy_gradient_loss | -0.0113    |\n",
      "|    value_loss           | 0.406      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=230000, episode_reward=5.52 +/- 22.29\n",
      "Episode length: 76.50 +/- 9.54\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 76.5         |\n",
      "|    mean_reward          | 5.52         |\n",
      "|    std_reward           | 22.3         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 230000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022510518 |\n",
      "|    clip_fraction        | 0.0748       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.42        |\n",
      "|    explained_variance   | 0.971        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.025        |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | -0.0102      |\n",
      "|    value_loss           | 0.433        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.4     |\n",
      "|    ep_rew_mean     | 29.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 405      |\n",
      "|    iterations      | 57       |\n",
      "|    time_elapsed    | 576      |\n",
      "|    total_timesteps | 233472   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78.1         |\n",
      "|    ep_rew_mean          | 29.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 405          |\n",
      "|    iterations           | 58           |\n",
      "|    time_elapsed         | 585          |\n",
      "|    total_timesteps      | 237568       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027474104 |\n",
      "|    clip_fraction        | 0.0902       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.41        |\n",
      "|    explained_variance   | 0.975        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0499       |\n",
      "|    n_updates            | 570          |\n",
      "|    policy_gradient_loss | -0.0119      |\n",
      "|    value_loss           | 0.404        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=240000, episode_reward=-9.85 +/- 13.20\n",
      "Episode length: 77.80 +/- 6.21\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 77.8         |\n",
      "|    mean_reward          | -9.85        |\n",
      "|    std_reward           | 13.2         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 240000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024613463 |\n",
      "|    clip_fraction        | 0.0952       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.43        |\n",
      "|    explained_variance   | 0.98         |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0274       |\n",
      "|    n_updates            | 580          |\n",
      "|    policy_gradient_loss | -0.012       |\n",
      "|    value_loss           | 0.356        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78       |\n",
      "|    ep_rew_mean     | 29.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 405      |\n",
      "|    iterations      | 59       |\n",
      "|    time_elapsed    | 596      |\n",
      "|    total_timesteps | 241664   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 79.1         |\n",
      "|    ep_rew_mean          | 29.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 405          |\n",
      "|    iterations           | 60           |\n",
      "|    time_elapsed         | 606          |\n",
      "|    total_timesteps      | 245760       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027049829 |\n",
      "|    clip_fraction        | 0.081        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.42        |\n",
      "|    explained_variance   | 0.973        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.128        |\n",
      "|    n_updates            | 590          |\n",
      "|    policy_gradient_loss | -0.0118      |\n",
      "|    value_loss           | 0.451        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.8        |\n",
      "|    ep_rew_mean          | 29.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 405         |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 616         |\n",
      "|    total_timesteps      | 249856      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002163325 |\n",
      "|    clip_fraction        | 0.0688      |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.4        |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0287      |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    value_loss           | 0.424       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=250000, episode_reward=23.40 +/- 9.78\n",
      "Episode length: 70.90 +/- 8.29\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 70.9         |\n",
      "|    mean_reward          | 23.4         |\n",
      "|    std_reward           | 9.78         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 250000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023556256 |\n",
      "|    clip_fraction        | 0.0832       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.43        |\n",
      "|    explained_variance   | 0.978        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0448       |\n",
      "|    n_updates            | 610          |\n",
      "|    policy_gradient_loss | -0.0127      |\n",
      "|    value_loss           | 0.377        |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.9     |\n",
      "|    ep_rew_mean     | 29.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 405      |\n",
      "|    iterations      | 62       |\n",
      "|    time_elapsed    | 626      |\n",
      "|    total_timesteps | 253952   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78.2         |\n",
      "|    ep_rew_mean          | 30.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 405          |\n",
      "|    iterations           | 63           |\n",
      "|    time_elapsed         | 636          |\n",
      "|    total_timesteps      | 258048       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030638766 |\n",
      "|    clip_fraction        | 0.0962       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.4         |\n",
      "|    explained_variance   | 0.974        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0295       |\n",
      "|    n_updates            | 620          |\n",
      "|    policy_gradient_loss | -0.0105      |\n",
      "|    value_loss           | 0.382        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=260000, episode_reward=21.75 +/- 15.61\n",
      "Episode length: 77.20 +/- 7.77\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 77.2         |\n",
      "|    mean_reward          | 21.7         |\n",
      "|    std_reward           | 15.6         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 260000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029934072 |\n",
      "|    clip_fraction        | 0.101        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.39        |\n",
      "|    explained_variance   | 0.977        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0559       |\n",
      "|    n_updates            | 630          |\n",
      "|    policy_gradient_loss | -0.0129      |\n",
      "|    value_loss           | 0.396        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.4     |\n",
      "|    ep_rew_mean     | 31.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 405      |\n",
      "|    iterations      | 64       |\n",
      "|    time_elapsed    | 647      |\n",
      "|    total_timesteps | 262144   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.8        |\n",
      "|    ep_rew_mean          | 30.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 405         |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 656         |\n",
      "|    total_timesteps      | 266240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002597657 |\n",
      "|    clip_fraction        | 0.0957      |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.39       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0249      |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    value_loss           | 0.387       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=270000, episode_reward=22.10 +/- 16.20\n",
      "Episode length: 75.70 +/- 10.72\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 75.7         |\n",
      "|    mean_reward          | 22.1         |\n",
      "|    std_reward           | 16.2         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 270000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026773992 |\n",
      "|    clip_fraction        | 0.0851       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.41        |\n",
      "|    explained_variance   | 0.979        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0484       |\n",
      "|    n_updates            | 650          |\n",
      "|    policy_gradient_loss | -0.0123      |\n",
      "|    value_loss           | 0.386        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.3     |\n",
      "|    ep_rew_mean     | 30.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 66       |\n",
      "|    time_elapsed    | 667      |\n",
      "|    total_timesteps | 270336   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 77.4         |\n",
      "|    ep_rew_mean          | 30.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 405          |\n",
      "|    iterations           | 67           |\n",
      "|    time_elapsed         | 677          |\n",
      "|    total_timesteps      | 274432       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027793432 |\n",
      "|    clip_fraction        | 0.0911       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.36        |\n",
      "|    explained_variance   | 0.975        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0537       |\n",
      "|    n_updates            | 660          |\n",
      "|    policy_gradient_loss | -0.0135      |\n",
      "|    value_loss           | 0.347        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78.1         |\n",
      "|    ep_rew_mean          | 29.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 405          |\n",
      "|    iterations           | 68           |\n",
      "|    time_elapsed         | 686          |\n",
      "|    total_timesteps      | 278528       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025651557 |\n",
      "|    clip_fraction        | 0.0918       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.38        |\n",
      "|    explained_variance   | 0.982        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.05         |\n",
      "|    n_updates            | 670          |\n",
      "|    policy_gradient_loss | -0.0125      |\n",
      "|    value_loss           | 0.368        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=280000, episode_reward=29.21 +/- 11.58\n",
      "Episode length: 77.30 +/- 13.06\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 77.3         |\n",
      "|    mean_reward          | 29.2         |\n",
      "|    std_reward           | 11.6         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 280000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025098338 |\n",
      "|    clip_fraction        | 0.0698       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.41        |\n",
      "|    explained_variance   | 0.973        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.129        |\n",
      "|    n_updates            | 680          |\n",
      "|    policy_gradient_loss | -0.0114      |\n",
      "|    value_loss           | 0.377        |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.4     |\n",
      "|    ep_rew_mean     | 29.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 405      |\n",
      "|    iterations      | 69       |\n",
      "|    time_elapsed    | 697      |\n",
      "|    total_timesteps | 282624   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 77.5         |\n",
      "|    ep_rew_mean          | 30.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 405          |\n",
      "|    iterations           | 70           |\n",
      "|    time_elapsed         | 707          |\n",
      "|    total_timesteps      | 286720       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031123534 |\n",
      "|    clip_fraction        | 0.109        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.39        |\n",
      "|    explained_variance   | 0.976        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0176       |\n",
      "|    n_updates            | 690          |\n",
      "|    policy_gradient_loss | -0.0124      |\n",
      "|    value_loss           | 0.388        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=290000, episode_reward=17.15 +/- 13.76\n",
      "Episode length: 76.20 +/- 4.98\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 76.2        |\n",
      "|    mean_reward          | 17.2        |\n",
      "|    std_reward           | 13.8        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 290000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003039977 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.38       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0437      |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    value_loss           | 0.325       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.3     |\n",
      "|    ep_rew_mean     | 31.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 71       |\n",
      "|    time_elapsed    | 718      |\n",
      "|    total_timesteps | 290816   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 77.7       |\n",
      "|    ep_rew_mean          | 31.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 405        |\n",
      "|    iterations           | 72         |\n",
      "|    time_elapsed         | 727        |\n",
      "|    total_timesteps      | 294912     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00278551 |\n",
      "|    clip_fraction        | 0.0908     |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -2.36      |\n",
      "|    explained_variance   | 0.972      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | 0.0464     |\n",
      "|    n_updates            | 710        |\n",
      "|    policy_gradient_loss | -0.0115    |\n",
      "|    value_loss           | 0.45       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78.6         |\n",
      "|    ep_rew_mean          | 32           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 405          |\n",
      "|    iterations           | 73           |\n",
      "|    time_elapsed         | 737          |\n",
      "|    total_timesteps      | 299008       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028486983 |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.37        |\n",
      "|    explained_variance   | 0.983        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0298       |\n",
      "|    n_updates            | 720          |\n",
      "|    policy_gradient_loss | -0.0117      |\n",
      "|    value_loss           | 0.35         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=300000, episode_reward=23.49 +/- 14.46\n",
      "Episode length: 79.40 +/- 11.02\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 79.4         |\n",
      "|    mean_reward          | 23.5         |\n",
      "|    std_reward           | 14.5         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 300000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028245633 |\n",
      "|    clip_fraction        | 0.101        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.37        |\n",
      "|    explained_variance   | 0.984        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0297       |\n",
      "|    n_updates            | 730          |\n",
      "|    policy_gradient_loss | -0.0121      |\n",
      "|    value_loss           | 0.318        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.5     |\n",
      "|    ep_rew_mean     | 31.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 405      |\n",
      "|    iterations      | 74       |\n",
      "|    time_elapsed    | 748      |\n",
      "|    total_timesteps | 303104   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.3        |\n",
      "|    ep_rew_mean          | 30.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 405         |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 758         |\n",
      "|    total_timesteps      | 307200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003471036 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.35       |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0368      |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    value_loss           | 0.309       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=310000, episode_reward=21.74 +/- 10.16\n",
      "Episode length: 80.70 +/- 7.79\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 80.7         |\n",
      "|    mean_reward          | 21.7         |\n",
      "|    std_reward           | 10.2         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 310000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031133713 |\n",
      "|    clip_fraction        | 0.113        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.33        |\n",
      "|    explained_variance   | 0.98         |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0276       |\n",
      "|    n_updates            | 750          |\n",
      "|    policy_gradient_loss | -0.0136      |\n",
      "|    value_loss           | 0.313        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.6     |\n",
      "|    ep_rew_mean     | 31       |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 76       |\n",
      "|    time_elapsed    | 769      |\n",
      "|    total_timesteps | 311296   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78           |\n",
      "|    ep_rew_mean          | 32.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 405          |\n",
      "|    iterations           | 77           |\n",
      "|    time_elapsed         | 778          |\n",
      "|    total_timesteps      | 315392       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027435184 |\n",
      "|    clip_fraction        | 0.0887       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.34        |\n",
      "|    explained_variance   | 0.977        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0281       |\n",
      "|    n_updates            | 760          |\n",
      "|    policy_gradient_loss | -0.011       |\n",
      "|    value_loss           | 0.427        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78           |\n",
      "|    ep_rew_mean          | 30.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 405          |\n",
      "|    iterations           | 78           |\n",
      "|    time_elapsed         | 788          |\n",
      "|    total_timesteps      | 319488       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038266608 |\n",
      "|    clip_fraction        | 0.12         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.36        |\n",
      "|    explained_variance   | 0.983        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0427       |\n",
      "|    n_updates            | 770          |\n",
      "|    policy_gradient_loss | -0.0128      |\n",
      "|    value_loss           | 0.345        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=320000, episode_reward=24.59 +/- 25.44\n",
      "Episode length: 76.50 +/- 8.87\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 76.5         |\n",
      "|    mean_reward          | 24.6         |\n",
      "|    std_reward           | 25.4         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 320000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031977426 |\n",
      "|    clip_fraction        | 0.106        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.36        |\n",
      "|    explained_variance   | 0.979        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.307        |\n",
      "|    n_updates            | 780          |\n",
      "|    policy_gradient_loss | -0.0128      |\n",
      "|    value_loss           | 0.378        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.3     |\n",
      "|    ep_rew_mean     | 31.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 79       |\n",
      "|    time_elapsed    | 799      |\n",
      "|    total_timesteps | 323584   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 77.2         |\n",
      "|    ep_rew_mean          | 31.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 405          |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 808          |\n",
      "|    total_timesteps      | 327680       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031448733 |\n",
      "|    clip_fraction        | 0.103        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.32        |\n",
      "|    explained_variance   | 0.983        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0408       |\n",
      "|    n_updates            | 790          |\n",
      "|    policy_gradient_loss | -0.0129      |\n",
      "|    value_loss           | 0.297        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=330000, episode_reward=28.95 +/- 7.44\n",
      "Episode length: 75.50 +/- 10.98\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 75.5         |\n",
      "|    mean_reward          | 28.9         |\n",
      "|    std_reward           | 7.44         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 330000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033330307 |\n",
      "|    clip_fraction        | 0.111        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.31        |\n",
      "|    explained_variance   | 0.981        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0345       |\n",
      "|    n_updates            | 800          |\n",
      "|    policy_gradient_loss | -0.0132      |\n",
      "|    value_loss           | 0.341        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 76.6     |\n",
      "|    ep_rew_mean     | 32.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 81       |\n",
      "|    time_elapsed    | 819      |\n",
      "|    total_timesteps | 331776   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.2        |\n",
      "|    ep_rew_mean          | 32.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 405         |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 829         |\n",
      "|    total_timesteps      | 335872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002987478 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.29       |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.18        |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    value_loss           | 0.415       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 77.5         |\n",
      "|    ep_rew_mean          | 32.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 405          |\n",
      "|    iterations           | 83           |\n",
      "|    time_elapsed         | 838          |\n",
      "|    total_timesteps      | 339968       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029594065 |\n",
      "|    clip_fraction        | 0.0941       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.3         |\n",
      "|    explained_variance   | 0.982        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0239       |\n",
      "|    n_updates            | 820          |\n",
      "|    policy_gradient_loss | -0.0119      |\n",
      "|    value_loss           | 0.351        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=340000, episode_reward=24.36 +/- 12.58\n",
      "Episode length: 82.00 +/- 11.21\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 82           |\n",
      "|    mean_reward          | 24.4         |\n",
      "|    std_reward           | 12.6         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 340000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033538626 |\n",
      "|    clip_fraction        | 0.115        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.3         |\n",
      "|    explained_variance   | 0.983        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0433       |\n",
      "|    n_updates            | 830          |\n",
      "|    policy_gradient_loss | -0.0129      |\n",
      "|    value_loss           | 0.319        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.4     |\n",
      "|    ep_rew_mean     | 31.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 405      |\n",
      "|    iterations      | 84       |\n",
      "|    time_elapsed    | 849      |\n",
      "|    total_timesteps | 344064   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78.7         |\n",
      "|    ep_rew_mean          | 31.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 405          |\n",
      "|    iterations           | 85           |\n",
      "|    time_elapsed         | 859          |\n",
      "|    total_timesteps      | 348160       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031813786 |\n",
      "|    clip_fraction        | 0.125        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.31        |\n",
      "|    explained_variance   | 0.984        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0374       |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.0139      |\n",
      "|    value_loss           | 0.292        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=350000, episode_reward=31.76 +/- 5.25\n",
      "Episode length: 71.20 +/- 5.91\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 71.2         |\n",
      "|    mean_reward          | 31.8         |\n",
      "|    std_reward           | 5.25         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 350000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027295777 |\n",
      "|    clip_fraction        | 0.0978       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.3         |\n",
      "|    explained_variance   | 0.982        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0242       |\n",
      "|    n_updates            | 850          |\n",
      "|    policy_gradient_loss | -0.0126      |\n",
      "|    value_loss           | 0.351        |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.5     |\n",
      "|    ep_rew_mean     | 31.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 86       |\n",
      "|    time_elapsed    | 869      |\n",
      "|    total_timesteps | 352256   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78.9         |\n",
      "|    ep_rew_mean          | 32.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 405          |\n",
      "|    iterations           | 87           |\n",
      "|    time_elapsed         | 879          |\n",
      "|    total_timesteps      | 356352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034088297 |\n",
      "|    clip_fraction        | 0.113        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.3         |\n",
      "|    explained_variance   | 0.979        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0693       |\n",
      "|    n_updates            | 860          |\n",
      "|    policy_gradient_loss | -0.0137      |\n",
      "|    value_loss           | 0.327        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=360000, episode_reward=33.78 +/- 8.23\n",
      "Episode length: 75.00 +/- 9.21\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 75           |\n",
      "|    mean_reward          | 33.8         |\n",
      "|    std_reward           | 8.23         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 360000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031939163 |\n",
      "|    clip_fraction        | 0.11         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.29        |\n",
      "|    explained_variance   | 0.982        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0253       |\n",
      "|    n_updates            | 870          |\n",
      "|    policy_gradient_loss | -0.0122      |\n",
      "|    value_loss           | 0.373        |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.2     |\n",
      "|    ep_rew_mean     | 32.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 88       |\n",
      "|    time_elapsed    | 890      |\n",
      "|    total_timesteps | 360448   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.7        |\n",
      "|    ep_rew_mean          | 34          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 405         |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 899         |\n",
      "|    total_timesteps      | 364544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003311452 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.29       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0276      |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 0.351       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.7        |\n",
      "|    ep_rew_mean          | 34.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 405         |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 909         |\n",
      "|    total_timesteps      | 368640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003380097 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.25       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0398      |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    value_loss           | 0.303       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=370000, episode_reward=28.93 +/- 6.67\n",
      "Episode length: 75.10 +/- 9.26\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 75.1         |\n",
      "|    mean_reward          | 28.9         |\n",
      "|    std_reward           | 6.67         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 370000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034210347 |\n",
      "|    clip_fraction        | 0.126        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.27        |\n",
      "|    explained_variance   | 0.98         |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0472       |\n",
      "|    n_updates            | 900          |\n",
      "|    policy_gradient_loss | -0.0145      |\n",
      "|    value_loss           | 0.387        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78       |\n",
      "|    ep_rew_mean     | 32       |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 91       |\n",
      "|    time_elapsed    | 920      |\n",
      "|    total_timesteps | 372736   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78.2         |\n",
      "|    ep_rew_mean          | 32.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 405          |\n",
      "|    iterations           | 92           |\n",
      "|    time_elapsed         | 930          |\n",
      "|    total_timesteps      | 376832       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031959745 |\n",
      "|    clip_fraction        | 0.101        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.29        |\n",
      "|    explained_variance   | 0.97         |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.036        |\n",
      "|    n_updates            | 910          |\n",
      "|    policy_gradient_loss | -0.0135      |\n",
      "|    value_loss           | 0.415        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=380000, episode_reward=31.61 +/- 8.74\n",
      "Episode length: 73.90 +/- 11.93\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 73.9         |\n",
      "|    mean_reward          | 31.6         |\n",
      "|    std_reward           | 8.74         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 380000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037736222 |\n",
      "|    clip_fraction        | 0.156        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.28        |\n",
      "|    explained_variance   | 0.988        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0383       |\n",
      "|    n_updates            | 920          |\n",
      "|    policy_gradient_loss | -0.0142      |\n",
      "|    value_loss           | 0.288        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.2     |\n",
      "|    ep_rew_mean     | 32.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 93       |\n",
      "|    time_elapsed    | 940      |\n",
      "|    total_timesteps | 380928   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78.1         |\n",
      "|    ep_rew_mean          | 33.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 405          |\n",
      "|    iterations           | 94           |\n",
      "|    time_elapsed         | 950          |\n",
      "|    total_timesteps      | 385024       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039016958 |\n",
      "|    clip_fraction        | 0.142        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.28        |\n",
      "|    explained_variance   | 0.98         |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0346       |\n",
      "|    n_updates            | 930          |\n",
      "|    policy_gradient_loss | -0.0147      |\n",
      "|    value_loss           | 0.316        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 79.6         |\n",
      "|    ep_rew_mean          | 33.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 405          |\n",
      "|    iterations           | 95           |\n",
      "|    time_elapsed         | 960          |\n",
      "|    total_timesteps      | 389120       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033613662 |\n",
      "|    clip_fraction        | 0.115        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.23        |\n",
      "|    explained_variance   | 0.986        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0376       |\n",
      "|    n_updates            | 940          |\n",
      "|    policy_gradient_loss | -0.0131      |\n",
      "|    value_loss           | 0.32         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=390000, episode_reward=28.93 +/- 8.36\n",
      "Episode length: 78.60 +/- 12.07\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 78.6        |\n",
      "|    mean_reward          | 28.9        |\n",
      "|    std_reward           | 8.36        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 390000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003453778 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.25       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0235      |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    value_loss           | 0.336       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 80       |\n",
      "|    ep_rew_mean     | 33.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 96       |\n",
      "|    time_elapsed    | 971      |\n",
      "|    total_timesteps | 393216   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 77.7         |\n",
      "|    ep_rew_mean          | 34.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 405          |\n",
      "|    iterations           | 97           |\n",
      "|    time_elapsed         | 980          |\n",
      "|    total_timesteps      | 397312       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038795841 |\n",
      "|    clip_fraction        | 0.132        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.22        |\n",
      "|    explained_variance   | 0.987        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0206       |\n",
      "|    n_updates            | 960          |\n",
      "|    policy_gradient_loss | -0.0122      |\n",
      "|    value_loss           | 0.291        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=400000, episode_reward=29.64 +/- 6.57\n",
      "Episode length: 76.60 +/- 9.56\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 76.6         |\n",
      "|    mean_reward          | 29.6         |\n",
      "|    std_reward           | 6.57         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 400000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038327281 |\n",
      "|    clip_fraction        | 0.142        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.24        |\n",
      "|    explained_variance   | 0.984        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0513       |\n",
      "|    n_updates            | 970          |\n",
      "|    policy_gradient_loss | -0.0146      |\n",
      "|    value_loss           | 0.304        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.9     |\n",
      "|    ep_rew_mean     | 34.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 98       |\n",
      "|    time_elapsed    | 991      |\n",
      "|    total_timesteps | 401408   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 77.4         |\n",
      "|    ep_rew_mean          | 34.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 405          |\n",
      "|    iterations           | 99           |\n",
      "|    time_elapsed         | 1001         |\n",
      "|    total_timesteps      | 405504       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037733086 |\n",
      "|    clip_fraction        | 0.136        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.24        |\n",
      "|    explained_variance   | 0.984        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.027        |\n",
      "|    n_updates            | 980          |\n",
      "|    policy_gradient_loss | -0.0146      |\n",
      "|    value_loss           | 0.322        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78.5         |\n",
      "|    ep_rew_mean          | 33           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 405          |\n",
      "|    iterations           | 100          |\n",
      "|    time_elapsed         | 1011         |\n",
      "|    total_timesteps      | 409600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048849573 |\n",
      "|    clip_fraction        | 0.173        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.25        |\n",
      "|    explained_variance   | 0.982        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0123       |\n",
      "|    n_updates            | 990          |\n",
      "|    policy_gradient_loss | -0.0139      |\n",
      "|    value_loss           | 0.304        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=410000, episode_reward=30.92 +/- 7.31\n",
      "Episode length: 76.30 +/- 12.71\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 76.3         |\n",
      "|    mean_reward          | 30.9         |\n",
      "|    std_reward           | 7.31         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 410000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033296882 |\n",
      "|    clip_fraction        | 0.134        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.25        |\n",
      "|    explained_variance   | 0.981        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0395       |\n",
      "|    n_updates            | 1000         |\n",
      "|    policy_gradient_loss | -0.0131      |\n",
      "|    value_loss           | 0.307        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.5     |\n",
      "|    ep_rew_mean     | 31.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 101      |\n",
      "|    time_elapsed    | 1021     |\n",
      "|    total_timesteps | 413696   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78.5         |\n",
      "|    ep_rew_mean          | 33           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 405          |\n",
      "|    iterations           | 102          |\n",
      "|    time_elapsed         | 1031         |\n",
      "|    total_timesteps      | 417792       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037084261 |\n",
      "|    clip_fraction        | 0.123        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.3         |\n",
      "|    explained_variance   | 0.978        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0322       |\n",
      "|    n_updates            | 1010         |\n",
      "|    policy_gradient_loss | -0.0146      |\n",
      "|    value_loss           | 0.39         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=420000, episode_reward=24.45 +/- 8.91\n",
      "Episode length: 82.50 +/- 11.21\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 82.5       |\n",
      "|    mean_reward          | 24.5       |\n",
      "|    std_reward           | 8.91       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 420000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00397096 |\n",
      "|    clip_fraction        | 0.125      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -2.26      |\n",
      "|    explained_variance   | 0.979      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | 0.0571     |\n",
      "|    n_updates            | 1020       |\n",
      "|    policy_gradient_loss | -0.0134    |\n",
      "|    value_loss           | 0.393      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.8     |\n",
      "|    ep_rew_mean     | 33.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 103      |\n",
      "|    time_elapsed    | 1042     |\n",
      "|    total_timesteps | 421888   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 77.7         |\n",
      "|    ep_rew_mean          | 34.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 104          |\n",
      "|    time_elapsed         | 1051         |\n",
      "|    total_timesteps      | 425984       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035094253 |\n",
      "|    clip_fraction        | 0.129        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.25        |\n",
      "|    explained_variance   | 0.985        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0116       |\n",
      "|    n_updates            | 1030         |\n",
      "|    policy_gradient_loss | -0.0151      |\n",
      "|    value_loss           | 0.299        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=430000, episode_reward=24.48 +/- 8.56\n",
      "Episode length: 78.30 +/- 8.15\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 78.3        |\n",
      "|    mean_reward          | 24.5        |\n",
      "|    std_reward           | 8.56        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 430000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004587137 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.22       |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0338      |\n",
      "|    n_updates            | 1040        |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 0.274       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.9     |\n",
      "|    ep_rew_mean     | 34.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 105      |\n",
      "|    time_elapsed    | 1062     |\n",
      "|    total_timesteps | 430080   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 79.8         |\n",
      "|    ep_rew_mean          | 33.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 106          |\n",
      "|    time_elapsed         | 1072         |\n",
      "|    total_timesteps      | 434176       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041358406 |\n",
      "|    clip_fraction        | 0.143        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.27        |\n",
      "|    explained_variance   | 0.985        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0163       |\n",
      "|    n_updates            | 1050         |\n",
      "|    policy_gradient_loss | -0.0156      |\n",
      "|    value_loss           | 0.265        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 79.6         |\n",
      "|    ep_rew_mean          | 34.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 107          |\n",
      "|    time_elapsed         | 1082         |\n",
      "|    total_timesteps      | 438272       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038798326 |\n",
      "|    clip_fraction        | 0.151        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.24        |\n",
      "|    explained_variance   | 0.985        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0104       |\n",
      "|    n_updates            | 1060         |\n",
      "|    policy_gradient_loss | -0.0139      |\n",
      "|    value_loss           | 0.28         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=440000, episode_reward=30.47 +/- 5.88\n",
      "Episode length: 78.50 +/- 9.51\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 78.5         |\n",
      "|    mean_reward          | 30.5         |\n",
      "|    std_reward           | 5.88         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 440000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034955447 |\n",
      "|    clip_fraction        | 0.131        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.24        |\n",
      "|    explained_variance   | 0.978        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0332       |\n",
      "|    n_updates            | 1070         |\n",
      "|    policy_gradient_loss | -0.0131      |\n",
      "|    value_loss           | 0.399        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.8     |\n",
      "|    ep_rew_mean     | 33.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 108      |\n",
      "|    time_elapsed    | 1093     |\n",
      "|    total_timesteps | 442368   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.6        |\n",
      "|    ep_rew_mean          | 32.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 109         |\n",
      "|    time_elapsed         | 1102        |\n",
      "|    total_timesteps      | 446464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003531156 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.27       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.05        |\n",
      "|    n_updates            | 1080        |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    value_loss           | 0.413       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=450000, episode_reward=24.17 +/- 6.44\n",
      "Episode length: 86.70 +/- 6.45\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 86.7         |\n",
      "|    mean_reward          | 24.2         |\n",
      "|    std_reward           | 6.44         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 450000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041744234 |\n",
      "|    clip_fraction        | 0.139        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.26        |\n",
      "|    explained_variance   | 0.981        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0449       |\n",
      "|    n_updates            | 1090         |\n",
      "|    policy_gradient_loss | -0.015       |\n",
      "|    value_loss           | 0.332        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.9     |\n",
      "|    ep_rew_mean     | 33.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 110      |\n",
      "|    time_elapsed    | 1113     |\n",
      "|    total_timesteps | 450560   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 77.5         |\n",
      "|    ep_rew_mean          | 34.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 111          |\n",
      "|    time_elapsed         | 1123         |\n",
      "|    total_timesteps      | 454656       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049425103 |\n",
      "|    clip_fraction        | 0.172        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.26        |\n",
      "|    explained_variance   | 0.988        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0248       |\n",
      "|    n_updates            | 1100         |\n",
      "|    policy_gradient_loss | -0.0161      |\n",
      "|    value_loss           | 0.248        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 77.1         |\n",
      "|    ep_rew_mean          | 34.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 112          |\n",
      "|    time_elapsed         | 1132         |\n",
      "|    total_timesteps      | 458752       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040288176 |\n",
      "|    clip_fraction        | 0.166        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.25        |\n",
      "|    explained_variance   | 0.985        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0317       |\n",
      "|    n_updates            | 1110         |\n",
      "|    policy_gradient_loss | -0.0143      |\n",
      "|    value_loss           | 0.289        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=460000, episode_reward=26.95 +/- 8.50\n",
      "Episode length: 80.30 +/- 10.98\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 80.3        |\n",
      "|    mean_reward          | 27          |\n",
      "|    std_reward           | 8.5         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 460000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004062336 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.26       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0177      |\n",
      "|    n_updates            | 1120        |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    value_loss           | 0.293       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.4     |\n",
      "|    ep_rew_mean     | 34.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 113      |\n",
      "|    time_elapsed    | 1143     |\n",
      "|    total_timesteps | 462848   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78.1         |\n",
      "|    ep_rew_mean          | 35.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 114          |\n",
      "|    time_elapsed         | 1153         |\n",
      "|    total_timesteps      | 466944       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041065514 |\n",
      "|    clip_fraction        | 0.124        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.27        |\n",
      "|    explained_variance   | 0.979        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0389       |\n",
      "|    n_updates            | 1130         |\n",
      "|    policy_gradient_loss | -0.0141      |\n",
      "|    value_loss           | 0.347        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=470000, episode_reward=28.13 +/- 6.89\n",
      "Episode length: 80.80 +/- 11.80\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 80.8         |\n",
      "|    mean_reward          | 28.1         |\n",
      "|    std_reward           | 6.89         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 470000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042640194 |\n",
      "|    clip_fraction        | 0.149        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.18        |\n",
      "|    explained_variance   | 0.987        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0028      |\n",
      "|    n_updates            | 1140         |\n",
      "|    policy_gradient_loss | -0.0133      |\n",
      "|    value_loss           | 0.262        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.7     |\n",
      "|    ep_rew_mean     | 34.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 115      |\n",
      "|    time_elapsed    | 1164     |\n",
      "|    total_timesteps | 471040   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.5        |\n",
      "|    ep_rew_mean          | 33.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 116         |\n",
      "|    time_elapsed         | 1174        |\n",
      "|    total_timesteps      | 475136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004793466 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.23       |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0158      |\n",
      "|    n_updates            | 1150        |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    value_loss           | 0.275       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 77.6         |\n",
      "|    ep_rew_mean          | 34.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 117          |\n",
      "|    time_elapsed         | 1183         |\n",
      "|    total_timesteps      | 479232       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041417615 |\n",
      "|    clip_fraction        | 0.139        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.21        |\n",
      "|    explained_variance   | 0.983        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0408       |\n",
      "|    n_updates            | 1160         |\n",
      "|    policy_gradient_loss | -0.0133      |\n",
      "|    value_loss           | 0.34         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=480000, episode_reward=30.79 +/- 9.73\n",
      "Episode length: 76.20 +/- 8.39\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 76.2         |\n",
      "|    mean_reward          | 30.8         |\n",
      "|    std_reward           | 9.73         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 480000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037080708 |\n",
      "|    clip_fraction        | 0.137        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.23        |\n",
      "|    explained_variance   | 0.979        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0157       |\n",
      "|    n_updates            | 1170         |\n",
      "|    policy_gradient_loss | -0.0124      |\n",
      "|    value_loss           | 0.44         |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.8     |\n",
      "|    ep_rew_mean     | 34.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 118      |\n",
      "|    time_elapsed    | 1194     |\n",
      "|    total_timesteps | 483328   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.7        |\n",
      "|    ep_rew_mean          | 34.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 119         |\n",
      "|    time_elapsed         | 1204        |\n",
      "|    total_timesteps      | 487424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004974287 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.18       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.029       |\n",
      "|    n_updates            | 1180        |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    value_loss           | 0.305       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=490000, episode_reward=29.95 +/- 7.51\n",
      "Episode length: 79.70 +/- 9.33\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 79.7        |\n",
      "|    mean_reward          | 30          |\n",
      "|    std_reward           | 7.51        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 490000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004650004 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.2        |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0129      |\n",
      "|    n_updates            | 1190        |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 0.243       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.1     |\n",
      "|    ep_rew_mean     | 34.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 120      |\n",
      "|    time_elapsed    | 1215     |\n",
      "|    total_timesteps | 491520   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 77.8         |\n",
      "|    ep_rew_mean          | 33.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 121          |\n",
      "|    time_elapsed         | 1224         |\n",
      "|    total_timesteps      | 495616       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047610556 |\n",
      "|    clip_fraction        | 0.164        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.19        |\n",
      "|    explained_variance   | 0.979        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0278       |\n",
      "|    n_updates            | 1200         |\n",
      "|    policy_gradient_loss | -0.0154      |\n",
      "|    value_loss           | 0.341        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 77.9         |\n",
      "|    ep_rew_mean          | 35.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 122          |\n",
      "|    time_elapsed         | 1234         |\n",
      "|    total_timesteps      | 499712       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036345287 |\n",
      "|    clip_fraction        | 0.124        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.21        |\n",
      "|    explained_variance   | 0.977        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0403       |\n",
      "|    n_updates            | 1210         |\n",
      "|    policy_gradient_loss | -0.0146      |\n",
      "|    value_loss           | 0.379        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=500000, episode_reward=28.41 +/- 5.60\n",
      "Episode length: 76.50 +/- 8.10\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 76.5      |\n",
      "|    mean_reward          | 28.4      |\n",
      "|    std_reward           | 5.6       |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 500000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0042367 |\n",
      "|    clip_fraction        | 0.14      |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -2.16     |\n",
      "|    explained_variance   | 0.986     |\n",
      "|    learning_rate        | 5e-05     |\n",
      "|    loss                 | 0.0269    |\n",
      "|    n_updates            | 1220      |\n",
      "|    policy_gradient_loss | -0.0127   |\n",
      "|    value_loss           | 0.339     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.9     |\n",
      "|    ep_rew_mean     | 35.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 123      |\n",
      "|    time_elapsed    | 1245     |\n",
      "|    total_timesteps | 503808   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.3        |\n",
      "|    ep_rew_mean          | 34.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 124         |\n",
      "|    time_elapsed         | 1254        |\n",
      "|    total_timesteps      | 507904      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004271129 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.21       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0173      |\n",
      "|    n_updates            | 1230        |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    value_loss           | 0.331       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=510000, episode_reward=29.48 +/- 5.72\n",
      "Episode length: 83.50 +/- 6.73\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 83.5        |\n",
      "|    mean_reward          | 29.5        |\n",
      "|    std_reward           | 5.72        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 510000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005712049 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.19       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.047       |\n",
      "|    n_updates            | 1240        |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    value_loss           | 0.442       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.6     |\n",
      "|    ep_rew_mean     | 35.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 125      |\n",
      "|    time_elapsed    | 1265     |\n",
      "|    total_timesteps | 512000   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78           |\n",
      "|    ep_rew_mean          | 36.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 126          |\n",
      "|    time_elapsed         | 1275         |\n",
      "|    total_timesteps      | 516096       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047072424 |\n",
      "|    clip_fraction        | 0.17         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.15        |\n",
      "|    explained_variance   | 0.987        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0652       |\n",
      "|    n_updates            | 1250         |\n",
      "|    policy_gradient_loss | -0.0141      |\n",
      "|    value_loss           | 0.363        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=520000, episode_reward=32.75 +/- 5.04\n",
      "Episode length: 79.60 +/- 7.28\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 79.6       |\n",
      "|    mean_reward          | 32.8       |\n",
      "|    std_reward           | 5.04       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 520000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00477151 |\n",
      "|    clip_fraction        | 0.178      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -2.19      |\n",
      "|    explained_variance   | 0.988      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | 0.0561     |\n",
      "|    n_updates            | 1260       |\n",
      "|    policy_gradient_loss | -0.0157    |\n",
      "|    value_loss           | 0.258      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 76.9     |\n",
      "|    ep_rew_mean     | 35.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 127      |\n",
      "|    time_elapsed    | 1285     |\n",
      "|    total_timesteps | 520192   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78           |\n",
      "|    ep_rew_mean          | 35.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 128          |\n",
      "|    time_elapsed         | 1295         |\n",
      "|    total_timesteps      | 524288       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044748634 |\n",
      "|    clip_fraction        | 0.146        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.15        |\n",
      "|    explained_variance   | 0.983        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0246       |\n",
      "|    n_updates            | 1270         |\n",
      "|    policy_gradient_loss | -0.0155      |\n",
      "|    value_loss           | 0.309        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.2        |\n",
      "|    ep_rew_mean          | 36.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 129         |\n",
      "|    time_elapsed         | 1305        |\n",
      "|    total_timesteps      | 528384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005013978 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.18       |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.02        |\n",
      "|    n_updates            | 1280        |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    value_loss           | 0.261       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=530000, episode_reward=33.14 +/- 6.98\n",
      "Episode length: 76.50 +/- 10.13\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 76.5        |\n",
      "|    mean_reward          | 33.1        |\n",
      "|    std_reward           | 6.98        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 530000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004166006 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.19       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0162      |\n",
      "|    n_updates            | 1290        |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    value_loss           | 0.276       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.7     |\n",
      "|    ep_rew_mean     | 35.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 130      |\n",
      "|    time_elapsed    | 1316     |\n",
      "|    total_timesteps | 532480   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 78.3       |\n",
      "|    ep_rew_mean          | 35.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 404        |\n",
      "|    iterations           | 131        |\n",
      "|    time_elapsed         | 1325       |\n",
      "|    total_timesteps      | 536576     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00549163 |\n",
      "|    clip_fraction        | 0.168      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -2.2       |\n",
      "|    explained_variance   | 0.986      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | 0.0161     |\n",
      "|    n_updates            | 1300       |\n",
      "|    policy_gradient_loss | -0.0163    |\n",
      "|    value_loss           | 0.254      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=540000, episode_reward=33.42 +/- 8.11\n",
      "Episode length: 72.00 +/- 6.63\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 72           |\n",
      "|    mean_reward          | 33.4         |\n",
      "|    std_reward           | 8.11         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 540000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056805657 |\n",
      "|    clip_fraction        | 0.171        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.16        |\n",
      "|    explained_variance   | 0.987        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0369       |\n",
      "|    n_updates            | 1310         |\n",
      "|    policy_gradient_loss | -0.0121      |\n",
      "|    value_loss           | 0.284        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.5     |\n",
      "|    ep_rew_mean     | 35.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 132      |\n",
      "|    time_elapsed    | 1336     |\n",
      "|    total_timesteps | 540672   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.3        |\n",
      "|    ep_rew_mean          | 36          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 133         |\n",
      "|    time_elapsed         | 1346        |\n",
      "|    total_timesteps      | 544768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004664723 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.17       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.062       |\n",
      "|    n_updates            | 1320        |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 0.333       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 76.8         |\n",
      "|    ep_rew_mean          | 36.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 134          |\n",
      "|    time_elapsed         | 1355         |\n",
      "|    total_timesteps      | 548864       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048234398 |\n",
      "|    clip_fraction        | 0.158        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.17        |\n",
      "|    explained_variance   | 0.987        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0146       |\n",
      "|    n_updates            | 1330         |\n",
      "|    policy_gradient_loss | -0.0165      |\n",
      "|    value_loss           | 0.272        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=550000, episode_reward=29.79 +/- 5.93\n",
      "Episode length: 82.90 +/- 11.79\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 82.9        |\n",
      "|    mean_reward          | 29.8        |\n",
      "|    std_reward           | 5.93        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 550000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004375512 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.16       |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0318      |\n",
      "|    n_updates            | 1340        |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    value_loss           | 0.284       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 76.7     |\n",
      "|    ep_rew_mean     | 36.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 135      |\n",
      "|    time_elapsed    | 1366     |\n",
      "|    total_timesteps | 552960   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.3        |\n",
      "|    ep_rew_mean          | 36.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 136         |\n",
      "|    time_elapsed         | 1376        |\n",
      "|    total_timesteps      | 557056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004829265 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.18       |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0142      |\n",
      "|    n_updates            | 1350        |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    value_loss           | 0.292       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=560000, episode_reward=33.53 +/- 6.22\n",
      "Episode length: 81.90 +/- 12.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 81.9         |\n",
      "|    mean_reward          | 33.5         |\n",
      "|    std_reward           | 6.22         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 560000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046558958 |\n",
      "|    clip_fraction        | 0.162        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.13        |\n",
      "|    explained_variance   | 0.986        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0142       |\n",
      "|    n_updates            | 1360         |\n",
      "|    policy_gradient_loss | -0.0147      |\n",
      "|    value_loss           | 0.292        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.3     |\n",
      "|    ep_rew_mean     | 37       |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 137      |\n",
      "|    time_elapsed    | 1387     |\n",
      "|    total_timesteps | 561152   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78.7         |\n",
      "|    ep_rew_mean          | 36.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 138          |\n",
      "|    time_elapsed         | 1396         |\n",
      "|    total_timesteps      | 565248       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056728716 |\n",
      "|    clip_fraction        | 0.172        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.15        |\n",
      "|    explained_variance   | 0.989        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0154       |\n",
      "|    n_updates            | 1370         |\n",
      "|    policy_gradient_loss | -0.0147      |\n",
      "|    value_loss           | 0.21         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78.1         |\n",
      "|    ep_rew_mean          | 35.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 139          |\n",
      "|    time_elapsed         | 1406         |\n",
      "|    total_timesteps      | 569344       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041446695 |\n",
      "|    clip_fraction        | 0.149        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.12        |\n",
      "|    explained_variance   | 0.987        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0238       |\n",
      "|    n_updates            | 1380         |\n",
      "|    policy_gradient_loss | -0.0154      |\n",
      "|    value_loss           | 0.273        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=570000, episode_reward=35.91 +/- 7.63\n",
      "Episode length: 77.30 +/- 7.55\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 77.3        |\n",
      "|    mean_reward          | 35.9        |\n",
      "|    std_reward           | 7.63        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 570000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005518304 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.14       |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0444      |\n",
      "|    n_updates            | 1390        |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 0.289       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.5     |\n",
      "|    ep_rew_mean     | 36.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 140      |\n",
      "|    time_elapsed    | 1417     |\n",
      "|    total_timesteps | 573440   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 76.7         |\n",
      "|    ep_rew_mean          | 37.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 141          |\n",
      "|    time_elapsed         | 1426         |\n",
      "|    total_timesteps      | 577536       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045367246 |\n",
      "|    clip_fraction        | 0.17         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.1         |\n",
      "|    explained_variance   | 0.991        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0922       |\n",
      "|    n_updates            | 1400         |\n",
      "|    policy_gradient_loss | -0.0156      |\n",
      "|    value_loss           | 0.241        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=580000, episode_reward=35.38 +/- 5.57\n",
      "Episode length: 72.40 +/- 5.80\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 72.4        |\n",
      "|    mean_reward          | 35.4        |\n",
      "|    std_reward           | 5.57        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 580000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005310169 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.1        |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00801     |\n",
      "|    n_updates            | 1410        |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    value_loss           | 0.246       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.1     |\n",
      "|    ep_rew_mean     | 37.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 142      |\n",
      "|    time_elapsed    | 1437     |\n",
      "|    total_timesteps | 581632   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78.4         |\n",
      "|    ep_rew_mean          | 36.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 143          |\n",
      "|    time_elapsed         | 1447         |\n",
      "|    total_timesteps      | 585728       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040174266 |\n",
      "|    clip_fraction        | 0.144        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.09        |\n",
      "|    explained_variance   | 0.987        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0233       |\n",
      "|    n_updates            | 1420         |\n",
      "|    policy_gradient_loss | -0.0134      |\n",
      "|    value_loss           | 0.326        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78.3         |\n",
      "|    ep_rew_mean          | 36.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 144          |\n",
      "|    time_elapsed         | 1457         |\n",
      "|    total_timesteps      | 589824       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044863527 |\n",
      "|    clip_fraction        | 0.159        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.11        |\n",
      "|    explained_variance   | 0.987        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0116       |\n",
      "|    n_updates            | 1430         |\n",
      "|    policy_gradient_loss | -0.0174      |\n",
      "|    value_loss           | 0.277        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=590000, episode_reward=34.33 +/- 4.74\n",
      "Episode length: 84.30 +/- 6.63\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 84.3         |\n",
      "|    mean_reward          | 34.3         |\n",
      "|    std_reward           | 4.74         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 590000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052238116 |\n",
      "|    clip_fraction        | 0.162        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.12        |\n",
      "|    explained_variance   | 0.989        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0369       |\n",
      "|    n_updates            | 1440         |\n",
      "|    policy_gradient_loss | -0.016       |\n",
      "|    value_loss           | 0.241        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.5     |\n",
      "|    ep_rew_mean     | 37       |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 145      |\n",
      "|    time_elapsed    | 1468     |\n",
      "|    total_timesteps | 593920   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 79.3       |\n",
      "|    ep_rew_mean          | 36.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 404        |\n",
      "|    iterations           | 146        |\n",
      "|    time_elapsed         | 1477       |\n",
      "|    total_timesteps      | 598016     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00554464 |\n",
      "|    clip_fraction        | 0.16       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -2.11      |\n",
      "|    explained_variance   | 0.987      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | 0.0214     |\n",
      "|    n_updates            | 1450       |\n",
      "|    policy_gradient_loss | -0.0166    |\n",
      "|    value_loss           | 0.268      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=600000, episode_reward=37.49 +/- 7.51\n",
      "Episode length: 75.20 +/- 10.54\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 75.2        |\n",
      "|    mean_reward          | 37.5        |\n",
      "|    std_reward           | 7.51        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 600000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004664476 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.12       |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0154      |\n",
      "|    n_updates            | 1460        |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    value_loss           | 0.266       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.1     |\n",
      "|    ep_rew_mean     | 37.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 147      |\n",
      "|    time_elapsed    | 1488     |\n",
      "|    total_timesteps | 602112   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 77           |\n",
      "|    ep_rew_mean          | 37.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 148          |\n",
      "|    time_elapsed         | 1498         |\n",
      "|    total_timesteps      | 606208       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047587017 |\n",
      "|    clip_fraction        | 0.173        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.08        |\n",
      "|    explained_variance   | 0.988        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0299       |\n",
      "|    n_updates            | 1470         |\n",
      "|    policy_gradient_loss | -0.0152      |\n",
      "|    value_loss           | 0.302        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=610000, episode_reward=31.23 +/- 7.25\n",
      "Episode length: 79.70 +/- 8.27\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 79.7        |\n",
      "|    mean_reward          | 31.2        |\n",
      "|    std_reward           | 7.25        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 610000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004934109 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.13       |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00962     |\n",
      "|    n_updates            | 1480        |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    value_loss           | 0.279       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.9     |\n",
      "|    ep_rew_mean     | 37.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 149      |\n",
      "|    time_elapsed    | 1509     |\n",
      "|    total_timesteps | 610304   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.2        |\n",
      "|    ep_rew_mean          | 37.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 150         |\n",
      "|    time_elapsed         | 1518        |\n",
      "|    total_timesteps      | 614400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004535636 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.1        |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.045       |\n",
      "|    n_updates            | 1490        |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 0.3         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 77.3         |\n",
      "|    ep_rew_mean          | 38           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 151          |\n",
      "|    time_elapsed         | 1528         |\n",
      "|    total_timesteps      | 618496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063024834 |\n",
      "|    clip_fraction        | 0.212        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.09        |\n",
      "|    explained_variance   | 0.986        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.00554      |\n",
      "|    n_updates            | 1500         |\n",
      "|    policy_gradient_loss | -0.0162      |\n",
      "|    value_loss           | 0.274        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=620000, episode_reward=36.09 +/- 5.20\n",
      "Episode length: 79.10 +/- 6.74\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 79.1         |\n",
      "|    mean_reward          | 36.1         |\n",
      "|    std_reward           | 5.2          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 620000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046833064 |\n",
      "|    clip_fraction        | 0.178        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.08        |\n",
      "|    explained_variance   | 0.99         |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.000343     |\n",
      "|    n_updates            | 1510         |\n",
      "|    policy_gradient_loss | -0.0143      |\n",
      "|    value_loss           | 0.219        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.6     |\n",
      "|    ep_rew_mean     | 38.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 152      |\n",
      "|    time_elapsed    | 1539     |\n",
      "|    total_timesteps | 622592   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.5        |\n",
      "|    ep_rew_mean          | 38          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 153         |\n",
      "|    time_elapsed         | 1548        |\n",
      "|    total_timesteps      | 626688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005269694 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.04       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00573     |\n",
      "|    n_updates            | 1520        |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    value_loss           | 0.309       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=630000, episode_reward=39.72 +/- 7.31\n",
      "Episode length: 72.30 +/- 5.59\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 72.3         |\n",
      "|    mean_reward          | 39.7         |\n",
      "|    std_reward           | 7.31         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 630000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052810838 |\n",
      "|    clip_fraction        | 0.171        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.07        |\n",
      "|    explained_variance   | 0.986        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0335       |\n",
      "|    n_updates            | 1530         |\n",
      "|    policy_gradient_loss | -0.0146      |\n",
      "|    value_loss           | 0.276        |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.8     |\n",
      "|    ep_rew_mean     | 36.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 154      |\n",
      "|    time_elapsed    | 1559     |\n",
      "|    total_timesteps | 630784   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 77.7         |\n",
      "|    ep_rew_mean          | 37.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 155          |\n",
      "|    time_elapsed         | 1569         |\n",
      "|    total_timesteps      | 634880       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051037376 |\n",
      "|    clip_fraction        | 0.177        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.05        |\n",
      "|    explained_variance   | 0.985        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0088       |\n",
      "|    n_updates            | 1540         |\n",
      "|    policy_gradient_loss | -0.0162      |\n",
      "|    value_loss           | 0.33         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 77.8         |\n",
      "|    ep_rew_mean          | 37.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 156          |\n",
      "|    time_elapsed         | 1578         |\n",
      "|    total_timesteps      | 638976       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060097463 |\n",
      "|    clip_fraction        | 0.188        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.04        |\n",
      "|    explained_variance   | 0.99         |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0279       |\n",
      "|    n_updates            | 1550         |\n",
      "|    policy_gradient_loss | -0.017       |\n",
      "|    value_loss           | 0.257        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=640000, episode_reward=36.48 +/- 8.19\n",
      "Episode length: 78.60 +/- 10.14\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 78.6         |\n",
      "|    mean_reward          | 36.5         |\n",
      "|    std_reward           | 8.19         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 640000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049542096 |\n",
      "|    clip_fraction        | 0.18         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.04        |\n",
      "|    explained_variance   | 0.988        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0218       |\n",
      "|    n_updates            | 1560         |\n",
      "|    policy_gradient_loss | -0.0163      |\n",
      "|    value_loss           | 0.293        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.8     |\n",
      "|    ep_rew_mean     | 37.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 157      |\n",
      "|    time_elapsed    | 1589     |\n",
      "|    total_timesteps | 643072   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.6        |\n",
      "|    ep_rew_mean          | 37          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 158         |\n",
      "|    time_elapsed         | 1599        |\n",
      "|    total_timesteps      | 647168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005142674 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.03       |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0182      |\n",
      "|    n_updates            | 1570        |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    value_loss           | 0.236       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=650000, episode_reward=37.77 +/- 7.13\n",
      "Episode length: 78.50 +/- 6.65\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 78.5        |\n",
      "|    mean_reward          | 37.8        |\n",
      "|    std_reward           | 7.13        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 650000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005961077 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.03       |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0233      |\n",
      "|    n_updates            | 1580        |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    value_loss           | 0.264       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.5     |\n",
      "|    ep_rew_mean     | 38.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 159      |\n",
      "|    time_elapsed    | 1610     |\n",
      "|    total_timesteps | 651264   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 79.7         |\n",
      "|    ep_rew_mean          | 38.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 160          |\n",
      "|    time_elapsed         | 1620         |\n",
      "|    total_timesteps      | 655360       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052805548 |\n",
      "|    clip_fraction        | 0.182        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.01        |\n",
      "|    explained_variance   | 0.991        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0203       |\n",
      "|    n_updates            | 1590         |\n",
      "|    policy_gradient_loss | -0.0152      |\n",
      "|    value_loss           | 0.204        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 80.5         |\n",
      "|    ep_rew_mean          | 37.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 161          |\n",
      "|    time_elapsed         | 1629         |\n",
      "|    total_timesteps      | 659456       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059488323 |\n",
      "|    clip_fraction        | 0.173        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.01        |\n",
      "|    explained_variance   | 0.99         |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0337       |\n",
      "|    n_updates            | 1600         |\n",
      "|    policy_gradient_loss | -0.0153      |\n",
      "|    value_loss           | 0.254        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=660000, episode_reward=40.62 +/- 5.45\n",
      "Episode length: 73.90 +/- 10.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 73.9         |\n",
      "|    mean_reward          | 40.6         |\n",
      "|    std_reward           | 5.45         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 660000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054288576 |\n",
      "|    clip_fraction        | 0.199        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.06        |\n",
      "|    explained_variance   | 0.989        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.00399      |\n",
      "|    n_updates            | 1610         |\n",
      "|    policy_gradient_loss | -0.0157      |\n",
      "|    value_loss           | 0.235        |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 80.1     |\n",
      "|    ep_rew_mean     | 37.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 162      |\n",
      "|    time_elapsed    | 1640     |\n",
      "|    total_timesteps | 663552   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 79           |\n",
      "|    ep_rew_mean          | 38.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 163          |\n",
      "|    time_elapsed         | 1650         |\n",
      "|    total_timesteps      | 667648       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051540975 |\n",
      "|    clip_fraction        | 0.176        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.03        |\n",
      "|    explained_variance   | 0.99         |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0226       |\n",
      "|    n_updates            | 1620         |\n",
      "|    policy_gradient_loss | -0.0168      |\n",
      "|    value_loss           | 0.252        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=670000, episode_reward=35.84 +/- 10.63\n",
      "Episode length: 78.40 +/- 8.83\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 78.4         |\n",
      "|    mean_reward          | 35.8         |\n",
      "|    std_reward           | 10.6         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 670000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058613834 |\n",
      "|    clip_fraction        | 0.21         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.01        |\n",
      "|    explained_variance   | 0.992        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.00524      |\n",
      "|    n_updates            | 1630         |\n",
      "|    policy_gradient_loss | -0.0158      |\n",
      "|    value_loss           | 0.203        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.6     |\n",
      "|    ep_rew_mean     | 38.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 164      |\n",
      "|    time_elapsed    | 1661     |\n",
      "|    total_timesteps | 671744   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.5        |\n",
      "|    ep_rew_mean          | 38.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 165         |\n",
      "|    time_elapsed         | 1671        |\n",
      "|    total_timesteps      | 675840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006266511 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2          |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0477      |\n",
      "|    n_updates            | 1640        |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    value_loss           | 0.339       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 78.5       |\n",
      "|    ep_rew_mean          | 38.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 404        |\n",
      "|    iterations           | 166        |\n",
      "|    time_elapsed         | 1680       |\n",
      "|    total_timesteps      | 679936     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00576273 |\n",
      "|    clip_fraction        | 0.189      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -2.04      |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | 0.0131     |\n",
      "|    n_updates            | 1650       |\n",
      "|    policy_gradient_loss | -0.0159    |\n",
      "|    value_loss           | 0.206      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=680000, episode_reward=39.62 +/- 6.07\n",
      "Episode length: 77.40 +/- 7.85\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 77.4        |\n",
      "|    mean_reward          | 39.6        |\n",
      "|    std_reward           | 6.07        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 680000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006028616 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.03       |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0148      |\n",
      "|    n_updates            | 1660        |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    value_loss           | 0.229       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.1     |\n",
      "|    ep_rew_mean     | 38.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 167      |\n",
      "|    time_elapsed    | 1691     |\n",
      "|    total_timesteps | 684032   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 79.5         |\n",
      "|    ep_rew_mean          | 38.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 168          |\n",
      "|    time_elapsed         | 1701         |\n",
      "|    total_timesteps      | 688128       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058937063 |\n",
      "|    clip_fraction        | 0.201        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.05        |\n",
      "|    explained_variance   | 0.989        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.00502      |\n",
      "|    n_updates            | 1670         |\n",
      "|    policy_gradient_loss | -0.0164      |\n",
      "|    value_loss           | 0.298        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=690000, episode_reward=39.28 +/- 8.45\n",
      "Episode length: 75.10 +/- 10.45\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 75.1        |\n",
      "|    mean_reward          | 39.3        |\n",
      "|    std_reward           | 8.45        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 690000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005232876 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.04       |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0295      |\n",
      "|    n_updates            | 1680        |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    value_loss           | 0.211       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.7     |\n",
      "|    ep_rew_mean     | 39.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 169      |\n",
      "|    time_elapsed    | 1712     |\n",
      "|    total_timesteps | 692224   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78.6         |\n",
      "|    ep_rew_mean          | 40           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 170          |\n",
      "|    time_elapsed         | 1721         |\n",
      "|    total_timesteps      | 696320       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058605927 |\n",
      "|    clip_fraction        | 0.197        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.02        |\n",
      "|    explained_variance   | 0.991        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0632       |\n",
      "|    n_updates            | 1690         |\n",
      "|    policy_gradient_loss | -0.0147      |\n",
      "|    value_loss           | 0.232        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=700000, episode_reward=40.97 +/- 5.22\n",
      "Episode length: 77.20 +/- 7.28\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 77.2        |\n",
      "|    mean_reward          | 41          |\n",
      "|    std_reward           | 5.22        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 700000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006697963 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.98       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0255      |\n",
      "|    n_updates            | 1700        |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    value_loss           | 0.194       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.2     |\n",
      "|    ep_rew_mean     | 39.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 171      |\n",
      "|    time_elapsed    | 1732     |\n",
      "|    total_timesteps | 700416   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 75.9        |\n",
      "|    ep_rew_mean          | 40.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 172         |\n",
      "|    time_elapsed         | 1742        |\n",
      "|    total_timesteps      | 704512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005648115 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.99       |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0203      |\n",
      "|    n_updates            | 1710        |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    value_loss           | 0.216       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 77           |\n",
      "|    ep_rew_mean          | 40.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 173          |\n",
      "|    time_elapsed         | 1751         |\n",
      "|    total_timesteps      | 708608       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064763287 |\n",
      "|    clip_fraction        | 0.202        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2           |\n",
      "|    explained_variance   | 0.991        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00669     |\n",
      "|    n_updates            | 1720         |\n",
      "|    policy_gradient_loss | -0.0147      |\n",
      "|    value_loss           | 0.214        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=710000, episode_reward=38.09 +/- 5.06\n",
      "Episode length: 80.00 +/- 11.24\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 80          |\n",
      "|    mean_reward          | 38.1        |\n",
      "|    std_reward           | 5.06        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 710000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005908771 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2          |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0168      |\n",
      "|    n_updates            | 1730        |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    value_loss           | 0.228       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.7     |\n",
      "|    ep_rew_mean     | 38.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 174      |\n",
      "|    time_elapsed    | 1762     |\n",
      "|    total_timesteps | 712704   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 80.1         |\n",
      "|    ep_rew_mean          | 38.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 175          |\n",
      "|    time_elapsed         | 1772         |\n",
      "|    total_timesteps      | 716800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054239994 |\n",
      "|    clip_fraction        | 0.167        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.01        |\n",
      "|    explained_variance   | 0.984        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0115       |\n",
      "|    n_updates            | 1740         |\n",
      "|    policy_gradient_loss | -0.014       |\n",
      "|    value_loss           | 0.35         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=720000, episode_reward=40.09 +/- 6.07\n",
      "Episode length: 79.20 +/- 5.81\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 79.2        |\n",
      "|    mean_reward          | 40.1        |\n",
      "|    std_reward           | 6.07        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 720000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005394091 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2          |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0225      |\n",
      "|    n_updates            | 1750        |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    value_loss           | 0.229       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.8     |\n",
      "|    ep_rew_mean     | 38.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 176      |\n",
      "|    time_elapsed    | 1783     |\n",
      "|    total_timesteps | 720896   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.1        |\n",
      "|    ep_rew_mean          | 38.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 177         |\n",
      "|    time_elapsed         | 1793        |\n",
      "|    total_timesteps      | 724992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006689605 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2          |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0086      |\n",
      "|    n_updates            | 1760        |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 0.194       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 80           |\n",
      "|    ep_rew_mean          | 38.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 178          |\n",
      "|    time_elapsed         | 1803         |\n",
      "|    total_timesteps      | 729088       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049017374 |\n",
      "|    clip_fraction        | 0.171        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.96        |\n",
      "|    explained_variance   | 0.99         |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0211       |\n",
      "|    n_updates            | 1770         |\n",
      "|    policy_gradient_loss | -0.0143      |\n",
      "|    value_loss           | 0.226        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=730000, episode_reward=37.12 +/- 8.09\n",
      "Episode length: 78.60 +/- 10.57\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 78.6         |\n",
      "|    mean_reward          | 37.1         |\n",
      "|    std_reward           | 8.09         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 730000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057143182 |\n",
      "|    clip_fraction        | 0.172        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.01        |\n",
      "|    explained_variance   | 0.99         |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.021        |\n",
      "|    n_updates            | 1780         |\n",
      "|    policy_gradient_loss | -0.0141      |\n",
      "|    value_loss           | 0.237        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.9     |\n",
      "|    ep_rew_mean     | 39.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 179      |\n",
      "|    time_elapsed    | 1813     |\n",
      "|    total_timesteps | 733184   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 77.7         |\n",
      "|    ep_rew_mean          | 39.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 180          |\n",
      "|    time_elapsed         | 1823         |\n",
      "|    total_timesteps      | 737280       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051040202 |\n",
      "|    clip_fraction        | 0.189        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.97        |\n",
      "|    explained_variance   | 0.991        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0308       |\n",
      "|    n_updates            | 1790         |\n",
      "|    policy_gradient_loss | -0.0142      |\n",
      "|    value_loss           | 0.236        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=740000, episode_reward=42.03 +/- 6.28\n",
      "Episode length: 76.10 +/- 8.07\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 76.1         |\n",
      "|    mean_reward          | 42           |\n",
      "|    std_reward           | 6.28         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 740000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067250794 |\n",
      "|    clip_fraction        | 0.204        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.02        |\n",
      "|    explained_variance   | 0.991        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.00965      |\n",
      "|    n_updates            | 1800         |\n",
      "|    policy_gradient_loss | -0.0159      |\n",
      "|    value_loss           | 0.215        |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78       |\n",
      "|    ep_rew_mean     | 38.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 181      |\n",
      "|    time_elapsed    | 1834     |\n",
      "|    total_timesteps | 741376   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 79           |\n",
      "|    ep_rew_mean          | 38.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 182          |\n",
      "|    time_elapsed         | 1844         |\n",
      "|    total_timesteps      | 745472       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063727116 |\n",
      "|    clip_fraction        | 0.199        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.99        |\n",
      "|    explained_variance   | 0.992        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0177       |\n",
      "|    n_updates            | 1810         |\n",
      "|    policy_gradient_loss | -0.0155      |\n",
      "|    value_loss           | 0.237        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.9        |\n",
      "|    ep_rew_mean          | 38.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 183         |\n",
      "|    time_elapsed         | 1853        |\n",
      "|    total_timesteps      | 749568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005673499 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.01       |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0152      |\n",
      "|    n_updates            | 1820        |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 0.254       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=750000, episode_reward=36.64 +/- 7.22\n",
      "Episode length: 78.30 +/- 8.97\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 78.3        |\n",
      "|    mean_reward          | 36.6        |\n",
      "|    std_reward           | 7.22        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 750000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005522347 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.96       |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00103     |\n",
      "|    n_updates            | 1830        |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 0.223       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.3     |\n",
      "|    ep_rew_mean     | 38.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 184      |\n",
      "|    time_elapsed    | 1864     |\n",
      "|    total_timesteps | 753664   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.5        |\n",
      "|    ep_rew_mean          | 39.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 185         |\n",
      "|    time_elapsed         | 1874        |\n",
      "|    total_timesteps      | 757760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006173814 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2          |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0155      |\n",
      "|    n_updates            | 1840        |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    value_loss           | 0.225       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=760000, episode_reward=41.76 +/- 5.96\n",
      "Episode length: 80.20 +/- 8.99\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 80.2       |\n",
      "|    mean_reward          | 41.8       |\n",
      "|    std_reward           | 5.96       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 760000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00581716 |\n",
      "|    clip_fraction        | 0.198      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.92      |\n",
      "|    explained_variance   | 0.991      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | 0.0244     |\n",
      "|    n_updates            | 1850       |\n",
      "|    policy_gradient_loss | -0.0166    |\n",
      "|    value_loss           | 0.251      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.6     |\n",
      "|    ep_rew_mean     | 39.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 186      |\n",
      "|    time_elapsed    | 1885     |\n",
      "|    total_timesteps | 761856   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 79.7         |\n",
      "|    ep_rew_mean          | 39.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 187          |\n",
      "|    time_elapsed         | 1894         |\n",
      "|    total_timesteps      | 765952       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062258267 |\n",
      "|    clip_fraction        | 0.194        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.99        |\n",
      "|    explained_variance   | 0.991        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.00348      |\n",
      "|    n_updates            | 1860         |\n",
      "|    policy_gradient_loss | -0.0158      |\n",
      "|    value_loss           | 0.197        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=770000, episode_reward=37.46 +/- 7.09\n",
      "Episode length: 79.80 +/- 12.27\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 79.8         |\n",
      "|    mean_reward          | 37.5         |\n",
      "|    std_reward           | 7.09         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 770000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062644924 |\n",
      "|    clip_fraction        | 0.213        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.97        |\n",
      "|    explained_variance   | 0.992        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.036        |\n",
      "|    n_updates            | 1870         |\n",
      "|    policy_gradient_loss | -0.0149      |\n",
      "|    value_loss           | 0.203        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 76.8     |\n",
      "|    ep_rew_mean     | 39.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 188      |\n",
      "|    time_elapsed    | 1905     |\n",
      "|    total_timesteps | 770048   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.5        |\n",
      "|    ep_rew_mean          | 39.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 189         |\n",
      "|    time_elapsed         | 1915        |\n",
      "|    total_timesteps      | 774144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005454271 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.93       |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0198      |\n",
      "|    n_updates            | 1880        |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 0.233       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.7        |\n",
      "|    ep_rew_mean          | 40          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 190         |\n",
      "|    time_elapsed         | 1924        |\n",
      "|    total_timesteps      | 778240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005933807 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.96       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00649     |\n",
      "|    n_updates            | 1890        |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    value_loss           | 0.21        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=780000, episode_reward=42.08 +/- 7.48\n",
      "Episode length: 76.90 +/- 13.45\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 76.9       |\n",
      "|    mean_reward          | 42.1       |\n",
      "|    std_reward           | 7.48       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 780000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00660104 |\n",
      "|    clip_fraction        | 0.205      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.96      |\n",
      "|    explained_variance   | 0.99       |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | 0.00409    |\n",
      "|    n_updates            | 1900       |\n",
      "|    policy_gradient_loss | -0.0144    |\n",
      "|    value_loss           | 0.267      |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.1     |\n",
      "|    ep_rew_mean     | 39       |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 191      |\n",
      "|    time_elapsed    | 1935     |\n",
      "|    total_timesteps | 782336   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78.3         |\n",
      "|    ep_rew_mean          | 38           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 192          |\n",
      "|    time_elapsed         | 1945         |\n",
      "|    total_timesteps      | 786432       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068035154 |\n",
      "|    clip_fraction        | 0.219        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.96        |\n",
      "|    explained_variance   | 0.99         |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.00354      |\n",
      "|    n_updates            | 1910         |\n",
      "|    policy_gradient_loss | -0.0154      |\n",
      "|    value_loss           | 0.225        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=790000, episode_reward=40.00 +/- 6.46\n",
      "Episode length: 77.30 +/- 7.46\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 77.3        |\n",
      "|    mean_reward          | 40          |\n",
      "|    std_reward           | 6.46        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 790000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005677779 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.95       |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0243      |\n",
      "|    n_updates            | 1920        |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    value_loss           | 0.262       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.4     |\n",
      "|    ep_rew_mean     | 38.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 193      |\n",
      "|    time_elapsed    | 1956     |\n",
      "|    total_timesteps | 790528   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78.3         |\n",
      "|    ep_rew_mean          | 39           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 194          |\n",
      "|    time_elapsed         | 1965         |\n",
      "|    total_timesteps      | 794624       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066829715 |\n",
      "|    clip_fraction        | 0.176        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.93        |\n",
      "|    explained_variance   | 0.989        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0159       |\n",
      "|    n_updates            | 1930         |\n",
      "|    policy_gradient_loss | -0.0151      |\n",
      "|    value_loss           | 0.231        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 77.8         |\n",
      "|    ep_rew_mean          | 39.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 195          |\n",
      "|    time_elapsed         | 1975         |\n",
      "|    total_timesteps      | 798720       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064406684 |\n",
      "|    clip_fraction        | 0.198        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.91        |\n",
      "|    explained_variance   | 0.99         |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.000615     |\n",
      "|    n_updates            | 1940         |\n",
      "|    policy_gradient_loss | -0.0158      |\n",
      "|    value_loss           | 0.229        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=800000, episode_reward=37.23 +/- 4.58\n",
      "Episode length: 81.00 +/- 7.28\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 81           |\n",
      "|    mean_reward          | 37.2         |\n",
      "|    std_reward           | 4.58         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 800000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066104145 |\n",
      "|    clip_fraction        | 0.234        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.91        |\n",
      "|    explained_variance   | 0.993        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.00965      |\n",
      "|    n_updates            | 1950         |\n",
      "|    policy_gradient_loss | -0.0152      |\n",
      "|    value_loss           | 0.19         |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.6     |\n",
      "|    ep_rew_mean     | 40.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 196      |\n",
      "|    time_elapsed    | 1986     |\n",
      "|    total_timesteps | 802816   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.1        |\n",
      "|    ep_rew_mean          | 40.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 197         |\n",
      "|    time_elapsed         | 1996        |\n",
      "|    total_timesteps      | 806912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007222671 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.93       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0162      |\n",
      "|    n_updates            | 1960        |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    value_loss           | 0.234       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=810000, episode_reward=39.17 +/- 7.65\n",
      "Episode length: 81.30 +/- 8.39\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 81.3         |\n",
      "|    mean_reward          | 39.2         |\n",
      "|    std_reward           | 7.65         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 810000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058708303 |\n",
      "|    clip_fraction        | 0.196        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.93        |\n",
      "|    explained_variance   | 0.992        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.019        |\n",
      "|    n_updates            | 1970         |\n",
      "|    policy_gradient_loss | -0.0151      |\n",
      "|    value_loss           | 0.208        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79       |\n",
      "|    ep_rew_mean     | 40.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 198      |\n",
      "|    time_elapsed    | 2007     |\n",
      "|    total_timesteps | 811008   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78.9         |\n",
      "|    ep_rew_mean          | 39.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 199          |\n",
      "|    time_elapsed         | 2016         |\n",
      "|    total_timesteps      | 815104       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069645476 |\n",
      "|    clip_fraction        | 0.225        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.89        |\n",
      "|    explained_variance   | 0.993        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.016        |\n",
      "|    n_updates            | 1980         |\n",
      "|    policy_gradient_loss | -0.0145      |\n",
      "|    value_loss           | 0.198        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.6        |\n",
      "|    ep_rew_mean          | 40.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 200         |\n",
      "|    time_elapsed         | 2026        |\n",
      "|    total_timesteps      | 819200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006889989 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00946     |\n",
      "|    n_updates            | 1990        |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    value_loss           | 0.193       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=820000, episode_reward=40.70 +/- 5.08\n",
      "Episode length: 79.00 +/- 7.54\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 79          |\n",
      "|    mean_reward          | 40.7        |\n",
      "|    std_reward           | 5.08        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 820000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006709188 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0104     |\n",
      "|    n_updates            | 2000        |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    value_loss           | 0.213       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.2     |\n",
      "|    ep_rew_mean     | 40.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 201      |\n",
      "|    time_elapsed    | 2037     |\n",
      "|    total_timesteps | 823296   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78.7         |\n",
      "|    ep_rew_mean          | 40           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 202          |\n",
      "|    time_elapsed         | 2046         |\n",
      "|    total_timesteps      | 827392       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058642337 |\n",
      "|    clip_fraction        | 0.18         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.9         |\n",
      "|    explained_variance   | 0.991        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0246       |\n",
      "|    n_updates            | 2010         |\n",
      "|    policy_gradient_loss | -0.0138      |\n",
      "|    value_loss           | 0.241        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=830000, episode_reward=39.78 +/- 8.02\n",
      "Episode length: 78.00 +/- 11.03\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 78          |\n",
      "|    mean_reward          | 39.8        |\n",
      "|    std_reward           | 8.02        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 830000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006674693 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.93       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00241    |\n",
      "|    n_updates            | 2020        |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    value_loss           | 0.187       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79       |\n",
      "|    ep_rew_mean     | 39.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 203      |\n",
      "|    time_elapsed    | 2058     |\n",
      "|    total_timesteps | 831488   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 79.1       |\n",
      "|    ep_rew_mean          | 40.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 404        |\n",
      "|    iterations           | 204        |\n",
      "|    time_elapsed         | 2067       |\n",
      "|    total_timesteps      | 835584     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00651062 |\n",
      "|    clip_fraction        | 0.223      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.91      |\n",
      "|    explained_variance   | 0.991      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | 0.0104     |\n",
      "|    n_updates            | 2030       |\n",
      "|    policy_gradient_loss | -0.0156    |\n",
      "|    value_loss           | 0.203      |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 76.5         |\n",
      "|    ep_rew_mean          | 41.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 205          |\n",
      "|    time_elapsed         | 2077         |\n",
      "|    total_timesteps      | 839680       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059817433 |\n",
      "|    clip_fraction        | 0.193        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.88        |\n",
      "|    explained_variance   | 0.993        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.00353      |\n",
      "|    n_updates            | 2040         |\n",
      "|    policy_gradient_loss | -0.0143      |\n",
      "|    value_loss           | 0.214        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=840000, episode_reward=39.88 +/- 5.11\n",
      "Episode length: 76.40 +/- 7.61\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 76.4         |\n",
      "|    mean_reward          | 39.9         |\n",
      "|    std_reward           | 5.11         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 840000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057952525 |\n",
      "|    clip_fraction        | 0.216        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.89        |\n",
      "|    explained_variance   | 0.992        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0418       |\n",
      "|    n_updates            | 2050         |\n",
      "|    policy_gradient_loss | -0.0153      |\n",
      "|    value_loss           | 0.2          |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.6     |\n",
      "|    ep_rew_mean     | 40.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 206      |\n",
      "|    time_elapsed    | 2088     |\n",
      "|    total_timesteps | 843776   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 79.1         |\n",
      "|    ep_rew_mean          | 40.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 207          |\n",
      "|    time_elapsed         | 2097         |\n",
      "|    total_timesteps      | 847872       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070332102 |\n",
      "|    clip_fraction        | 0.222        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.91        |\n",
      "|    explained_variance   | 0.992        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.005        |\n",
      "|    n_updates            | 2060         |\n",
      "|    policy_gradient_loss | -0.0152      |\n",
      "|    value_loss           | 0.186        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=850000, episode_reward=44.68 +/- 5.79\n",
      "Episode length: 74.90 +/- 11.17\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 74.9         |\n",
      "|    mean_reward          | 44.7         |\n",
      "|    std_reward           | 5.79         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 850000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075915046 |\n",
      "|    clip_fraction        | 0.225        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.91        |\n",
      "|    explained_variance   | 0.994        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0278       |\n",
      "|    n_updates            | 2070         |\n",
      "|    policy_gradient_loss | -0.0151      |\n",
      "|    value_loss           | 0.193        |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.9     |\n",
      "|    ep_rew_mean     | 40.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 208      |\n",
      "|    time_elapsed    | 2108     |\n",
      "|    total_timesteps | 851968   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.7        |\n",
      "|    ep_rew_mean          | 40.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 209         |\n",
      "|    time_elapsed         | 2118        |\n",
      "|    total_timesteps      | 856064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006876141 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00625     |\n",
      "|    n_updates            | 2080        |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    value_loss           | 0.22        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=860000, episode_reward=39.92 +/- 6.32\n",
      "Episode length: 76.60 +/- 5.54\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 76.6        |\n",
      "|    mean_reward          | 39.9        |\n",
      "|    std_reward           | 6.32        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 860000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007170952 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00576     |\n",
      "|    n_updates            | 2090        |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    value_loss           | 0.191       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 76.8     |\n",
      "|    ep_rew_mean     | 41.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 210      |\n",
      "|    time_elapsed    | 2128     |\n",
      "|    total_timesteps | 860160   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78           |\n",
      "|    ep_rew_mean          | 40.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 211          |\n",
      "|    time_elapsed         | 2138         |\n",
      "|    total_timesteps      | 864256       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064862524 |\n",
      "|    clip_fraction        | 0.215        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.9         |\n",
      "|    explained_variance   | 0.993        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.00028      |\n",
      "|    n_updates            | 2100         |\n",
      "|    policy_gradient_loss | -0.0156      |\n",
      "|    value_loss           | 0.184        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 77.8         |\n",
      "|    ep_rew_mean          | 41           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 212          |\n",
      "|    time_elapsed         | 2148         |\n",
      "|    total_timesteps      | 868352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063398387 |\n",
      "|    clip_fraction        | 0.203        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.88        |\n",
      "|    explained_variance   | 0.991        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0407       |\n",
      "|    n_updates            | 2110         |\n",
      "|    policy_gradient_loss | -0.0152      |\n",
      "|    value_loss           | 0.224        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=870000, episode_reward=40.51 +/- 5.79\n",
      "Episode length: 81.50 +/- 9.71\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 81.5         |\n",
      "|    mean_reward          | 40.5         |\n",
      "|    std_reward           | 5.79         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 870000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062387027 |\n",
      "|    clip_fraction        | 0.197        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.86        |\n",
      "|    explained_variance   | 0.992        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.00902      |\n",
      "|    n_updates            | 2120         |\n",
      "|    policy_gradient_loss | -0.014       |\n",
      "|    value_loss           | 0.228        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.3     |\n",
      "|    ep_rew_mean     | 41.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 213      |\n",
      "|    time_elapsed    | 2158     |\n",
      "|    total_timesteps | 872448   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 77.3         |\n",
      "|    ep_rew_mean          | 40.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 214          |\n",
      "|    time_elapsed         | 2168         |\n",
      "|    total_timesteps      | 876544       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060675135 |\n",
      "|    clip_fraction        | 0.214        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.88        |\n",
      "|    explained_variance   | 0.992        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0133       |\n",
      "|    n_updates            | 2130         |\n",
      "|    policy_gradient_loss | -0.0162      |\n",
      "|    value_loss           | 0.215        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=880000, episode_reward=39.02 +/- 8.15\n",
      "Episode length: 80.30 +/- 10.76\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 80.3         |\n",
      "|    mean_reward          | 39           |\n",
      "|    std_reward           | 8.15         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 880000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061762114 |\n",
      "|    clip_fraction        | 0.208        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.85        |\n",
      "|    explained_variance   | 0.993        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.00906      |\n",
      "|    n_updates            | 2140         |\n",
      "|    policy_gradient_loss | -0.0143      |\n",
      "|    value_loss           | 0.201        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.3     |\n",
      "|    ep_rew_mean     | 40.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 215      |\n",
      "|    time_elapsed    | 2179     |\n",
      "|    total_timesteps | 880640   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 77.9       |\n",
      "|    ep_rew_mean          | 41.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 404        |\n",
      "|    iterations           | 216        |\n",
      "|    time_elapsed         | 2189       |\n",
      "|    total_timesteps      | 884736     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00785965 |\n",
      "|    clip_fraction        | 0.209      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.86      |\n",
      "|    explained_variance   | 0.994      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | 0.0134     |\n",
      "|    n_updates            | 2150       |\n",
      "|    policy_gradient_loss | -0.0148    |\n",
      "|    value_loss           | 0.2        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.4        |\n",
      "|    ep_rew_mean          | 40.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 217         |\n",
      "|    time_elapsed         | 2198        |\n",
      "|    total_timesteps      | 888832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007424242 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.81       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0143      |\n",
      "|    n_updates            | 2160        |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 0.206       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=890000, episode_reward=43.30 +/- 4.97\n",
      "Episode length: 71.60 +/- 8.30\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 71.6        |\n",
      "|    mean_reward          | 43.3        |\n",
      "|    std_reward           | 4.97        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 890000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006589105 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.84       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0145      |\n",
      "|    n_updates            | 2170        |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    value_loss           | 0.206       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79       |\n",
      "|    ep_rew_mean     | 40.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 218      |\n",
      "|    time_elapsed    | 2209     |\n",
      "|    total_timesteps | 892928   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78           |\n",
      "|    ep_rew_mean          | 41.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 219          |\n",
      "|    time_elapsed         | 2218         |\n",
      "|    total_timesteps      | 897024       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077180546 |\n",
      "|    clip_fraction        | 0.244        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.87        |\n",
      "|    explained_variance   | 0.993        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0113       |\n",
      "|    n_updates            | 2180         |\n",
      "|    policy_gradient_loss | -0.0144      |\n",
      "|    value_loss           | 0.195        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=900000, episode_reward=39.17 +/- 5.16\n",
      "Episode length: 82.50 +/- 9.43\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 82.5         |\n",
      "|    mean_reward          | 39.2         |\n",
      "|    std_reward           | 5.16         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 900000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068988083 |\n",
      "|    clip_fraction        | 0.198        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.88        |\n",
      "|    explained_variance   | 0.993        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0307       |\n",
      "|    n_updates            | 2190         |\n",
      "|    policy_gradient_loss | -0.015       |\n",
      "|    value_loss           | 0.239        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 76.9     |\n",
      "|    ep_rew_mean     | 41.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 220      |\n",
      "|    time_elapsed    | 2229     |\n",
      "|    total_timesteps | 901120   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77          |\n",
      "|    ep_rew_mean          | 41.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 221         |\n",
      "|    time_elapsed         | 2239        |\n",
      "|    total_timesteps      | 905216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006638784 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00315     |\n",
      "|    n_updates            | 2200        |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    value_loss           | 0.222       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 78.2       |\n",
      "|    ep_rew_mean          | 42.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 404        |\n",
      "|    iterations           | 222        |\n",
      "|    time_elapsed         | 2248       |\n",
      "|    total_timesteps      | 909312     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00662639 |\n",
      "|    clip_fraction        | 0.224      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.84      |\n",
      "|    explained_variance   | 0.994      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | 0.014      |\n",
      "|    n_updates            | 2210       |\n",
      "|    policy_gradient_loss | -0.0147    |\n",
      "|    value_loss           | 0.184      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=910000, episode_reward=36.43 +/- 8.58\n",
      "Episode length: 79.00 +/- 7.91\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 79          |\n",
      "|    mean_reward          | 36.4        |\n",
      "|    std_reward           | 8.58        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 910000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007165957 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.85       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0144     |\n",
      "|    n_updates            | 2220        |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    value_loss           | 0.168       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78       |\n",
      "|    ep_rew_mean     | 41.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 223      |\n",
      "|    time_elapsed    | 2259     |\n",
      "|    total_timesteps | 913408   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 77.5         |\n",
      "|    ep_rew_mean          | 42           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 224          |\n",
      "|    time_elapsed         | 2269         |\n",
      "|    total_timesteps      | 917504       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067939186 |\n",
      "|    clip_fraction        | 0.219        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.86        |\n",
      "|    explained_variance   | 0.994        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0262       |\n",
      "|    n_updates            | 2230         |\n",
      "|    policy_gradient_loss | -0.0131      |\n",
      "|    value_loss           | 0.171        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=920000, episode_reward=42.42 +/- 2.85\n",
      "Episode length: 76.90 +/- 6.04\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 76.9         |\n",
      "|    mean_reward          | 42.4         |\n",
      "|    std_reward           | 2.85         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 920000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069247126 |\n",
      "|    clip_fraction        | 0.203        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.84        |\n",
      "|    explained_variance   | 0.993        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0146       |\n",
      "|    n_updates            | 2240         |\n",
      "|    policy_gradient_loss | -0.0135      |\n",
      "|    value_loss           | 0.182        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.2     |\n",
      "|    ep_rew_mean     | 41.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 225      |\n",
      "|    time_elapsed    | 2280     |\n",
      "|    total_timesteps | 921600   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 77.5         |\n",
      "|    ep_rew_mean          | 41.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 226          |\n",
      "|    time_elapsed         | 2290         |\n",
      "|    total_timesteps      | 925696       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072779967 |\n",
      "|    clip_fraction        | 0.229        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.86        |\n",
      "|    explained_variance   | 0.994        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00391     |\n",
      "|    n_updates            | 2250         |\n",
      "|    policy_gradient_loss | -0.0131      |\n",
      "|    value_loss           | 0.149        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.1        |\n",
      "|    ep_rew_mean          | 41.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 227         |\n",
      "|    time_elapsed         | 2299        |\n",
      "|    total_timesteps      | 929792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007260176 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.86       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0202      |\n",
      "|    n_updates            | 2260        |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 0.185       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=930000, episode_reward=42.69 +/- 7.05\n",
      "Episode length: 77.10 +/- 9.33\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 77.1         |\n",
      "|    mean_reward          | 42.7         |\n",
      "|    std_reward           | 7.05         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 930000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076623755 |\n",
      "|    clip_fraction        | 0.19         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.8         |\n",
      "|    explained_variance   | 0.992        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00155     |\n",
      "|    n_updates            | 2270         |\n",
      "|    policy_gradient_loss | -0.0125      |\n",
      "|    value_loss           | 0.191        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.4     |\n",
      "|    ep_rew_mean     | 41.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 228      |\n",
      "|    time_elapsed    | 2310     |\n",
      "|    total_timesteps | 933888   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.4        |\n",
      "|    ep_rew_mean          | 43.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 229         |\n",
      "|    time_elapsed         | 2320        |\n",
      "|    total_timesteps      | 937984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006163212 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.81       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00292     |\n",
      "|    n_updates            | 2280        |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    value_loss           | 0.188       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=940000, episode_reward=40.78 +/- 6.10\n",
      "Episode length: 79.70 +/- 6.54\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 79.7         |\n",
      "|    mean_reward          | 40.8         |\n",
      "|    std_reward           | 6.1          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 940000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064667747 |\n",
      "|    clip_fraction        | 0.204        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.8         |\n",
      "|    explained_variance   | 0.994        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0231       |\n",
      "|    n_updates            | 2290         |\n",
      "|    policy_gradient_loss | -0.014       |\n",
      "|    value_loss           | 0.182        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.4     |\n",
      "|    ep_rew_mean     | 43.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 230      |\n",
      "|    time_elapsed    | 2331     |\n",
      "|    total_timesteps | 942080   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.7        |\n",
      "|    ep_rew_mean          | 43.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 231         |\n",
      "|    time_elapsed         | 2340        |\n",
      "|    total_timesteps      | 946176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007457696 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.83       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00762    |\n",
      "|    n_updates            | 2300        |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    value_loss           | 0.157       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=950000, episode_reward=44.97 +/- 8.28\n",
      "Episode length: 72.10 +/- 11.21\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 72.1        |\n",
      "|    mean_reward          | 45          |\n",
      "|    std_reward           | 8.28        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 950000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007457166 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.77       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00208    |\n",
      "|    n_updates            | 2310        |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    value_loss           | 0.144       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.3     |\n",
      "|    ep_rew_mean     | 42.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 232      |\n",
      "|    time_elapsed    | 2351     |\n",
      "|    total_timesteps | 950272   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 76.8         |\n",
      "|    ep_rew_mean          | 42.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 233          |\n",
      "|    time_elapsed         | 2360         |\n",
      "|    total_timesteps      | 954368       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074033644 |\n",
      "|    clip_fraction        | 0.227        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.83        |\n",
      "|    explained_variance   | 0.993        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.00131      |\n",
      "|    n_updates            | 2320         |\n",
      "|    policy_gradient_loss | -0.0138      |\n",
      "|    value_loss           | 0.169        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78.1         |\n",
      "|    ep_rew_mean          | 42.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 234          |\n",
      "|    time_elapsed         | 2370         |\n",
      "|    total_timesteps      | 958464       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070444783 |\n",
      "|    clip_fraction        | 0.214        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.81        |\n",
      "|    explained_variance   | 0.995        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.00973      |\n",
      "|    n_updates            | 2330         |\n",
      "|    policy_gradient_loss | -0.0148      |\n",
      "|    value_loss           | 0.135        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=960000, episode_reward=42.30 +/- 3.38\n",
      "Episode length: 81.00 +/- 9.31\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 81          |\n",
      "|    mean_reward          | 42.3        |\n",
      "|    std_reward           | 3.38        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 960000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006930112 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.82       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00032    |\n",
      "|    n_updates            | 2340        |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    value_loss           | 0.141       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.6     |\n",
      "|    ep_rew_mean     | 42.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 235      |\n",
      "|    time_elapsed    | 2381     |\n",
      "|    total_timesteps | 962560   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 79           |\n",
      "|    ep_rew_mean          | 41.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 236          |\n",
      "|    time_elapsed         | 2391         |\n",
      "|    total_timesteps      | 966656       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066875834 |\n",
      "|    clip_fraction        | 0.226        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.83        |\n",
      "|    explained_variance   | 0.995        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.000395    |\n",
      "|    n_updates            | 2350         |\n",
      "|    policy_gradient_loss | -0.0145      |\n",
      "|    value_loss           | 0.143        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=970000, episode_reward=42.69 +/- 5.08\n",
      "Episode length: 80.80 +/- 7.39\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 80.8         |\n",
      "|    mean_reward          | 42.7         |\n",
      "|    std_reward           | 5.08         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 970000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066919224 |\n",
      "|    clip_fraction        | 0.228        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.85        |\n",
      "|    explained_variance   | 0.995        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.00346      |\n",
      "|    n_updates            | 2360         |\n",
      "|    policy_gradient_loss | -0.0169      |\n",
      "|    value_loss           | 0.148        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.8     |\n",
      "|    ep_rew_mean     | 42.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 237      |\n",
      "|    time_elapsed    | 2402     |\n",
      "|    total_timesteps | 970752   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.2        |\n",
      "|    ep_rew_mean          | 42.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 238         |\n",
      "|    time_elapsed         | 2411        |\n",
      "|    total_timesteps      | 974848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007422141 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.84       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0144      |\n",
      "|    n_updates            | 2370        |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    value_loss           | 0.141       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.1        |\n",
      "|    ep_rew_mean          | 42.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 239         |\n",
      "|    time_elapsed         | 2421        |\n",
      "|    total_timesteps      | 978944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008485678 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.84       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0102      |\n",
      "|    n_updates            | 2380        |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    value_loss           | 0.171       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=980000, episode_reward=42.09 +/- 5.87\n",
      "Episode length: 78.40 +/- 6.73\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 78.4        |\n",
      "|    mean_reward          | 42.1        |\n",
      "|    std_reward           | 5.87        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 980000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008221203 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.8        |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00111    |\n",
      "|    n_updates            | 2390        |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    value_loss           | 0.146       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.4     |\n",
      "|    ep_rew_mean     | 42.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 240      |\n",
      "|    time_elapsed    | 2432     |\n",
      "|    total_timesteps | 983040   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.4        |\n",
      "|    ep_rew_mean          | 41.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 241         |\n",
      "|    time_elapsed         | 2441        |\n",
      "|    total_timesteps      | 987136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007020065 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.85       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00588    |\n",
      "|    n_updates            | 2400        |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    value_loss           | 0.151       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=990000, episode_reward=42.81 +/- 7.56\n",
      "Episode length: 78.70 +/- 3.74\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 78.7         |\n",
      "|    mean_reward          | 42.8         |\n",
      "|    std_reward           | 7.56         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 990000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059206565 |\n",
      "|    clip_fraction        | 0.201        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.83        |\n",
      "|    explained_variance   | 0.989        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0177       |\n",
      "|    n_updates            | 2410         |\n",
      "|    policy_gradient_loss | -0.0152      |\n",
      "|    value_loss           | 0.281        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 76.9     |\n",
      "|    ep_rew_mean     | 41.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 242      |\n",
      "|    time_elapsed    | 2452     |\n",
      "|    total_timesteps | 991232   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 77.1         |\n",
      "|    ep_rew_mean          | 42.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 243          |\n",
      "|    time_elapsed         | 2462         |\n",
      "|    total_timesteps      | 995328       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065313373 |\n",
      "|    clip_fraction        | 0.229        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.79        |\n",
      "|    explained_variance   | 0.994        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0123       |\n",
      "|    n_updates            | 2420         |\n",
      "|    policy_gradient_loss | -0.0146      |\n",
      "|    value_loss           | 0.161        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.5        |\n",
      "|    ep_rew_mean          | 42.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 244         |\n",
      "|    time_elapsed         | 2471        |\n",
      "|    total_timesteps      | 999424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006891349 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.8        |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00775     |\n",
      "|    n_updates            | 2430        |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 0.155       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1000000, episode_reward=45.26 +/- 6.67\n",
      "Episode length: 74.60 +/- 9.53\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 74.6        |\n",
      "|    mean_reward          | 45.3        |\n",
      "|    std_reward           | 6.67        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1000000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007866481 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.78       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00344     |\n",
      "|    n_updates            | 2440        |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 0.174       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77       |\n",
      "|    ep_rew_mean     | 43.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 245      |\n",
      "|    time_elapsed    | 2482     |\n",
      "|    total_timesteps | 1003520  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.8        |\n",
      "|    ep_rew_mean          | 42.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 246         |\n",
      "|    time_elapsed         | 2492        |\n",
      "|    total_timesteps      | 1007616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006193764 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.78       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00566     |\n",
      "|    n_updates            | 2450        |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    value_loss           | 0.19        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1010000, episode_reward=40.16 +/- 7.98\n",
      "Episode length: 80.40 +/- 6.28\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 80.4        |\n",
      "|    mean_reward          | 40.2        |\n",
      "|    std_reward           | 7.98        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1010000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006576473 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.78       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00982     |\n",
      "|    n_updates            | 2460        |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    value_loss           | 0.188       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78       |\n",
      "|    ep_rew_mean     | 42.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 247      |\n",
      "|    time_elapsed    | 2503     |\n",
      "|    total_timesteps | 1011712  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 77.1         |\n",
      "|    ep_rew_mean          | 42.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 248          |\n",
      "|    time_elapsed         | 2512         |\n",
      "|    total_timesteps      | 1015808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060385456 |\n",
      "|    clip_fraction        | 0.198        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.82        |\n",
      "|    explained_variance   | 0.993        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.00516      |\n",
      "|    n_updates            | 2470         |\n",
      "|    policy_gradient_loss | -0.0133      |\n",
      "|    value_loss           | 0.222        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.8        |\n",
      "|    ep_rew_mean          | 42          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 249         |\n",
      "|    time_elapsed         | 2522        |\n",
      "|    total_timesteps      | 1019904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008703135 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.79       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.011       |\n",
      "|    n_updates            | 2480        |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    value_loss           | 0.17        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1020000, episode_reward=44.58 +/- 10.23\n",
      "Episode length: 75.50 +/- 19.02\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 75.5        |\n",
      "|    mean_reward          | 44.6        |\n",
      "|    std_reward           | 10.2        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1020000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007615378 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.81       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0316      |\n",
      "|    n_updates            | 2490        |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    value_loss           | 0.187       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.8     |\n",
      "|    ep_rew_mean     | 42.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 250      |\n",
      "|    time_elapsed    | 2533     |\n",
      "|    total_timesteps | 1024000  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.3        |\n",
      "|    ep_rew_mean          | 41.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 251         |\n",
      "|    time_elapsed         | 2543        |\n",
      "|    total_timesteps      | 1028096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007809847 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.79       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00101    |\n",
      "|    n_updates            | 2500        |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 0.177       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1030000, episode_reward=40.71 +/- 5.66\n",
      "Episode length: 83.10 +/- 7.65\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 83.1        |\n",
      "|    mean_reward          | 40.7        |\n",
      "|    std_reward           | 5.66        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1030000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008868846 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.8        |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00279     |\n",
      "|    n_updates            | 2510        |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 0.176       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.3     |\n",
      "|    ep_rew_mean     | 41.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 252      |\n",
      "|    time_elapsed    | 2554     |\n",
      "|    total_timesteps | 1032192  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 77.7         |\n",
      "|    ep_rew_mean          | 42.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 253          |\n",
      "|    time_elapsed         | 2563         |\n",
      "|    total_timesteps      | 1036288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074870335 |\n",
      "|    clip_fraction        | 0.216        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.8         |\n",
      "|    explained_variance   | 0.993        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0112       |\n",
      "|    n_updates            | 2520         |\n",
      "|    policy_gradient_loss | -0.016       |\n",
      "|    value_loss           | 0.193        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1040000, episode_reward=40.70 +/- 6.64\n",
      "Episode length: 76.40 +/- 10.86\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 76.4       |\n",
      "|    mean_reward          | 40.7       |\n",
      "|    std_reward           | 6.64       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1040000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00811976 |\n",
      "|    clip_fraction        | 0.207      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.75      |\n",
      "|    explained_variance   | 0.993      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.00155   |\n",
      "|    n_updates            | 2530       |\n",
      "|    policy_gradient_loss | -0.0133    |\n",
      "|    value_loss           | 0.192      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.2     |\n",
      "|    ep_rew_mean     | 42.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 254      |\n",
      "|    time_elapsed    | 2574     |\n",
      "|    total_timesteps | 1040384  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.7        |\n",
      "|    ep_rew_mean          | 42.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 255         |\n",
      "|    time_elapsed         | 2584        |\n",
      "|    total_timesteps      | 1044480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008865943 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.77       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0121      |\n",
      "|    n_updates            | 2540        |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    value_loss           | 0.148       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 80.1        |\n",
      "|    ep_rew_mean          | 42.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 256         |\n",
      "|    time_elapsed         | 2593        |\n",
      "|    total_timesteps      | 1048576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006709638 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.75       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.000665    |\n",
      "|    n_updates            | 2550        |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    value_loss           | 0.168       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1050000, episode_reward=38.37 +/- 7.19\n",
      "Episode length: 78.90 +/- 14.12\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 78.9        |\n",
      "|    mean_reward          | 38.4        |\n",
      "|    std_reward           | 7.19        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1050000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006355665 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.75       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.013       |\n",
      "|    n_updates            | 2560        |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    value_loss           | 0.15        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.6     |\n",
      "|    ep_rew_mean     | 42.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 257      |\n",
      "|    time_elapsed    | 2604     |\n",
      "|    total_timesteps | 1052672  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 77.3         |\n",
      "|    ep_rew_mean          | 43.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 258          |\n",
      "|    time_elapsed         | 2614         |\n",
      "|    total_timesteps      | 1056768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076863235 |\n",
      "|    clip_fraction        | 0.202        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.72        |\n",
      "|    explained_variance   | 0.994        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0127       |\n",
      "|    n_updates            | 2570         |\n",
      "|    policy_gradient_loss | -0.0149      |\n",
      "|    value_loss           | 0.169        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1060000, episode_reward=44.19 +/- 4.02\n",
      "Episode length: 74.00 +/- 8.04\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 74           |\n",
      "|    mean_reward          | 44.2         |\n",
      "|    std_reward           | 4.02         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1060000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070850817 |\n",
      "|    clip_fraction        | 0.234        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.75        |\n",
      "|    explained_variance   | 0.995        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0152       |\n",
      "|    n_updates            | 2580         |\n",
      "|    policy_gradient_loss | -0.0145      |\n",
      "|    value_loss           | 0.156        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.6     |\n",
      "|    ep_rew_mean     | 42.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 259      |\n",
      "|    time_elapsed    | 2625     |\n",
      "|    total_timesteps | 1060864  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78.3         |\n",
      "|    ep_rew_mean          | 41.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 260          |\n",
      "|    time_elapsed         | 2634         |\n",
      "|    total_timesteps      | 1064960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067185108 |\n",
      "|    clip_fraction        | 0.209        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.8         |\n",
      "|    explained_variance   | 0.993        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.000793     |\n",
      "|    n_updates            | 2590         |\n",
      "|    policy_gradient_loss | -0.0143      |\n",
      "|    value_loss           | 0.19         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 80.2         |\n",
      "|    ep_rew_mean          | 40.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 261          |\n",
      "|    time_elapsed         | 2644         |\n",
      "|    total_timesteps      | 1069056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067136204 |\n",
      "|    clip_fraction        | 0.225        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.79        |\n",
      "|    explained_variance   | 0.992        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0276       |\n",
      "|    n_updates            | 2600         |\n",
      "|    policy_gradient_loss | -0.0125      |\n",
      "|    value_loss           | 0.206        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1070000, episode_reward=43.55 +/- 4.22\n",
      "Episode length: 77.20 +/- 4.71\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 77.2         |\n",
      "|    mean_reward          | 43.6         |\n",
      "|    std_reward           | 4.22         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1070000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064878147 |\n",
      "|    clip_fraction        | 0.202        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.75        |\n",
      "|    explained_variance   | 0.993        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0107      |\n",
      "|    n_updates            | 2610         |\n",
      "|    policy_gradient_loss | -0.0138      |\n",
      "|    value_loss           | 0.18         |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.5     |\n",
      "|    ep_rew_mean     | 42.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 262      |\n",
      "|    time_elapsed    | 2655     |\n",
      "|    total_timesteps | 1073152  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 77.9         |\n",
      "|    ep_rew_mean          | 43           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 263          |\n",
      "|    time_elapsed         | 2665         |\n",
      "|    total_timesteps      | 1077248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076473365 |\n",
      "|    clip_fraction        | 0.227        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.78        |\n",
      "|    explained_variance   | 0.995        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00168     |\n",
      "|    n_updates            | 2620         |\n",
      "|    policy_gradient_loss | -0.0169      |\n",
      "|    value_loss           | 0.143        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1080000, episode_reward=38.02 +/- 9.67\n",
      "Episode length: 82.40 +/- 7.86\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 82.4        |\n",
      "|    mean_reward          | 38          |\n",
      "|    std_reward           | 9.67        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1080000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007966883 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.76       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00547     |\n",
      "|    n_updates            | 2630        |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    value_loss           | 0.192       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78       |\n",
      "|    ep_rew_mean     | 42.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 264      |\n",
      "|    time_elapsed    | 2675     |\n",
      "|    total_timesteps | 1081344  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.6        |\n",
      "|    ep_rew_mean          | 42.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 265         |\n",
      "|    time_elapsed         | 2685        |\n",
      "|    total_timesteps      | 1085440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008198961 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.78       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00592    |\n",
      "|    n_updates            | 2640        |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    value_loss           | 0.158       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.1        |\n",
      "|    ep_rew_mean          | 42.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 266         |\n",
      "|    time_elapsed         | 2695        |\n",
      "|    total_timesteps      | 1089536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007201517 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.76       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0159      |\n",
      "|    n_updates            | 2650        |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    value_loss           | 0.17        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1090000, episode_reward=41.84 +/- 6.26\n",
      "Episode length: 77.40 +/- 10.30\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 77.4        |\n",
      "|    mean_reward          | 41.8        |\n",
      "|    std_reward           | 6.26        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1090000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009056963 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.8        |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00836     |\n",
      "|    n_updates            | 2660        |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 0.184       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.2     |\n",
      "|    ep_rew_mean     | 42.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 267      |\n",
      "|    time_elapsed    | 2705     |\n",
      "|    total_timesteps | 1093632  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.4        |\n",
      "|    ep_rew_mean          | 42.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 268         |\n",
      "|    time_elapsed         | 2715        |\n",
      "|    total_timesteps      | 1097728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007762268 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.77       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00599    |\n",
      "|    n_updates            | 2670        |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    value_loss           | 0.133       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1100000, episode_reward=40.15 +/- 8.60\n",
      "Episode length: 81.50 +/- 6.42\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 81.5       |\n",
      "|    mean_reward          | 40.2       |\n",
      "|    std_reward           | 8.6        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1100000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00869905 |\n",
      "|    clip_fraction        | 0.248      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.79      |\n",
      "|    explained_variance   | 0.995      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.00904   |\n",
      "|    n_updates            | 2680       |\n",
      "|    policy_gradient_loss | -0.0156    |\n",
      "|    value_loss           | 0.133      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.1     |\n",
      "|    ep_rew_mean     | 43.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 269      |\n",
      "|    time_elapsed    | 2726     |\n",
      "|    total_timesteps | 1101824  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.2        |\n",
      "|    ep_rew_mean          | 43.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 270         |\n",
      "|    time_elapsed         | 2735        |\n",
      "|    total_timesteps      | 1105920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006392582 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.72       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00319     |\n",
      "|    n_updates            | 2690        |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 0.156       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1110000, episode_reward=42.92 +/- 6.41\n",
      "Episode length: 75.50 +/- 11.79\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 75.5         |\n",
      "|    mean_reward          | 42.9         |\n",
      "|    std_reward           | 6.41         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1110000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068112714 |\n",
      "|    clip_fraction        | 0.209        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.78        |\n",
      "|    explained_variance   | 0.994        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.00283      |\n",
      "|    n_updates            | 2700         |\n",
      "|    policy_gradient_loss | -0.015       |\n",
      "|    value_loss           | 0.178        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.1     |\n",
      "|    ep_rew_mean     | 43       |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 271      |\n",
      "|    time_elapsed    | 2746     |\n",
      "|    total_timesteps | 1110016  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 77.4         |\n",
      "|    ep_rew_mean          | 43.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 272          |\n",
      "|    time_elapsed         | 2755         |\n",
      "|    total_timesteps      | 1114112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077263825 |\n",
      "|    clip_fraction        | 0.232        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.75        |\n",
      "|    explained_variance   | 0.995        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.00535      |\n",
      "|    n_updates            | 2710         |\n",
      "|    policy_gradient_loss | -0.0153      |\n",
      "|    value_loss           | 0.148        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 77           |\n",
      "|    ep_rew_mean          | 43.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 273          |\n",
      "|    time_elapsed         | 2765         |\n",
      "|    total_timesteps      | 1118208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0080483835 |\n",
      "|    clip_fraction        | 0.215        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.75        |\n",
      "|    explained_variance   | 0.994        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.00683      |\n",
      "|    n_updates            | 2720         |\n",
      "|    policy_gradient_loss | -0.0153      |\n",
      "|    value_loss           | 0.167        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1120000, episode_reward=46.43 +/- 5.67\n",
      "Episode length: 74.00 +/- 8.47\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 74          |\n",
      "|    mean_reward          | 46.4        |\n",
      "|    std_reward           | 5.67        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1120000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008202754 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.72       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00318    |\n",
      "|    n_updates            | 2730        |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    value_loss           | 0.166       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.2     |\n",
      "|    ep_rew_mean     | 42.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 274      |\n",
      "|    time_elapsed    | 2776     |\n",
      "|    total_timesteps | 1122304  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.2        |\n",
      "|    ep_rew_mean          | 41.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 275         |\n",
      "|    time_elapsed         | 2785        |\n",
      "|    total_timesteps      | 1126400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007427068 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.72       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.01        |\n",
      "|    n_updates            | 2740        |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    value_loss           | 0.171       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1130000, episode_reward=40.37 +/- 4.95\n",
      "Episode length: 79.00 +/- 9.79\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 79           |\n",
      "|    mean_reward          | 40.4         |\n",
      "|    std_reward           | 4.95         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1130000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075596757 |\n",
      "|    clip_fraction        | 0.233        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.72        |\n",
      "|    explained_variance   | 0.994        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0112       |\n",
      "|    n_updates            | 2750         |\n",
      "|    policy_gradient_loss | -0.0175      |\n",
      "|    value_loss           | 0.174        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.5     |\n",
      "|    ep_rew_mean     | 42.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 276      |\n",
      "|    time_elapsed    | 2796     |\n",
      "|    total_timesteps | 1130496  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.7        |\n",
      "|    ep_rew_mean          | 43          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 277         |\n",
      "|    time_elapsed         | 2806        |\n",
      "|    total_timesteps      | 1134592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007965108 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.73       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00196    |\n",
      "|    n_updates            | 2760        |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    value_loss           | 0.192       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 79.1         |\n",
      "|    ep_rew_mean          | 43           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 278          |\n",
      "|    time_elapsed         | 2816         |\n",
      "|    total_timesteps      | 1138688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074837953 |\n",
      "|    clip_fraction        | 0.227        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.69        |\n",
      "|    explained_variance   | 0.994        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.000795     |\n",
      "|    n_updates            | 2770         |\n",
      "|    policy_gradient_loss | -0.0133      |\n",
      "|    value_loss           | 0.151        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1140000, episode_reward=39.59 +/- 5.45\n",
      "Episode length: 79.80 +/- 9.43\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 79.8        |\n",
      "|    mean_reward          | 39.6        |\n",
      "|    std_reward           | 5.45        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1140000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008512529 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.73       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00252    |\n",
      "|    n_updates            | 2780        |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    value_loss           | 0.174       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79       |\n",
      "|    ep_rew_mean     | 42.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 279      |\n",
      "|    time_elapsed    | 2826     |\n",
      "|    total_timesteps | 1142784  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.1        |\n",
      "|    ep_rew_mean          | 43.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 280         |\n",
      "|    time_elapsed         | 2836        |\n",
      "|    total_timesteps      | 1146880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006562683 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.68       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.000176   |\n",
      "|    n_updates            | 2790        |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    value_loss           | 0.18        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1150000, episode_reward=42.76 +/- 4.70\n",
      "Episode length: 81.70 +/- 7.36\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 81.7         |\n",
      "|    mean_reward          | 42.8         |\n",
      "|    std_reward           | 4.7          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1150000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073056603 |\n",
      "|    clip_fraction        | 0.216        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.71        |\n",
      "|    explained_variance   | 0.994        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00239     |\n",
      "|    n_updates            | 2800         |\n",
      "|    policy_gradient_loss | -0.0158      |\n",
      "|    value_loss           | 0.168        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.2     |\n",
      "|    ep_rew_mean     | 43.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 281      |\n",
      "|    time_elapsed    | 2847     |\n",
      "|    total_timesteps | 1150976  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78.2         |\n",
      "|    ep_rew_mean          | 43.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 282          |\n",
      "|    time_elapsed         | 2856         |\n",
      "|    total_timesteps      | 1155072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076596425 |\n",
      "|    clip_fraction        | 0.248        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.7         |\n",
      "|    explained_variance   | 0.995        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.00242      |\n",
      "|    n_updates            | 2810         |\n",
      "|    policy_gradient_loss | -0.0147      |\n",
      "|    value_loss           | 0.168        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.3        |\n",
      "|    ep_rew_mean          | 43.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 283         |\n",
      "|    time_elapsed         | 2866        |\n",
      "|    total_timesteps      | 1159168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007776259 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.7        |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.000311    |\n",
      "|    n_updates            | 2820        |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 0.202       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1160000, episode_reward=40.15 +/- 5.44\n",
      "Episode length: 77.90 +/- 5.43\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 77.9        |\n",
      "|    mean_reward          | 40.2        |\n",
      "|    std_reward           | 5.44        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1160000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008188985 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.7        |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.000752   |\n",
      "|    n_updates            | 2830        |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    value_loss           | 0.169       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 76.8     |\n",
      "|    ep_rew_mean     | 43.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 284      |\n",
      "|    time_elapsed    | 2877     |\n",
      "|    total_timesteps | 1163264  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.1        |\n",
      "|    ep_rew_mean          | 44.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 285         |\n",
      "|    time_elapsed         | 2886        |\n",
      "|    total_timesteps      | 1167360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008385226 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.69       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -3.49e-05   |\n",
      "|    n_updates            | 2840        |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    value_loss           | 0.171       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1170000, episode_reward=41.16 +/- 7.07\n",
      "Episode length: 77.50 +/- 9.72\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 77.5        |\n",
      "|    mean_reward          | 41.2        |\n",
      "|    std_reward           | 7.07        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1170000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007861484 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.68       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.000242   |\n",
      "|    n_updates            | 2850        |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    value_loss           | 0.176       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 76.3     |\n",
      "|    ep_rew_mean     | 43.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 286      |\n",
      "|    time_elapsed    | 2897     |\n",
      "|    total_timesteps | 1171456  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.3        |\n",
      "|    ep_rew_mean          | 44.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 287         |\n",
      "|    time_elapsed         | 2906        |\n",
      "|    total_timesteps      | 1175552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008515244 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.69       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0026      |\n",
      "|    n_updates            | 2860        |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 0.156       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.6        |\n",
      "|    ep_rew_mean          | 44.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 288         |\n",
      "|    time_elapsed         | 2916        |\n",
      "|    total_timesteps      | 1179648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007368699 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.67       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00108     |\n",
      "|    n_updates            | 2870        |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 0.178       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1180000, episode_reward=43.17 +/- 6.45\n",
      "Episode length: 77.30 +/- 12.69\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 77.3        |\n",
      "|    mean_reward          | 43.2        |\n",
      "|    std_reward           | 6.45        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1180000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008079849 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.7        |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00038     |\n",
      "|    n_updates            | 2880        |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    value_loss           | 0.174       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.3     |\n",
      "|    ep_rew_mean     | 43.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 289      |\n",
      "|    time_elapsed    | 2927     |\n",
      "|    total_timesteps | 1183744  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.3        |\n",
      "|    ep_rew_mean          | 43.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 290         |\n",
      "|    time_elapsed         | 2937        |\n",
      "|    total_timesteps      | 1187840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009586766 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.71       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0183      |\n",
      "|    n_updates            | 2890        |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    value_loss           | 0.135       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1190000, episode_reward=46.20 +/- 5.15\n",
      "Episode length: 70.70 +/- 10.37\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 70.7         |\n",
      "|    mean_reward          | 46.2         |\n",
      "|    std_reward           | 5.15         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1190000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077304677 |\n",
      "|    clip_fraction        | 0.254        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.67        |\n",
      "|    explained_variance   | 0.996        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00655     |\n",
      "|    n_updates            | 2900         |\n",
      "|    policy_gradient_loss | -0.0139      |\n",
      "|    value_loss           | 0.126        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.8     |\n",
      "|    ep_rew_mean     | 43.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 291      |\n",
      "|    time_elapsed    | 2947     |\n",
      "|    total_timesteps | 1191936  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78.1         |\n",
      "|    ep_rew_mean          | 43.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 292          |\n",
      "|    time_elapsed         | 2957         |\n",
      "|    total_timesteps      | 1196032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0093332995 |\n",
      "|    clip_fraction        | 0.264        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.68        |\n",
      "|    explained_variance   | 0.996        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00272     |\n",
      "|    n_updates            | 2910         |\n",
      "|    policy_gradient_loss | -0.0157      |\n",
      "|    value_loss           | 0.14         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1200000, episode_reward=42.05 +/- 4.23\n",
      "Episode length: 75.70 +/- 13.56\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 75.7         |\n",
      "|    mean_reward          | 42.1         |\n",
      "|    std_reward           | 4.23         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1200000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077880546 |\n",
      "|    clip_fraction        | 0.233        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.68        |\n",
      "|    explained_variance   | 0.994        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.00267      |\n",
      "|    n_updates            | 2920         |\n",
      "|    policy_gradient_loss | -0.014       |\n",
      "|    value_loss           | 0.168        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79       |\n",
      "|    ep_rew_mean     | 43.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 293      |\n",
      "|    time_elapsed    | 2968     |\n",
      "|    total_timesteps | 1200128  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.1        |\n",
      "|    ep_rew_mean          | 43.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 294         |\n",
      "|    time_elapsed         | 2978        |\n",
      "|    total_timesteps      | 1204224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008130627 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.68       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0066      |\n",
      "|    n_updates            | 2930        |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    value_loss           | 0.185       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.4        |\n",
      "|    ep_rew_mean          | 43.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 295         |\n",
      "|    time_elapsed         | 2987        |\n",
      "|    total_timesteps      | 1208320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007666347 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.67       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00885     |\n",
      "|    n_updates            | 2940        |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    value_loss           | 0.157       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1210000, episode_reward=41.18 +/- 7.59\n",
      "Episode length: 79.30 +/- 8.05\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 79.3         |\n",
      "|    mean_reward          | 41.2         |\n",
      "|    std_reward           | 7.59         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1210000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068214936 |\n",
      "|    clip_fraction        | 0.202        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.66        |\n",
      "|    explained_variance   | 0.993        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00696     |\n",
      "|    n_updates            | 2950         |\n",
      "|    policy_gradient_loss | -0.014       |\n",
      "|    value_loss           | 0.186        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.1     |\n",
      "|    ep_rew_mean     | 44.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 296      |\n",
      "|    time_elapsed    | 2998     |\n",
      "|    total_timesteps | 1212416  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 80.1         |\n",
      "|    ep_rew_mean          | 43.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 297          |\n",
      "|    time_elapsed         | 3008         |\n",
      "|    total_timesteps      | 1216512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075635007 |\n",
      "|    clip_fraction        | 0.235        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.65        |\n",
      "|    explained_variance   | 0.994        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0187       |\n",
      "|    n_updates            | 2960         |\n",
      "|    policy_gradient_loss | -0.016       |\n",
      "|    value_loss           | 0.148        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1220000, episode_reward=44.81 +/- 6.91\n",
      "Episode length: 75.20 +/- 6.94\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 75.2        |\n",
      "|    mean_reward          | 44.8        |\n",
      "|    std_reward           | 6.91        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1220000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009040687 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.71       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00356     |\n",
      "|    n_updates            | 2970        |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    value_loss           | 0.131       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79       |\n",
      "|    ep_rew_mean     | 43.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 298      |\n",
      "|    time_elapsed    | 3018     |\n",
      "|    total_timesteps | 1220608  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78.5         |\n",
      "|    ep_rew_mean          | 44.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 299          |\n",
      "|    time_elapsed         | 3028         |\n",
      "|    total_timesteps      | 1224704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074240514 |\n",
      "|    clip_fraction        | 0.218        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.66        |\n",
      "|    explained_variance   | 0.994        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.00145      |\n",
      "|    n_updates            | 2980         |\n",
      "|    policy_gradient_loss | -0.0145      |\n",
      "|    value_loss           | 0.163        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.9        |\n",
      "|    ep_rew_mean          | 44.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 300         |\n",
      "|    time_elapsed         | 3038        |\n",
      "|    total_timesteps      | 1228800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007996779 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.67       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.172       |\n",
      "|    n_updates            | 2990        |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 0.167       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1230000, episode_reward=41.83 +/- 4.09\n",
      "Episode length: 81.70 +/- 7.89\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 81.7        |\n",
      "|    mean_reward          | 41.8        |\n",
      "|    std_reward           | 4.09        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1230000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010562781 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.64       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.019       |\n",
      "|    n_updates            | 3000        |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    value_loss           | 0.128       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 76.6     |\n",
      "|    ep_rew_mean     | 44.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 301      |\n",
      "|    time_elapsed    | 3048     |\n",
      "|    total_timesteps | 1232896  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 75.8       |\n",
      "|    ep_rew_mean          | 44.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 404        |\n",
      "|    iterations           | 302        |\n",
      "|    time_elapsed         | 3058       |\n",
      "|    total_timesteps      | 1236992    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00882679 |\n",
      "|    clip_fraction        | 0.243      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.7       |\n",
      "|    explained_variance   | 0.995      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.00774   |\n",
      "|    n_updates            | 3010       |\n",
      "|    policy_gradient_loss | -0.0152    |\n",
      "|    value_loss           | 0.14       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1240000, episode_reward=41.53 +/- 5.52\n",
      "Episode length: 77.70 +/- 12.04\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 77.7         |\n",
      "|    mean_reward          | 41.5         |\n",
      "|    std_reward           | 5.52         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1240000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077401786 |\n",
      "|    clip_fraction        | 0.232        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.68        |\n",
      "|    explained_variance   | 0.995        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0122       |\n",
      "|    n_updates            | 3020         |\n",
      "|    policy_gradient_loss | -0.0152      |\n",
      "|    value_loss           | 0.147        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 76.6     |\n",
      "|    ep_rew_mean     | 44.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 303      |\n",
      "|    time_elapsed    | 3069     |\n",
      "|    total_timesteps | 1241088  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.9        |\n",
      "|    ep_rew_mean          | 43.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 304         |\n",
      "|    time_elapsed         | 3079        |\n",
      "|    total_timesteps      | 1245184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009241017 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.72       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00584     |\n",
      "|    n_updates            | 3030        |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    value_loss           | 0.17        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.5        |\n",
      "|    ep_rew_mean          | 43.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 305         |\n",
      "|    time_elapsed         | 3088        |\n",
      "|    total_timesteps      | 1249280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008503561 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.7        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.000915   |\n",
      "|    n_updates            | 3040        |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    value_loss           | 0.136       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1250000, episode_reward=40.21 +/- 4.98\n",
      "Episode length: 85.60 +/- 13.05\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 85.6        |\n",
      "|    mean_reward          | 40.2        |\n",
      "|    std_reward           | 4.98        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1250000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009997859 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.69       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0047      |\n",
      "|    n_updates            | 3050        |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 0.163       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.5     |\n",
      "|    ep_rew_mean     | 43.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 306      |\n",
      "|    time_elapsed    | 3099     |\n",
      "|    total_timesteps | 1253376  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.5        |\n",
      "|    ep_rew_mean          | 42.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 307         |\n",
      "|    time_elapsed         | 3109        |\n",
      "|    total_timesteps      | 1257472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008339789 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.71       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00551    |\n",
      "|    n_updates            | 3060        |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    value_loss           | 0.143       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1260000, episode_reward=41.48 +/- 5.89\n",
      "Episode length: 80.10 +/- 10.02\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 80.1        |\n",
      "|    mean_reward          | 41.5        |\n",
      "|    std_reward           | 5.89        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1260000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009660687 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.73       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00836    |\n",
      "|    n_updates            | 3070        |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    value_loss           | 0.138       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.1     |\n",
      "|    ep_rew_mean     | 43.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 308      |\n",
      "|    time_elapsed    | 3120     |\n",
      "|    total_timesteps | 1261568  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 77.3         |\n",
      "|    ep_rew_mean          | 43.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 309          |\n",
      "|    time_elapsed         | 3129         |\n",
      "|    total_timesteps      | 1265664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077072843 |\n",
      "|    clip_fraction        | 0.235        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.71        |\n",
      "|    explained_variance   | 0.994        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0132       |\n",
      "|    n_updates            | 3080         |\n",
      "|    policy_gradient_loss | -0.0141      |\n",
      "|    value_loss           | 0.16         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.9        |\n",
      "|    ep_rew_mean          | 43.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 310         |\n",
      "|    time_elapsed         | 3139        |\n",
      "|    total_timesteps      | 1269760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009297106 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.72       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0175      |\n",
      "|    n_updates            | 3090        |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    value_loss           | 0.156       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1270000, episode_reward=45.80 +/- 4.10\n",
      "Episode length: 77.40 +/- 9.98\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 77.4       |\n",
      "|    mean_reward          | 45.8       |\n",
      "|    std_reward           | 4.1        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1270000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00898811 |\n",
      "|    clip_fraction        | 0.258      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.72      |\n",
      "|    explained_variance   | 0.994      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | 0.000861   |\n",
      "|    n_updates            | 3100       |\n",
      "|    policy_gradient_loss | -0.016     |\n",
      "|    value_loss           | 0.158      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 76.4     |\n",
      "|    ep_rew_mean     | 43.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 311      |\n",
      "|    time_elapsed    | 3150     |\n",
      "|    total_timesteps | 1273856  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.5        |\n",
      "|    ep_rew_mean          | 42.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 312         |\n",
      "|    time_elapsed         | 3159        |\n",
      "|    total_timesteps      | 1277952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009440766 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.68       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00781     |\n",
      "|    n_updates            | 3110        |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    value_loss           | 0.159       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1280000, episode_reward=41.65 +/- 6.94\n",
      "Episode length: 75.50 +/- 7.58\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 75.5        |\n",
      "|    mean_reward          | 41.6        |\n",
      "|    std_reward           | 6.94        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1280000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008836638 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.67       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00957     |\n",
      "|    n_updates            | 3120        |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    value_loss           | 0.157       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.8     |\n",
      "|    ep_rew_mean     | 43.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 313      |\n",
      "|    time_elapsed    | 3170     |\n",
      "|    total_timesteps | 1282048  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 77.9         |\n",
      "|    ep_rew_mean          | 43.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 314          |\n",
      "|    time_elapsed         | 3180         |\n",
      "|    total_timesteps      | 1286144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0093373405 |\n",
      "|    clip_fraction        | 0.231        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.7         |\n",
      "|    explained_variance   | 0.994        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0188      |\n",
      "|    n_updates            | 3130         |\n",
      "|    policy_gradient_loss | -0.0154      |\n",
      "|    value_loss           | 0.149        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1290000, episode_reward=43.47 +/- 7.30\n",
      "Episode length: 76.80 +/- 6.87\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 76.8        |\n",
      "|    mean_reward          | 43.5        |\n",
      "|    std_reward           | 7.3         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1290000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009309899 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.68       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00825     |\n",
      "|    n_updates            | 3140        |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 0.151       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.2     |\n",
      "|    ep_rew_mean     | 43.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 315      |\n",
      "|    time_elapsed    | 3191     |\n",
      "|    total_timesteps | 1290240  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.2        |\n",
      "|    ep_rew_mean          | 43.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 316         |\n",
      "|    time_elapsed         | 3200        |\n",
      "|    total_timesteps      | 1294336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007558588 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.7        |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00279     |\n",
      "|    n_updates            | 3150        |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    value_loss           | 0.132       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 77.7         |\n",
      "|    ep_rew_mean          | 43           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 317          |\n",
      "|    time_elapsed         | 3210         |\n",
      "|    total_timesteps      | 1298432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076145236 |\n",
      "|    clip_fraction        | 0.233        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.68        |\n",
      "|    explained_variance   | 0.995        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00639     |\n",
      "|    n_updates            | 3160         |\n",
      "|    policy_gradient_loss | -0.0168      |\n",
      "|    value_loss           | 0.142        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1300000, episode_reward=45.47 +/- 4.49\n",
      "Episode length: 73.60 +/- 9.40\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 73.6         |\n",
      "|    mean_reward          | 45.5         |\n",
      "|    std_reward           | 4.49         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1300000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077440003 |\n",
      "|    clip_fraction        | 0.252        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.68        |\n",
      "|    explained_variance   | 0.994        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00196     |\n",
      "|    n_updates            | 3170         |\n",
      "|    policy_gradient_loss | -0.0151      |\n",
      "|    value_loss           | 0.162        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.3     |\n",
      "|    ep_rew_mean     | 43       |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 318      |\n",
      "|    time_elapsed    | 3221     |\n",
      "|    total_timesteps | 1302528  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.4        |\n",
      "|    ep_rew_mean          | 43.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 319         |\n",
      "|    time_elapsed         | 3230        |\n",
      "|    total_timesteps      | 1306624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008760789 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.66       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00093     |\n",
      "|    n_updates            | 3180        |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    value_loss           | 0.127       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1310000, episode_reward=45.56 +/- 4.44\n",
      "Episode length: 79.00 +/- 9.06\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 79          |\n",
      "|    mean_reward          | 45.6        |\n",
      "|    std_reward           | 4.44        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1310000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007511935 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.66       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00612    |\n",
      "|    n_updates            | 3190        |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    value_loss           | 0.123       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.1     |\n",
      "|    ep_rew_mean     | 43.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 320      |\n",
      "|    time_elapsed    | 3241     |\n",
      "|    total_timesteps | 1310720  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.4        |\n",
      "|    ep_rew_mean          | 44.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 321         |\n",
      "|    time_elapsed         | 3251        |\n",
      "|    total_timesteps      | 1314816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008671016 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.67       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00312    |\n",
      "|    n_updates            | 3200        |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    value_loss           | 0.158       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.3        |\n",
      "|    ep_rew_mean          | 44.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 322         |\n",
      "|    time_elapsed         | 3260        |\n",
      "|    total_timesteps      | 1318912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010161671 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.67       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.018       |\n",
      "|    n_updates            | 3210        |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    value_loss           | 0.136       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1320000, episode_reward=44.28 +/- 5.70\n",
      "Episode length: 73.40 +/- 10.58\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 73.4        |\n",
      "|    mean_reward          | 44.3        |\n",
      "|    std_reward           | 5.7         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1320000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009750636 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.66       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00918    |\n",
      "|    n_updates            | 3220        |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    value_loss           | 0.132       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.9     |\n",
      "|    ep_rew_mean     | 42.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 323      |\n",
      "|    time_elapsed    | 3271     |\n",
      "|    total_timesteps | 1323008  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79          |\n",
      "|    ep_rew_mean          | 42.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 324         |\n",
      "|    time_elapsed         | 3281        |\n",
      "|    total_timesteps      | 1327104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008831929 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.7        |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.000633   |\n",
      "|    n_updates            | 3230        |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    value_loss           | 0.156       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1330000, episode_reward=41.95 +/- 6.28\n",
      "Episode length: 79.10 +/- 11.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 79.1        |\n",
      "|    mean_reward          | 41.9        |\n",
      "|    std_reward           | 6.28        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1330000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008062668 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.69       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.011       |\n",
      "|    n_updates            | 3240        |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    value_loss           | 0.156       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78       |\n",
      "|    ep_rew_mean     | 44       |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 325      |\n",
      "|    time_elapsed    | 3292     |\n",
      "|    total_timesteps | 1331200  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.9        |\n",
      "|    ep_rew_mean          | 43.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 326         |\n",
      "|    time_elapsed         | 3301        |\n",
      "|    total_timesteps      | 1335296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007524101 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.68       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00206     |\n",
      "|    n_updates            | 3250        |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    value_loss           | 0.173       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.8        |\n",
      "|    ep_rew_mean          | 44.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 327         |\n",
      "|    time_elapsed         | 3311        |\n",
      "|    total_timesteps      | 1339392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009667289 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.71       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.000734    |\n",
      "|    n_updates            | 3260        |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    value_loss           | 0.129       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1340000, episode_reward=43.33 +/- 7.00\n",
      "Episode length: 78.60 +/- 11.54\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 78.6        |\n",
      "|    mean_reward          | 43.3        |\n",
      "|    std_reward           | 7           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1340000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009434327 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.66       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0276      |\n",
      "|    n_updates            | 3270        |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    value_loss           | 0.169       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.2     |\n",
      "|    ep_rew_mean     | 43.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 328      |\n",
      "|    time_elapsed    | 3322     |\n",
      "|    total_timesteps | 1343488  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.9        |\n",
      "|    ep_rew_mean          | 43.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 329         |\n",
      "|    time_elapsed         | 3331        |\n",
      "|    total_timesteps      | 1347584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009798171 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.67       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00827    |\n",
      "|    n_updates            | 3280        |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 0.148       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1350000, episode_reward=41.31 +/- 6.08\n",
      "Episode length: 80.90 +/- 6.70\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 80.9        |\n",
      "|    mean_reward          | 41.3        |\n",
      "|    std_reward           | 6.08        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1350000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010890774 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.65       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00565     |\n",
      "|    n_updates            | 3290        |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    value_loss           | 0.134       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.3     |\n",
      "|    ep_rew_mean     | 43.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 330      |\n",
      "|    time_elapsed    | 3342     |\n",
      "|    total_timesteps | 1351680  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.2        |\n",
      "|    ep_rew_mean          | 43.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 331         |\n",
      "|    time_elapsed         | 3352        |\n",
      "|    total_timesteps      | 1355776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008844501 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.64       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0129      |\n",
      "|    n_updates            | 3300        |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    value_loss           | 0.15        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.2        |\n",
      "|    ep_rew_mean          | 43.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 332         |\n",
      "|    time_elapsed         | 3362        |\n",
      "|    total_timesteps      | 1359872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008863806 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.67       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0029     |\n",
      "|    n_updates            | 3310        |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    value_loss           | 0.149       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1360000, episode_reward=40.48 +/- 4.94\n",
      "Episode length: 80.60 +/- 11.44\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 80.6         |\n",
      "|    mean_reward          | 40.5         |\n",
      "|    std_reward           | 4.94         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1360000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076176855 |\n",
      "|    clip_fraction        | 0.233        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.64        |\n",
      "|    explained_variance   | 0.994        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.00689      |\n",
      "|    n_updates            | 3320         |\n",
      "|    policy_gradient_loss | -0.0143      |\n",
      "|    value_loss           | 0.156        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.9     |\n",
      "|    ep_rew_mean     | 43.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 333      |\n",
      "|    time_elapsed    | 3373     |\n",
      "|    total_timesteps | 1363968  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.6        |\n",
      "|    ep_rew_mean          | 44.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 334         |\n",
      "|    time_elapsed         | 3382        |\n",
      "|    total_timesteps      | 1368064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006845656 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.62       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0142      |\n",
      "|    n_updates            | 3330        |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    value_loss           | 0.158       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1370000, episode_reward=42.93 +/- 3.28\n",
      "Episode length: 79.40 +/- 8.95\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 79.4        |\n",
      "|    mean_reward          | 42.9        |\n",
      "|    std_reward           | 3.28        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1370000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009884784 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.63       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00627    |\n",
      "|    n_updates            | 3340        |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    value_loss           | 0.132       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.1     |\n",
      "|    ep_rew_mean     | 43.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 335      |\n",
      "|    time_elapsed    | 3393     |\n",
      "|    total_timesteps | 1372160  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.7        |\n",
      "|    ep_rew_mean          | 44.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 336         |\n",
      "|    time_elapsed         | 3402        |\n",
      "|    total_timesteps      | 1376256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008549133 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.61       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00307    |\n",
      "|    n_updates            | 3350        |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 0.191       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1380000, episode_reward=41.82 +/- 5.59\n",
      "Episode length: 70.50 +/- 7.13\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 70.5        |\n",
      "|    mean_reward          | 41.8        |\n",
      "|    std_reward           | 5.59        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1380000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008241699 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.62       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.027       |\n",
      "|    n_updates            | 3360        |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 0.159       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.2     |\n",
      "|    ep_rew_mean     | 45.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 337      |\n",
      "|    time_elapsed    | 3413     |\n",
      "|    total_timesteps | 1380352  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78.9         |\n",
      "|    ep_rew_mean          | 44.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 338          |\n",
      "|    time_elapsed         | 3423         |\n",
      "|    total_timesteps      | 1384448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0089912135 |\n",
      "|    clip_fraction        | 0.258        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.62        |\n",
      "|    explained_variance   | 0.996        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0117       |\n",
      "|    n_updates            | 3370         |\n",
      "|    policy_gradient_loss | -0.0117      |\n",
      "|    value_loss           | 0.127        |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 78.4       |\n",
      "|    ep_rew_mean          | 44.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 404        |\n",
      "|    iterations           | 339        |\n",
      "|    time_elapsed         | 3432       |\n",
      "|    total_timesteps      | 1388544    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00916706 |\n",
      "|    clip_fraction        | 0.266      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.64      |\n",
      "|    explained_variance   | 0.995      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.00438   |\n",
      "|    n_updates            | 3380       |\n",
      "|    policy_gradient_loss | -0.0155    |\n",
      "|    value_loss           | 0.148      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1390000, episode_reward=44.70 +/- 3.96\n",
      "Episode length: 72.70 +/- 8.78\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 72.7        |\n",
      "|    mean_reward          | 44.7        |\n",
      "|    std_reward           | 3.96        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1390000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010311474 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.62       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0014     |\n",
      "|    n_updates            | 3390        |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    value_loss           | 0.126       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.5     |\n",
      "|    ep_rew_mean     | 44.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 340      |\n",
      "|    time_elapsed    | 3443     |\n",
      "|    total_timesteps | 1392640  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.2        |\n",
      "|    ep_rew_mean          | 44.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 341         |\n",
      "|    time_elapsed         | 3453        |\n",
      "|    total_timesteps      | 1396736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010486733 |\n",
      "|    clip_fraction        | 0.27        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.65       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00122    |\n",
      "|    n_updates            | 3400        |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    value_loss           | 0.144       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1400000, episode_reward=45.10 +/- 6.01\n",
      "Episode length: 75.50 +/- 8.70\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 75.5        |\n",
      "|    mean_reward          | 45.1        |\n",
      "|    std_reward           | 6.01        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1400000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013119796 |\n",
      "|    clip_fraction        | 0.302       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.64       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00304    |\n",
      "|    n_updates            | 3410        |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 0.117       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.5     |\n",
      "|    ep_rew_mean     | 44.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 342      |\n",
      "|    time_elapsed    | 3464     |\n",
      "|    total_timesteps | 1400832  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.6        |\n",
      "|    ep_rew_mean          | 45          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 343         |\n",
      "|    time_elapsed         | 3474        |\n",
      "|    total_timesteps      | 1404928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008528139 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.64       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00802    |\n",
      "|    n_updates            | 3420        |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    value_loss           | 0.136       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.9        |\n",
      "|    ep_rew_mean          | 45.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 344         |\n",
      "|    time_elapsed         | 3483        |\n",
      "|    total_timesteps      | 1409024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008561172 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.65       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00929     |\n",
      "|    n_updates            | 3430        |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    value_loss           | 0.186       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1410000, episode_reward=42.34 +/- 6.64\n",
      "Episode length: 81.40 +/- 9.74\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 81.4         |\n",
      "|    mean_reward          | 42.3         |\n",
      "|    std_reward           | 6.64         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1410000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074936855 |\n",
      "|    clip_fraction        | 0.243        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.63        |\n",
      "|    explained_variance   | 0.996        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.00794      |\n",
      "|    n_updates            | 3440         |\n",
      "|    policy_gradient_loss | -0.0146      |\n",
      "|    value_loss           | 0.14         |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 76.3     |\n",
      "|    ep_rew_mean     | 45       |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 345      |\n",
      "|    time_elapsed    | 3494     |\n",
      "|    total_timesteps | 1413120  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.7        |\n",
      "|    ep_rew_mean          | 44.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 346         |\n",
      "|    time_elapsed         | 3504        |\n",
      "|    total_timesteps      | 1417216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009101648 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.67       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0124      |\n",
      "|    n_updates            | 3450        |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    value_loss           | 0.164       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1420000, episode_reward=44.51 +/- 5.12\n",
      "Episode length: 78.50 +/- 9.60\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 78.5        |\n",
      "|    mean_reward          | 44.5        |\n",
      "|    std_reward           | 5.12        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1420000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008591214 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.66       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00112    |\n",
      "|    n_updates            | 3460        |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    value_loss           | 0.148       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.7     |\n",
      "|    ep_rew_mean     | 44.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 347      |\n",
      "|    time_elapsed    | 3515     |\n",
      "|    total_timesteps | 1421312  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.2        |\n",
      "|    ep_rew_mean          | 45          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 348         |\n",
      "|    time_elapsed         | 3524        |\n",
      "|    total_timesteps      | 1425408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009188857 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.65       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0078     |\n",
      "|    n_updates            | 3470        |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    value_loss           | 0.131       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.2        |\n",
      "|    ep_rew_mean          | 43.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 349         |\n",
      "|    time_elapsed         | 3534        |\n",
      "|    total_timesteps      | 1429504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008058092 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.64       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00336    |\n",
      "|    n_updates            | 3480        |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    value_loss           | 0.138       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1430000, episode_reward=40.82 +/- 7.85\n",
      "Episode length: 81.10 +/- 10.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 81.1        |\n",
      "|    mean_reward          | 40.8        |\n",
      "|    std_reward           | 7.85        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1430000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010711016 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.65       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00405     |\n",
      "|    n_updates            | 3490        |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    value_loss           | 0.133       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.2     |\n",
      "|    ep_rew_mean     | 45       |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 350      |\n",
      "|    time_elapsed    | 3545     |\n",
      "|    total_timesteps | 1433600  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 76.8       |\n",
      "|    ep_rew_mean          | 45.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 404        |\n",
      "|    iterations           | 351        |\n",
      "|    time_elapsed         | 3554       |\n",
      "|    total_timesteps      | 1437696    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00997512 |\n",
      "|    clip_fraction        | 0.29       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.65      |\n",
      "|    explained_variance   | 0.996      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | 0.00519    |\n",
      "|    n_updates            | 3500       |\n",
      "|    policy_gradient_loss | -0.0153    |\n",
      "|    value_loss           | 0.125      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1440000, episode_reward=43.02 +/- 5.27\n",
      "Episode length: 81.80 +/- 12.38\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 81.8        |\n",
      "|    mean_reward          | 43          |\n",
      "|    std_reward           | 5.27        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1440000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008670641 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.65       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.000448   |\n",
      "|    n_updates            | 3510        |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    value_loss           | 0.119       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 76.9     |\n",
      "|    ep_rew_mean     | 44.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 352      |\n",
      "|    time_elapsed    | 3565     |\n",
      "|    total_timesteps | 1441792  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.5        |\n",
      "|    ep_rew_mean          | 45.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 353         |\n",
      "|    time_elapsed         | 3575        |\n",
      "|    total_timesteps      | 1445888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008382018 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.62       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0244      |\n",
      "|    n_updates            | 3520        |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    value_loss           | 0.131       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.4        |\n",
      "|    ep_rew_mean          | 45.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 354         |\n",
      "|    time_elapsed         | 3585        |\n",
      "|    total_timesteps      | 1449984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008976299 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.65       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0135     |\n",
      "|    n_updates            | 3530        |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    value_loss           | 0.125       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1450000, episode_reward=38.55 +/- 8.05\n",
      "Episode length: 81.00 +/- 12.92\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 81           |\n",
      "|    mean_reward          | 38.5         |\n",
      "|    std_reward           | 8.05         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1450000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072821947 |\n",
      "|    clip_fraction        | 0.245        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.65        |\n",
      "|    explained_variance   | 0.996        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.00162      |\n",
      "|    n_updates            | 3540         |\n",
      "|    policy_gradient_loss | -0.0139      |\n",
      "|    value_loss           | 0.135        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.7     |\n",
      "|    ep_rew_mean     | 45.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 355      |\n",
      "|    time_elapsed    | 3595     |\n",
      "|    total_timesteps | 1454080  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78.4         |\n",
      "|    ep_rew_mean          | 45.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 356          |\n",
      "|    time_elapsed         | 3605         |\n",
      "|    total_timesteps      | 1458176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0095196115 |\n",
      "|    clip_fraction        | 0.256        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.65        |\n",
      "|    explained_variance   | 0.996        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00365     |\n",
      "|    n_updates            | 3550         |\n",
      "|    policy_gradient_loss | -0.0145      |\n",
      "|    value_loss           | 0.138        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1460000, episode_reward=41.83 +/- 6.71\n",
      "Episode length: 79.80 +/- 10.24\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 79.8        |\n",
      "|    mean_reward          | 41.8        |\n",
      "|    std_reward           | 6.71        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1460000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009076156 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.65       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00352     |\n",
      "|    n_updates            | 3560        |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    value_loss           | 0.128       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.2     |\n",
      "|    ep_rew_mean     | 44.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 357      |\n",
      "|    time_elapsed    | 3616     |\n",
      "|    total_timesteps | 1462272  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.6        |\n",
      "|    ep_rew_mean          | 44.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 358         |\n",
      "|    time_elapsed         | 3626        |\n",
      "|    total_timesteps      | 1466368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008181328 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.66       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00923     |\n",
      "|    n_updates            | 3570        |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    value_loss           | 0.114       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1470000, episode_reward=39.90 +/- 7.20\n",
      "Episode length: 82.70 +/- 5.73\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 82.7        |\n",
      "|    mean_reward          | 39.9        |\n",
      "|    std_reward           | 7.2         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1470000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009572306 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.67       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0119      |\n",
      "|    n_updates            | 3580        |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    value_loss           | 0.153       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.2     |\n",
      "|    ep_rew_mean     | 44.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 359      |\n",
      "|    time_elapsed    | 3637     |\n",
      "|    total_timesteps | 1470464  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.4        |\n",
      "|    ep_rew_mean          | 44          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 360         |\n",
      "|    time_elapsed         | 3646        |\n",
      "|    total_timesteps      | 1474560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011404689 |\n",
      "|    clip_fraction        | 0.284       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.66       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00655    |\n",
      "|    n_updates            | 3590        |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 0.125       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.8        |\n",
      "|    ep_rew_mean          | 43.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 361         |\n",
      "|    time_elapsed         | 3656        |\n",
      "|    total_timesteps      | 1478656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010217695 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.66       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.000833    |\n",
      "|    n_updates            | 3600        |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    value_loss           | 0.143       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1480000, episode_reward=42.07 +/- 9.13\n",
      "Episode length: 77.60 +/- 9.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 77.6        |\n",
      "|    mean_reward          | 42.1        |\n",
      "|    std_reward           | 9.13        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1480000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009159072 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.67       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00678     |\n",
      "|    n_updates            | 3610        |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    value_loss           | 0.15        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.7     |\n",
      "|    ep_rew_mean     | 44.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 362      |\n",
      "|    time_elapsed    | 3667     |\n",
      "|    total_timesteps | 1482752  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 77.5         |\n",
      "|    ep_rew_mean          | 44.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 363          |\n",
      "|    time_elapsed         | 3676         |\n",
      "|    total_timesteps      | 1486848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075374204 |\n",
      "|    clip_fraction        | 0.261        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.67        |\n",
      "|    explained_variance   | 0.995        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0124       |\n",
      "|    n_updates            | 3620         |\n",
      "|    policy_gradient_loss | -0.0148      |\n",
      "|    value_loss           | 0.157        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1490000, episode_reward=41.14 +/- 5.42\n",
      "Episode length: 77.70 +/- 5.76\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 77.7       |\n",
      "|    mean_reward          | 41.1       |\n",
      "|    std_reward           | 5.42       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1490000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00862748 |\n",
      "|    clip_fraction        | 0.265      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.66      |\n",
      "|    explained_variance   | 0.995      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.00361   |\n",
      "|    n_updates            | 3630       |\n",
      "|    policy_gradient_loss | -0.0149    |\n",
      "|    value_loss           | 0.158      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.1     |\n",
      "|    ep_rew_mean     | 45.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 364      |\n",
      "|    time_elapsed    | 3687     |\n",
      "|    total_timesteps | 1490944  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.1        |\n",
      "|    ep_rew_mean          | 45.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 365         |\n",
      "|    time_elapsed         | 3697        |\n",
      "|    total_timesteps      | 1495040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010181826 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.65       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.016       |\n",
      "|    n_updates            | 3640        |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    value_loss           | 0.142       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.6        |\n",
      "|    ep_rew_mean          | 45.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 366         |\n",
      "|    time_elapsed         | 3706        |\n",
      "|    total_timesteps      | 1499136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009983441 |\n",
      "|    clip_fraction        | 0.284       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.65       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0103     |\n",
      "|    n_updates            | 3650        |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    value_loss           | 0.114       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1500000, episode_reward=44.02 +/- 4.77\n",
      "Episode length: 78.20 +/- 9.82\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 78.2        |\n",
      "|    mean_reward          | 44          |\n",
      "|    std_reward           | 4.77        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1500000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009828715 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.64       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00532    |\n",
      "|    n_updates            | 3660        |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 0.158       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.7     |\n",
      "|    ep_rew_mean     | 45.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 367      |\n",
      "|    time_elapsed    | 3717     |\n",
      "|    total_timesteps | 1503232  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.1        |\n",
      "|    ep_rew_mean          | 45.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 368         |\n",
      "|    time_elapsed         | 3727        |\n",
      "|    total_timesteps      | 1507328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009180479 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.65       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00532    |\n",
      "|    n_updates            | 3670        |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    value_loss           | 0.1         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1510000, episode_reward=41.24 +/- 7.14\n",
      "Episode length: 79.10 +/- 9.02\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 79.1        |\n",
      "|    mean_reward          | 41.2        |\n",
      "|    std_reward           | 7.14        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1510000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009847307 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.63       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0147      |\n",
      "|    n_updates            | 3680        |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    value_loss           | 0.16        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.5     |\n",
      "|    ep_rew_mean     | 45.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 369      |\n",
      "|    time_elapsed    | 3738     |\n",
      "|    total_timesteps | 1511424  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.7        |\n",
      "|    ep_rew_mean          | 43.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 370         |\n",
      "|    time_elapsed         | 3747        |\n",
      "|    total_timesteps      | 1515520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010216415 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.65       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00536    |\n",
      "|    n_updates            | 3690        |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    value_loss           | 0.127       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 78.5       |\n",
      "|    ep_rew_mean          | 43.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 404        |\n",
      "|    iterations           | 371        |\n",
      "|    time_elapsed         | 3757       |\n",
      "|    total_timesteps      | 1519616    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00995817 |\n",
      "|    clip_fraction        | 0.269      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.68      |\n",
      "|    explained_variance   | 0.993      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.0118    |\n",
      "|    n_updates            | 3700       |\n",
      "|    policy_gradient_loss | -0.0137    |\n",
      "|    value_loss           | 0.178      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1520000, episode_reward=42.67 +/- 4.42\n",
      "Episode length: 74.00 +/- 7.47\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 74          |\n",
      "|    mean_reward          | 42.7        |\n",
      "|    std_reward           | 4.42        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1520000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009048856 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.65       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00718    |\n",
      "|    n_updates            | 3710        |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    value_loss           | 0.139       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.4     |\n",
      "|    ep_rew_mean     | 45.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 372      |\n",
      "|    time_elapsed    | 3768     |\n",
      "|    total_timesteps | 1523712  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78          |\n",
      "|    ep_rew_mean          | 44.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 373         |\n",
      "|    time_elapsed         | 3777        |\n",
      "|    total_timesteps      | 1527808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009305759 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.63       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0188      |\n",
      "|    n_updates            | 3720        |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    value_loss           | 0.141       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1530000, episode_reward=45.19 +/- 4.84\n",
      "Episode length: 73.20 +/- 7.65\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 73.2       |\n",
      "|    mean_reward          | 45.2       |\n",
      "|    std_reward           | 4.84       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1530000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01159039 |\n",
      "|    clip_fraction        | 0.274      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.65      |\n",
      "|    explained_variance   | 0.995      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.00544   |\n",
      "|    n_updates            | 3730       |\n",
      "|    policy_gradient_loss | -0.014     |\n",
      "|    value_loss           | 0.124      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.7     |\n",
      "|    ep_rew_mean     | 43.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 374      |\n",
      "|    time_elapsed    | 3788     |\n",
      "|    total_timesteps | 1531904  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.8        |\n",
      "|    ep_rew_mean          | 44.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 375         |\n",
      "|    time_elapsed         | 3798        |\n",
      "|    total_timesteps      | 1536000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009016278 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.65       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00985    |\n",
      "|    n_updates            | 3740        |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    value_loss           | 0.13        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1540000, episode_reward=45.43 +/- 4.33\n",
      "Episode length: 75.90 +/- 7.18\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 75.9        |\n",
      "|    mean_reward          | 45.4        |\n",
      "|    std_reward           | 4.33        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1540000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008806098 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.61       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00116     |\n",
      "|    n_updates            | 3750        |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    value_loss           | 0.14        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79       |\n",
      "|    ep_rew_mean     | 44.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 376      |\n",
      "|    time_elapsed    | 3809     |\n",
      "|    total_timesteps | 1540096  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.1        |\n",
      "|    ep_rew_mean          | 44.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 377         |\n",
      "|    time_elapsed         | 3818        |\n",
      "|    total_timesteps      | 1544192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011580998 |\n",
      "|    clip_fraction        | 0.28        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.66       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00925    |\n",
      "|    n_updates            | 3760        |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    value_loss           | 0.107       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.1        |\n",
      "|    ep_rew_mean          | 45.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 378         |\n",
      "|    time_elapsed         | 3828        |\n",
      "|    total_timesteps      | 1548288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010226142 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.62       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0113      |\n",
      "|    n_updates            | 3770        |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    value_loss           | 0.132       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1550000, episode_reward=42.35 +/- 3.39\n",
      "Episode length: 81.30 +/- 10.98\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 81.3        |\n",
      "|    mean_reward          | 42.3        |\n",
      "|    std_reward           | 3.39        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1550000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009639404 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.64       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.000696    |\n",
      "|    n_updates            | 3780        |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    value_loss           | 0.126       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.7     |\n",
      "|    ep_rew_mean     | 44.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 379      |\n",
      "|    time_elapsed    | 3839     |\n",
      "|    total_timesteps | 1552384  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78.4         |\n",
      "|    ep_rew_mean          | 44.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 380          |\n",
      "|    time_elapsed         | 3848         |\n",
      "|    total_timesteps      | 1556480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0093935095 |\n",
      "|    clip_fraction        | 0.266        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.64        |\n",
      "|    explained_variance   | 0.995        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00333     |\n",
      "|    n_updates            | 3790         |\n",
      "|    policy_gradient_loss | -0.0158      |\n",
      "|    value_loss           | 0.154        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1560000, episode_reward=38.46 +/- 4.15\n",
      "Episode length: 80.70 +/- 9.28\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 80.7         |\n",
      "|    mean_reward          | 38.5         |\n",
      "|    std_reward           | 4.15         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1560000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075920904 |\n",
      "|    clip_fraction        | 0.249        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.64        |\n",
      "|    explained_variance   | 0.996        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00176     |\n",
      "|    n_updates            | 3800         |\n",
      "|    policy_gradient_loss | -0.0157      |\n",
      "|    value_loss           | 0.131        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.3     |\n",
      "|    ep_rew_mean     | 44.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 381      |\n",
      "|    time_elapsed    | 3859     |\n",
      "|    total_timesteps | 1560576  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 77.9       |\n",
      "|    ep_rew_mean          | 43.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 404        |\n",
      "|    iterations           | 382        |\n",
      "|    time_elapsed         | 3869       |\n",
      "|    total_timesteps      | 1564672    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01018017 |\n",
      "|    clip_fraction        | 0.291      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.67      |\n",
      "|    explained_variance   | 0.995      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.00196   |\n",
      "|    n_updates            | 3810       |\n",
      "|    policy_gradient_loss | -0.016     |\n",
      "|    value_loss           | 0.128      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.7        |\n",
      "|    ep_rew_mean          | 43.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 383         |\n",
      "|    time_elapsed         | 3878        |\n",
      "|    total_timesteps      | 1568768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010056044 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.71       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.000281   |\n",
      "|    n_updates            | 3820        |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    value_loss           | 0.179       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1570000, episode_reward=40.61 +/- 4.58\n",
      "Episode length: 83.50 +/- 8.96\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 83.5        |\n",
      "|    mean_reward          | 40.6        |\n",
      "|    std_reward           | 4.58        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1570000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010425522 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.69       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0156     |\n",
      "|    n_updates            | 3830        |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    value_loss           | 0.139       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.5     |\n",
      "|    ep_rew_mean     | 44.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 384      |\n",
      "|    time_elapsed    | 3889     |\n",
      "|    total_timesteps | 1572864  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77          |\n",
      "|    ep_rew_mean          | 44.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 385         |\n",
      "|    time_elapsed         | 3899        |\n",
      "|    total_timesteps      | 1576960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009276597 |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.69       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00891     |\n",
      "|    n_updates            | 3840        |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    value_loss           | 0.147       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1580000, episode_reward=43.65 +/- 4.03\n",
      "Episode length: 77.20 +/- 7.91\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 77.2        |\n",
      "|    mean_reward          | 43.7        |\n",
      "|    std_reward           | 4.03        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1580000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008211166 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.68       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00446    |\n",
      "|    n_updates            | 3850        |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    value_loss           | 0.159       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 76.2     |\n",
      "|    ep_rew_mean     | 45.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 386      |\n",
      "|    time_elapsed    | 3910     |\n",
      "|    total_timesteps | 1581056  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 77         |\n",
      "|    ep_rew_mean          | 45         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 404        |\n",
      "|    iterations           | 387        |\n",
      "|    time_elapsed         | 3919       |\n",
      "|    total_timesteps      | 1585152    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01090868 |\n",
      "|    clip_fraction        | 0.265      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.69      |\n",
      "|    explained_variance   | 0.996      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | 0.00184    |\n",
      "|    n_updates            | 3860       |\n",
      "|    policy_gradient_loss | -0.0153    |\n",
      "|    value_loss           | 0.127      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 76.7       |\n",
      "|    ep_rew_mean          | 44.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 404        |\n",
      "|    iterations           | 388        |\n",
      "|    time_elapsed         | 3929       |\n",
      "|    total_timesteps      | 1589248    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01048768 |\n",
      "|    clip_fraction        | 0.283      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.7       |\n",
      "|    explained_variance   | 0.996      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.00336   |\n",
      "|    n_updates            | 3870       |\n",
      "|    policy_gradient_loss | -0.0173    |\n",
      "|    value_loss           | 0.127      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1590000, episode_reward=45.64 +/- 6.18\n",
      "Episode length: 76.10 +/- 9.32\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 76.1         |\n",
      "|    mean_reward          | 45.6         |\n",
      "|    std_reward           | 6.18         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1590000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0100076385 |\n",
      "|    clip_fraction        | 0.294        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.68        |\n",
      "|    explained_variance   | 0.995        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.00798      |\n",
      "|    n_updates            | 3880         |\n",
      "|    policy_gradient_loss | -0.0165      |\n",
      "|    value_loss           | 0.152        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77       |\n",
      "|    ep_rew_mean     | 44.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 389      |\n",
      "|    time_elapsed    | 3940     |\n",
      "|    total_timesteps | 1593344  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.4        |\n",
      "|    ep_rew_mean          | 43.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 390         |\n",
      "|    time_elapsed         | 3949        |\n",
      "|    total_timesteps      | 1597440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009491594 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.74       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00483    |\n",
      "|    n_updates            | 3890        |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    value_loss           | 0.16        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1600000, episode_reward=40.00 +/- 8.47\n",
      "Episode length: 78.80 +/- 8.54\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 78.8       |\n",
      "|    mean_reward          | 40         |\n",
      "|    std_reward           | 8.47       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1600000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00882231 |\n",
      "|    clip_fraction        | 0.25       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.72      |\n",
      "|    explained_variance   | 0.993      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.00466   |\n",
      "|    n_updates            | 3900       |\n",
      "|    policy_gradient_loss | -0.0157    |\n",
      "|    value_loss           | 0.179      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 80       |\n",
      "|    ep_rew_mean     | 43.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 391      |\n",
      "|    time_elapsed    | 3960     |\n",
      "|    total_timesteps | 1601536  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.6        |\n",
      "|    ep_rew_mean          | 44          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 392         |\n",
      "|    time_elapsed         | 3970        |\n",
      "|    total_timesteps      | 1605632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012386582 |\n",
      "|    clip_fraction        | 0.302       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.7        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00592    |\n",
      "|    n_updates            | 3910        |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    value_loss           | 0.116       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78          |\n",
      "|    ep_rew_mean          | 44.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 393         |\n",
      "|    time_elapsed         | 3980        |\n",
      "|    total_timesteps      | 1609728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010899713 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.68       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00661    |\n",
      "|    n_updates            | 3920        |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    value_loss           | 0.124       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1610000, episode_reward=42.98 +/- 5.48\n",
      "Episode length: 80.40 +/- 8.22\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 80.4        |\n",
      "|    mean_reward          | 43          |\n",
      "|    std_reward           | 5.48        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1610000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011294076 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.7        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.000501    |\n",
      "|    n_updates            | 3930        |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    value_loss           | 0.115       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.4     |\n",
      "|    ep_rew_mean     | 44.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 394      |\n",
      "|    time_elapsed    | 3991     |\n",
      "|    total_timesteps | 1613824  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.7        |\n",
      "|    ep_rew_mean          | 45.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 395         |\n",
      "|    time_elapsed         | 4000        |\n",
      "|    total_timesteps      | 1617920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009979704 |\n",
      "|    clip_fraction        | 0.301       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.67       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0164     |\n",
      "|    n_updates            | 3940        |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    value_loss           | 0.128       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1620000, episode_reward=43.02 +/- 7.98\n",
      "Episode length: 76.00 +/- 7.04\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 76           |\n",
      "|    mean_reward          | 43           |\n",
      "|    std_reward           | 7.98         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1620000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0107047185 |\n",
      "|    clip_fraction        | 0.309        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.69        |\n",
      "|    explained_variance   | 0.996        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00608     |\n",
      "|    n_updates            | 3950         |\n",
      "|    policy_gradient_loss | -0.0171      |\n",
      "|    value_loss           | 0.109        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.7     |\n",
      "|    ep_rew_mean     | 45       |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 396      |\n",
      "|    time_elapsed    | 4011     |\n",
      "|    total_timesteps | 1622016  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.1        |\n",
      "|    ep_rew_mean          | 44.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 397         |\n",
      "|    time_elapsed         | 4021        |\n",
      "|    total_timesteps      | 1626112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009529224 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.67       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.000604   |\n",
      "|    n_updates            | 3960        |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    value_loss           | 0.146       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1630000, episode_reward=42.62 +/- 5.54\n",
      "Episode length: 78.80 +/- 10.10\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 78.8        |\n",
      "|    mean_reward          | 42.6        |\n",
      "|    std_reward           | 5.54        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1630000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008901315 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.7        |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00542     |\n",
      "|    n_updates            | 3970        |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    value_loss           | 0.17        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.4     |\n",
      "|    ep_rew_mean     | 44.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 398      |\n",
      "|    time_elapsed    | 4032     |\n",
      "|    total_timesteps | 1630208  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78          |\n",
      "|    ep_rew_mean          | 45.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 399         |\n",
      "|    time_elapsed         | 4041        |\n",
      "|    total_timesteps      | 1634304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012209028 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.66       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0112      |\n",
      "|    n_updates            | 3980        |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    value_loss           | 0.129       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.7        |\n",
      "|    ep_rew_mean          | 45          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 400         |\n",
      "|    time_elapsed         | 4051        |\n",
      "|    total_timesteps      | 1638400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010149324 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.64       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0034      |\n",
      "|    n_updates            | 3990        |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    value_loss           | 0.135       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1640000, episode_reward=44.23 +/- 5.79\n",
      "Episode length: 75.80 +/- 13.31\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 75.8        |\n",
      "|    mean_reward          | 44.2        |\n",
      "|    std_reward           | 5.79        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1640000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009261833 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.68       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.000589   |\n",
      "|    n_updates            | 4000        |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    value_loss           | 0.171       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.8     |\n",
      "|    ep_rew_mean     | 44.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 401      |\n",
      "|    time_elapsed    | 4062     |\n",
      "|    total_timesteps | 1642496  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.9        |\n",
      "|    ep_rew_mean          | 44.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 402         |\n",
      "|    time_elapsed         | 4071        |\n",
      "|    total_timesteps      | 1646592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009300345 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.66       |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0163      |\n",
      "|    n_updates            | 4010        |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    value_loss           | 0.245       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1650000, episode_reward=39.86 +/- 6.58\n",
      "Episode length: 81.60 +/- 9.73\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 81.6        |\n",
      "|    mean_reward          | 39.9        |\n",
      "|    std_reward           | 6.58        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1650000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011713105 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.65       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00182    |\n",
      "|    n_updates            | 4020        |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    value_loss           | 0.16        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.9     |\n",
      "|    ep_rew_mean     | 45.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 403      |\n",
      "|    time_elapsed    | 4082     |\n",
      "|    total_timesteps | 1650688  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.2        |\n",
      "|    ep_rew_mean          | 45.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 404         |\n",
      "|    time_elapsed         | 4092        |\n",
      "|    total_timesteps      | 1654784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010324055 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.64       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00393     |\n",
      "|    n_updates            | 4030        |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    value_loss           | 0.134       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.2        |\n",
      "|    ep_rew_mean          | 44.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 405         |\n",
      "|    time_elapsed         | 4102        |\n",
      "|    total_timesteps      | 1658880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013192881 |\n",
      "|    clip_fraction        | 0.318       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.65       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00727    |\n",
      "|    n_updates            | 4040        |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    value_loss           | 0.107       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1660000, episode_reward=44.54 +/- 5.80\n",
      "Episode length: 86.60 +/- 3.44\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 86.6        |\n",
      "|    mean_reward          | 44.5        |\n",
      "|    std_reward           | 5.8         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1660000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009766532 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.65       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00761     |\n",
      "|    n_updates            | 4050        |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    value_loss           | 0.14        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 76.9     |\n",
      "|    ep_rew_mean     | 45.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 406      |\n",
      "|    time_elapsed    | 4113     |\n",
      "|    total_timesteps | 1662976  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.4        |\n",
      "|    ep_rew_mean          | 45.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 407         |\n",
      "|    time_elapsed         | 4122        |\n",
      "|    total_timesteps      | 1667072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009470597 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.63       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00569    |\n",
      "|    n_updates            | 4060        |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    value_loss           | 0.125       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1670000, episode_reward=44.75 +/- 6.19\n",
      "Episode length: 75.80 +/- 8.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 75.8        |\n",
      "|    mean_reward          | 44.7        |\n",
      "|    std_reward           | 6.19        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1670000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009760315 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.61       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00368     |\n",
      "|    n_updates            | 4070        |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 0.112       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.5     |\n",
      "|    ep_rew_mean     | 45.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 408      |\n",
      "|    time_elapsed    | 4133     |\n",
      "|    total_timesteps | 1671168  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.2        |\n",
      "|    ep_rew_mean          | 44.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 409         |\n",
      "|    time_elapsed         | 4143        |\n",
      "|    total_timesteps      | 1675264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010240381 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.63       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00507     |\n",
      "|    n_updates            | 4080        |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 0.133       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79          |\n",
      "|    ep_rew_mean          | 44.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 410         |\n",
      "|    time_elapsed         | 4152        |\n",
      "|    total_timesteps      | 1679360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009362562 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.63       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00533     |\n",
      "|    n_updates            | 4090        |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 0.173       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1680000, episode_reward=42.14 +/- 9.18\n",
      "Episode length: 76.60 +/- 11.01\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 76.6        |\n",
      "|    mean_reward          | 42.1        |\n",
      "|    std_reward           | 9.18        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1680000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010178093 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.62       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00355    |\n",
      "|    n_updates            | 4100        |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    value_loss           | 0.143       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.1     |\n",
      "|    ep_rew_mean     | 44.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 411      |\n",
      "|    time_elapsed    | 4163     |\n",
      "|    total_timesteps | 1683456  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.6        |\n",
      "|    ep_rew_mean          | 45.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 412         |\n",
      "|    time_elapsed         | 4173        |\n",
      "|    total_timesteps      | 1687552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009769177 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.62       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00288    |\n",
      "|    n_updates            | 4110        |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 0.133       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1690000, episode_reward=44.35 +/- 6.34\n",
      "Episode length: 85.40 +/- 9.10\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 85.4         |\n",
      "|    mean_reward          | 44.4         |\n",
      "|    std_reward           | 6.34         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1690000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0102215065 |\n",
      "|    clip_fraction        | 0.271        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.62        |\n",
      "|    explained_variance   | 0.996        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00328     |\n",
      "|    n_updates            | 4120         |\n",
      "|    policy_gradient_loss | -0.0172      |\n",
      "|    value_loss           | 0.149        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.3     |\n",
      "|    ep_rew_mean     | 45.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 413      |\n",
      "|    time_elapsed    | 4184     |\n",
      "|    total_timesteps | 1691648  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.7        |\n",
      "|    ep_rew_mean          | 45.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 414         |\n",
      "|    time_elapsed         | 4194        |\n",
      "|    total_timesteps      | 1695744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009943863 |\n",
      "|    clip_fraction        | 0.28        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.62       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00302    |\n",
      "|    n_updates            | 4130        |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    value_loss           | 0.128       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.7        |\n",
      "|    ep_rew_mean          | 45.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 415         |\n",
      "|    time_elapsed         | 4203        |\n",
      "|    total_timesteps      | 1699840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009819815 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.61       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0213      |\n",
      "|    n_updates            | 4140        |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    value_loss           | 0.145       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1700000, episode_reward=44.64 +/- 5.42\n",
      "Episode length: 77.20 +/- 7.26\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 77.2        |\n",
      "|    mean_reward          | 44.6        |\n",
      "|    std_reward           | 5.42        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1700000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010099949 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.63       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00242    |\n",
      "|    n_updates            | 4150        |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    value_loss           | 0.13        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78       |\n",
      "|    ep_rew_mean     | 45.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 416      |\n",
      "|    time_elapsed    | 4214     |\n",
      "|    total_timesteps | 1703936  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.4        |\n",
      "|    ep_rew_mean          | 45.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 417         |\n",
      "|    time_elapsed         | 4224        |\n",
      "|    total_timesteps      | 1708032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012721831 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.62       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00533    |\n",
      "|    n_updates            | 4160        |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    value_loss           | 0.146       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1710000, episode_reward=43.29 +/- 3.09\n",
      "Episode length: 81.60 +/- 7.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 81.6       |\n",
      "|    mean_reward          | 43.3       |\n",
      "|    std_reward           | 3.09       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1710000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00991925 |\n",
      "|    clip_fraction        | 0.281      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.59      |\n",
      "|    explained_variance   | 0.996      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.000663  |\n",
      "|    n_updates            | 4170       |\n",
      "|    policy_gradient_loss | -0.017     |\n",
      "|    value_loss           | 0.121      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 76.6     |\n",
      "|    ep_rew_mean     | 45.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 418      |\n",
      "|    time_elapsed    | 4235     |\n",
      "|    total_timesteps | 1712128  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.2        |\n",
      "|    ep_rew_mean          | 46.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 419         |\n",
      "|    time_elapsed         | 4244        |\n",
      "|    total_timesteps      | 1716224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009336291 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.61       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0172     |\n",
      "|    n_updates            | 4180        |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 0.166       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1720000, episode_reward=43.83 +/- 7.60\n",
      "Episode length: 78.70 +/- 14.71\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 78.7        |\n",
      "|    mean_reward          | 43.8        |\n",
      "|    std_reward           | 7.6         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1720000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009762056 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00494     |\n",
      "|    n_updates            | 4190        |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    value_loss           | 0.151       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 76.8     |\n",
      "|    ep_rew_mean     | 46.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 420      |\n",
      "|    time_elapsed    | 4255     |\n",
      "|    total_timesteps | 1720320  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.2        |\n",
      "|    ep_rew_mean          | 46.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 421         |\n",
      "|    time_elapsed         | 4265        |\n",
      "|    total_timesteps      | 1724416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010450641 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.61       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.019      |\n",
      "|    n_updates            | 4200        |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    value_loss           | 0.12        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.7        |\n",
      "|    ep_rew_mean          | 46.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 422         |\n",
      "|    time_elapsed         | 4274        |\n",
      "|    total_timesteps      | 1728512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011355068 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.61       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0144     |\n",
      "|    n_updates            | 4210        |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    value_loss           | 0.117       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1730000, episode_reward=47.13 +/- 4.23\n",
      "Episode length: 75.00 +/- 9.27\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 75          |\n",
      "|    mean_reward          | 47.1        |\n",
      "|    std_reward           | 4.23        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1730000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012650038 |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.61       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0013     |\n",
      "|    n_updates            | 4220        |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    value_loss           | 0.124       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 76.8     |\n",
      "|    ep_rew_mean     | 46.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 423      |\n",
      "|    time_elapsed    | 4285     |\n",
      "|    total_timesteps | 1732608  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.2        |\n",
      "|    ep_rew_mean          | 45.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 424         |\n",
      "|    time_elapsed         | 4295        |\n",
      "|    total_timesteps      | 1736704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009528607 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.61       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00851     |\n",
      "|    n_updates            | 4230        |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    value_loss           | 0.145       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1740000, episode_reward=45.03 +/- 5.94\n",
      "Episode length: 80.40 +/- 10.46\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 80.4        |\n",
      "|    mean_reward          | 45          |\n",
      "|    std_reward           | 5.94        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1740000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009253165 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.62       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0123     |\n",
      "|    n_updates            | 4240        |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    value_loss           | 0.115       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.5     |\n",
      "|    ep_rew_mean     | 45.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 425      |\n",
      "|    time_elapsed    | 4306     |\n",
      "|    total_timesteps | 1740800  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.9        |\n",
      "|    ep_rew_mean          | 45.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 426         |\n",
      "|    time_elapsed         | 4315        |\n",
      "|    total_timesteps      | 1744896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010592155 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0114     |\n",
      "|    n_updates            | 4250        |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    value_loss           | 0.113       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.6        |\n",
      "|    ep_rew_mean          | 45.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 427         |\n",
      "|    time_elapsed         | 4325        |\n",
      "|    total_timesteps      | 1748992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011160154 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.62       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00549    |\n",
      "|    n_updates            | 4260        |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    value_loss           | 0.131       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1750000, episode_reward=48.01 +/- 6.41\n",
      "Episode length: 79.80 +/- 10.62\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 79.8        |\n",
      "|    mean_reward          | 48          |\n",
      "|    std_reward           | 6.41        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1750000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009611546 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.61       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00473     |\n",
      "|    n_updates            | 4270        |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    value_loss           | 0.148       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.2     |\n",
      "|    ep_rew_mean     | 45.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 428      |\n",
      "|    time_elapsed    | 4336     |\n",
      "|    total_timesteps | 1753088  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79          |\n",
      "|    ep_rew_mean          | 45.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 429         |\n",
      "|    time_elapsed         | 4346        |\n",
      "|    total_timesteps      | 1757184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008362491 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00091    |\n",
      "|    n_updates            | 4280        |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    value_loss           | 0.149       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1760000, episode_reward=46.96 +/- 3.46\n",
      "Episode length: 75.30 +/- 5.95\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 75.3        |\n",
      "|    mean_reward          | 47          |\n",
      "|    std_reward           | 3.46        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1760000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014301674 |\n",
      "|    clip_fraction        | 0.324       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.63       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00272     |\n",
      "|    n_updates            | 4290        |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    value_loss           | 0.109       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.5     |\n",
      "|    ep_rew_mean     | 46.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 430      |\n",
      "|    time_elapsed    | 4357     |\n",
      "|    total_timesteps | 1761280  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.5        |\n",
      "|    ep_rew_mean          | 46.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 431         |\n",
      "|    time_elapsed         | 4367        |\n",
      "|    total_timesteps      | 1765376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012022054 |\n",
      "|    clip_fraction        | 0.294       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.61       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0082     |\n",
      "|    n_updates            | 4300        |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    value_loss           | 0.114       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.9        |\n",
      "|    ep_rew_mean          | 45.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 432         |\n",
      "|    time_elapsed         | 4376        |\n",
      "|    total_timesteps      | 1769472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011200521 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.000631    |\n",
      "|    n_updates            | 4310        |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    value_loss           | 0.126       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1770000, episode_reward=50.49 +/- 3.31\n",
      "Episode length: 75.00 +/- 9.11\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 75          |\n",
      "|    mean_reward          | 50.5        |\n",
      "|    std_reward           | 3.31        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1770000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009791231 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.61       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00144    |\n",
      "|    n_updates            | 4320        |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    value_loss           | 0.118       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79       |\n",
      "|    ep_rew_mean     | 46.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 433      |\n",
      "|    time_elapsed    | 4387     |\n",
      "|    total_timesteps | 1773568  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.7        |\n",
      "|    ep_rew_mean          | 46.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 434         |\n",
      "|    time_elapsed         | 4397        |\n",
      "|    total_timesteps      | 1777664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008555753 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.61       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.000452   |\n",
      "|    n_updates            | 4330        |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    value_loss           | 0.163       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1780000, episode_reward=43.63 +/- 7.95\n",
      "Episode length: 81.30 +/- 10.38\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 81.3        |\n",
      "|    mean_reward          | 43.6        |\n",
      "|    std_reward           | 7.95        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1780000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011612218 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00468     |\n",
      "|    n_updates            | 4340        |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    value_loss           | 0.142       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79       |\n",
      "|    ep_rew_mean     | 46.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 435      |\n",
      "|    time_elapsed    | 4408     |\n",
      "|    total_timesteps | 1781760  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 80          |\n",
      "|    ep_rew_mean          | 46.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 436         |\n",
      "|    time_elapsed         | 4418        |\n",
      "|    total_timesteps      | 1785856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010855092 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.58       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0132     |\n",
      "|    n_updates            | 4350        |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    value_loss           | 0.13        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.3        |\n",
      "|    ep_rew_mean          | 46.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 437         |\n",
      "|    time_elapsed         | 4427        |\n",
      "|    total_timesteps      | 1789952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010444948 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0349      |\n",
      "|    n_updates            | 4360        |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    value_loss           | 0.123       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1790000, episode_reward=43.59 +/- 4.66\n",
      "Episode length: 81.20 +/- 8.05\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 81.2        |\n",
      "|    mean_reward          | 43.6        |\n",
      "|    std_reward           | 4.66        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1790000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010899803 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.59       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00152     |\n",
      "|    n_updates            | 4370        |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 0.148       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 76.6     |\n",
      "|    ep_rew_mean     | 46.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 438      |\n",
      "|    time_elapsed    | 4438     |\n",
      "|    total_timesteps | 1794048  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.5        |\n",
      "|    ep_rew_mean          | 46          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 439         |\n",
      "|    time_elapsed         | 4448        |\n",
      "|    total_timesteps      | 1798144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009862414 |\n",
      "|    clip_fraction        | 0.267       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.59       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.000927    |\n",
      "|    n_updates            | 4380        |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 0.14        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1800000, episode_reward=43.58 +/- 6.04\n",
      "Episode length: 80.00 +/- 8.39\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 80           |\n",
      "|    mean_reward          | 43.6         |\n",
      "|    std_reward           | 6.04         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1800000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0108771995 |\n",
      "|    clip_fraction        | 0.25         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.57        |\n",
      "|    explained_variance   | 0.996        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00173     |\n",
      "|    n_updates            | 4390         |\n",
      "|    policy_gradient_loss | -0.015       |\n",
      "|    value_loss           | 0.129        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.2     |\n",
      "|    ep_rew_mean     | 45.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 440      |\n",
      "|    time_elapsed    | 4459     |\n",
      "|    total_timesteps | 1802240  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 78.3       |\n",
      "|    ep_rew_mean          | 45         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 404        |\n",
      "|    iterations           | 441        |\n",
      "|    time_elapsed         | 4468       |\n",
      "|    total_timesteps      | 1806336    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01065035 |\n",
      "|    clip_fraction        | 0.261      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.58      |\n",
      "|    explained_variance   | 0.995      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.00166   |\n",
      "|    n_updates            | 4400       |\n",
      "|    policy_gradient_loss | -0.0142    |\n",
      "|    value_loss           | 0.136      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1810000, episode_reward=48.07 +/- 7.50\n",
      "Episode length: 74.50 +/- 9.25\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 74.5        |\n",
      "|    mean_reward          | 48.1        |\n",
      "|    std_reward           | 7.5         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1810000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011335774 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.59       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.000616    |\n",
      "|    n_updates            | 4410        |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    value_loss           | 0.158       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.4     |\n",
      "|    ep_rew_mean     | 45.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 442      |\n",
      "|    time_elapsed    | 4479     |\n",
      "|    total_timesteps | 1810432  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.8        |\n",
      "|    ep_rew_mean          | 46.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 443         |\n",
      "|    time_elapsed         | 4489        |\n",
      "|    total_timesteps      | 1814528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010775786 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.56       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00181    |\n",
      "|    n_updates            | 4420        |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    value_loss           | 0.132       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79          |\n",
      "|    ep_rew_mean          | 45.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 444         |\n",
      "|    time_elapsed         | 4498        |\n",
      "|    total_timesteps      | 1818624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012685961 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.59       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00181     |\n",
      "|    n_updates            | 4430        |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    value_loss           | 0.139       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1820000, episode_reward=47.07 +/- 4.09\n",
      "Episode length: 82.30 +/- 8.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 82.3        |\n",
      "|    mean_reward          | 47.1        |\n",
      "|    std_reward           | 4.09        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1820000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012228577 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0115     |\n",
      "|    n_updates            | 4440        |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    value_loss           | 0.122       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.8     |\n",
      "|    ep_rew_mean     | 45.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 445      |\n",
      "|    time_elapsed    | 4509     |\n",
      "|    total_timesteps | 1822720  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.2        |\n",
      "|    ep_rew_mean          | 45.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 446         |\n",
      "|    time_elapsed         | 4519        |\n",
      "|    total_timesteps      | 1826816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010997651 |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.59       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00569    |\n",
      "|    n_updates            | 4450        |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    value_loss           | 0.132       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1830000, episode_reward=44.67 +/- 6.45\n",
      "Episode length: 85.30 +/- 11.66\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 85.3        |\n",
      "|    mean_reward          | 44.7        |\n",
      "|    std_reward           | 6.45        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1830000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013836661 |\n",
      "|    clip_fraction        | 0.301       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.61       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0041      |\n",
      "|    n_updates            | 4460        |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    value_loss           | 0.112       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.3     |\n",
      "|    ep_rew_mean     | 46       |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 447      |\n",
      "|    time_elapsed    | 4530     |\n",
      "|    total_timesteps | 1830912  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 77.9         |\n",
      "|    ep_rew_mean          | 46.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 448          |\n",
      "|    time_elapsed         | 4539         |\n",
      "|    total_timesteps      | 1835008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0100338645 |\n",
      "|    clip_fraction        | 0.264        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.59        |\n",
      "|    explained_variance   | 0.996        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.00862      |\n",
      "|    n_updates            | 4470         |\n",
      "|    policy_gradient_loss | -0.0153      |\n",
      "|    value_loss           | 0.128        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78          |\n",
      "|    ep_rew_mean          | 46.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 449         |\n",
      "|    time_elapsed         | 4549        |\n",
      "|    total_timesteps      | 1839104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010733921 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.59       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00208    |\n",
      "|    n_updates            | 4480        |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    value_loss           | 0.159       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1840000, episode_reward=47.86 +/- 3.61\n",
      "Episode length: 77.90 +/- 8.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 77.9        |\n",
      "|    mean_reward          | 47.9        |\n",
      "|    std_reward           | 3.61        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1840000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011916833 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00975    |\n",
      "|    n_updates            | 4490        |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    value_loss           | 0.125       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 80       |\n",
      "|    ep_rew_mean     | 45.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 450      |\n",
      "|    time_elapsed    | 4560     |\n",
      "|    total_timesteps | 1843200  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 81.8        |\n",
      "|    ep_rew_mean          | 44.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 451         |\n",
      "|    time_elapsed         | 4570        |\n",
      "|    total_timesteps      | 1847296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011185189 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.59       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.000348   |\n",
      "|    n_updates            | 4500        |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    value_loss           | 0.148       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1850000, episode_reward=49.06 +/- 3.69\n",
      "Episode length: 77.50 +/- 10.35\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 77.5        |\n",
      "|    mean_reward          | 49.1        |\n",
      "|    std_reward           | 3.69        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1850000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010381662 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.59       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00326     |\n",
      "|    n_updates            | 4510        |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    value_loss           | 0.125       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 80.3     |\n",
      "|    ep_rew_mean     | 45.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 452      |\n",
      "|    time_elapsed    | 4581     |\n",
      "|    total_timesteps | 1851392  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.8        |\n",
      "|    ep_rew_mean          | 45.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 453         |\n",
      "|    time_elapsed         | 4590        |\n",
      "|    total_timesteps      | 1855488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013291925 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0115     |\n",
      "|    n_updates            | 4520        |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    value_loss           | 0.126       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.2        |\n",
      "|    ep_rew_mean          | 45.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 454         |\n",
      "|    time_elapsed         | 4600        |\n",
      "|    total_timesteps      | 1859584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009924063 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.59       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00141    |\n",
      "|    n_updates            | 4530        |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    value_loss           | 0.152       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1860000, episode_reward=46.92 +/- 4.00\n",
      "Episode length: 74.40 +/- 6.17\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 74.4        |\n",
      "|    mean_reward          | 46.9        |\n",
      "|    std_reward           | 4           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1860000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012084678 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.59       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00544     |\n",
      "|    n_updates            | 4540        |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    value_loss           | 0.144       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 76.9     |\n",
      "|    ep_rew_mean     | 46       |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 455      |\n",
      "|    time_elapsed    | 4611     |\n",
      "|    total_timesteps | 1863680  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.6        |\n",
      "|    ep_rew_mean          | 45.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 456         |\n",
      "|    time_elapsed         | 4620        |\n",
      "|    total_timesteps      | 1867776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010597324 |\n",
      "|    clip_fraction        | 0.284       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.61       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00334     |\n",
      "|    n_updates            | 4550        |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    value_loss           | 0.148       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1870000, episode_reward=44.65 +/- 5.42\n",
      "Episode length: 82.90 +/- 8.64\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 82.9        |\n",
      "|    mean_reward          | 44.6        |\n",
      "|    std_reward           | 5.42        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1870000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013180451 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.61       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0206      |\n",
      "|    n_updates            | 4560        |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    value_loss           | 0.139       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.8     |\n",
      "|    ep_rew_mean     | 45.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 457      |\n",
      "|    time_elapsed    | 4631     |\n",
      "|    total_timesteps | 1871872  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78          |\n",
      "|    ep_rew_mean          | 45.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 458         |\n",
      "|    time_elapsed         | 4641        |\n",
      "|    total_timesteps      | 1875968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010223065 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.59       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.000462   |\n",
      "|    n_updates            | 4570        |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    value_loss           | 0.142       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1880000, episode_reward=45.96 +/- 4.66\n",
      "Episode length: 78.00 +/- 10.75\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 78          |\n",
      "|    mean_reward          | 46          |\n",
      "|    std_reward           | 4.66        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1880000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012183238 |\n",
      "|    clip_fraction        | 0.305       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.58       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.000266   |\n",
      "|    n_updates            | 4580        |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    value_loss           | 0.137       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.1     |\n",
      "|    ep_rew_mean     | 45.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 459      |\n",
      "|    time_elapsed    | 4652     |\n",
      "|    total_timesteps | 1880064  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.8        |\n",
      "|    ep_rew_mean          | 46          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 460         |\n",
      "|    time_elapsed         | 4661        |\n",
      "|    total_timesteps      | 1884160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011517059 |\n",
      "|    clip_fraction        | 0.293       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.58       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0107     |\n",
      "|    n_updates            | 4590        |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 0.109       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.8        |\n",
      "|    ep_rew_mean          | 45.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 461         |\n",
      "|    time_elapsed         | 4671        |\n",
      "|    total_timesteps      | 1888256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010058048 |\n",
      "|    clip_fraction        | 0.3         |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.56       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00543    |\n",
      "|    n_updates            | 4600        |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    value_loss           | 0.105       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1890000, episode_reward=46.90 +/- 6.01\n",
      "Episode length: 78.80 +/- 10.74\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 78.8        |\n",
      "|    mean_reward          | 46.9        |\n",
      "|    std_reward           | 6.01        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1890000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010593446 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.56       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0108     |\n",
      "|    n_updates            | 4610        |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    value_loss           | 0.107       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.3     |\n",
      "|    ep_rew_mean     | 45.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 462      |\n",
      "|    time_elapsed    | 4682     |\n",
      "|    total_timesteps | 1892352  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.1        |\n",
      "|    ep_rew_mean          | 45.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 463         |\n",
      "|    time_elapsed         | 4692        |\n",
      "|    total_timesteps      | 1896448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010188777 |\n",
      "|    clip_fraction        | 0.287       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00156     |\n",
      "|    n_updates            | 4620        |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    value_loss           | 0.0969      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1900000, episode_reward=46.16 +/- 4.50\n",
      "Episode length: 79.60 +/- 13.01\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 79.6        |\n",
      "|    mean_reward          | 46.2        |\n",
      "|    std_reward           | 4.5         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1900000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011738526 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.56       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00827    |\n",
      "|    n_updates            | 4630        |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    value_loss           | 0.142       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.2     |\n",
      "|    ep_rew_mean     | 45.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 464      |\n",
      "|    time_elapsed    | 4703     |\n",
      "|    total_timesteps | 1900544  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.6        |\n",
      "|    ep_rew_mean          | 46.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 465         |\n",
      "|    time_elapsed         | 4712        |\n",
      "|    total_timesteps      | 1904640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010479769 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.54       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00261    |\n",
      "|    n_updates            | 4640        |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 0.115       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.4        |\n",
      "|    ep_rew_mean          | 46.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 466         |\n",
      "|    time_elapsed         | 4722        |\n",
      "|    total_timesteps      | 1908736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009734008 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.53       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0122     |\n",
      "|    n_updates            | 4650        |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    value_loss           | 0.139       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1910000, episode_reward=47.02 +/- 6.03\n",
      "Episode length: 77.40 +/- 8.79\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 77.4        |\n",
      "|    mean_reward          | 47          |\n",
      "|    std_reward           | 6.03        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1910000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009323248 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00505     |\n",
      "|    n_updates            | 4660        |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 0.139       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.8     |\n",
      "|    ep_rew_mean     | 46.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 467      |\n",
      "|    time_elapsed    | 4733     |\n",
      "|    total_timesteps | 1912832  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.5        |\n",
      "|    ep_rew_mean          | 45.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 468         |\n",
      "|    time_elapsed         | 4743        |\n",
      "|    total_timesteps      | 1916928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010873647 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.53       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00292     |\n",
      "|    n_updates            | 4670        |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    value_loss           | 0.137       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1920000, episode_reward=47.27 +/- 5.59\n",
      "Episode length: 76.20 +/- 8.34\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 76.2        |\n",
      "|    mean_reward          | 47.3        |\n",
      "|    std_reward           | 5.59        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1920000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010062614 |\n",
      "|    clip_fraction        | 0.28        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.55       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00121    |\n",
      "|    n_updates            | 4680        |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    value_loss           | 0.121       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.5     |\n",
      "|    ep_rew_mean     | 45.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 469      |\n",
      "|    time_elapsed    | 4753     |\n",
      "|    total_timesteps | 1921024  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.4        |\n",
      "|    ep_rew_mean          | 46.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 470         |\n",
      "|    time_elapsed         | 4763        |\n",
      "|    total_timesteps      | 1925120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012331299 |\n",
      "|    clip_fraction        | 0.287       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00396    |\n",
      "|    n_updates            | 4690        |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    value_loss           | 0.125       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 78.2       |\n",
      "|    ep_rew_mean          | 46.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 404        |\n",
      "|    iterations           | 471        |\n",
      "|    time_elapsed         | 4773       |\n",
      "|    total_timesteps      | 1929216    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01097886 |\n",
      "|    clip_fraction        | 0.274      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.51      |\n",
      "|    explained_variance   | 0.996      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.00983   |\n",
      "|    n_updates            | 4700       |\n",
      "|    policy_gradient_loss | -0.0122    |\n",
      "|    value_loss           | 0.121      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1930000, episode_reward=48.97 +/- 6.10\n",
      "Episode length: 77.00 +/- 7.73\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 77          |\n",
      "|    mean_reward          | 49          |\n",
      "|    std_reward           | 6.1         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1930000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011305198 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.51       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.000266   |\n",
      "|    n_updates            | 4710        |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    value_loss           | 0.137       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.6     |\n",
      "|    ep_rew_mean     | 46.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 472      |\n",
      "|    time_elapsed    | 4783     |\n",
      "|    total_timesteps | 1933312  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 76.8       |\n",
      "|    ep_rew_mean          | 46.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 404        |\n",
      "|    iterations           | 473        |\n",
      "|    time_elapsed         | 4793       |\n",
      "|    total_timesteps      | 1937408    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00976072 |\n",
      "|    clip_fraction        | 0.299      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.53      |\n",
      "|    explained_variance   | 0.996      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.0148    |\n",
      "|    n_updates            | 4720       |\n",
      "|    policy_gradient_loss | -0.0122    |\n",
      "|    value_loss           | 0.119      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1940000, episode_reward=44.21 +/- 3.04\n",
      "Episode length: 78.60 +/- 7.88\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 78.6        |\n",
      "|    mean_reward          | 44.2        |\n",
      "|    std_reward           | 3.04        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1940000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010234848 |\n",
      "|    clip_fraction        | 0.267       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.53       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00149     |\n",
      "|    n_updates            | 4730        |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    value_loss           | 0.178       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.6     |\n",
      "|    ep_rew_mean     | 45.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 474      |\n",
      "|    time_elapsed    | 4804     |\n",
      "|    total_timesteps | 1941504  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.2        |\n",
      "|    ep_rew_mean          | 46.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 475         |\n",
      "|    time_elapsed         | 4813        |\n",
      "|    total_timesteps      | 1945600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015194487 |\n",
      "|    clip_fraction        | 0.305       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0127     |\n",
      "|    n_updates            | 4740        |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    value_loss           | 0.106       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.2        |\n",
      "|    ep_rew_mean          | 46.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 476         |\n",
      "|    time_elapsed         | 4823        |\n",
      "|    total_timesteps      | 1949696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011662912 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.51       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.000341   |\n",
      "|    n_updates            | 4750        |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    value_loss           | 0.129       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1950000, episode_reward=42.18 +/- 11.59\n",
      "Episode length: 80.50 +/- 7.84\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 80.5        |\n",
      "|    mean_reward          | 42.2        |\n",
      "|    std_reward           | 11.6        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1950000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010399568 |\n",
      "|    clip_fraction        | 0.267       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.53       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0154     |\n",
      "|    n_updates            | 4760        |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    value_loss           | 0.129       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.8     |\n",
      "|    ep_rew_mean     | 46.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 477      |\n",
      "|    time_elapsed    | 4834     |\n",
      "|    total_timesteps | 1953792  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.3        |\n",
      "|    ep_rew_mean          | 46.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 478         |\n",
      "|    time_elapsed         | 4843        |\n",
      "|    total_timesteps      | 1957888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009561412 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00351     |\n",
      "|    n_updates            | 4770        |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    value_loss           | 0.172       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1960000, episode_reward=47.81 +/- 4.58\n",
      "Episode length: 71.10 +/- 7.19\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 71.1        |\n",
      "|    mean_reward          | 47.8        |\n",
      "|    std_reward           | 4.58        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1960000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009109007 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.54       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0113     |\n",
      "|    n_updates            | 4780        |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 0.125       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.7     |\n",
      "|    ep_rew_mean     | 45.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 479      |\n",
      "|    time_elapsed    | 4854     |\n",
      "|    total_timesteps | 1961984  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.5        |\n",
      "|    ep_rew_mean          | 44.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 480         |\n",
      "|    time_elapsed         | 4864        |\n",
      "|    total_timesteps      | 1966080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011273852 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.55       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00465    |\n",
      "|    n_updates            | 4790        |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    value_loss           | 0.148       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1970000, episode_reward=46.90 +/- 7.04\n",
      "Episode length: 81.90 +/- 7.76\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 81.9       |\n",
      "|    mean_reward          | 46.9       |\n",
      "|    std_reward           | 7.04       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1970000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01288726 |\n",
      "|    clip_fraction        | 0.292      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.55      |\n",
      "|    explained_variance   | 0.995      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | 0.0193     |\n",
      "|    n_updates            | 4800       |\n",
      "|    policy_gradient_loss | -0.0149    |\n",
      "|    value_loss           | 0.157      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.7     |\n",
      "|    ep_rew_mean     | 45.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 481      |\n",
      "|    time_elapsed    | 4875     |\n",
      "|    total_timesteps | 1970176  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.1        |\n",
      "|    ep_rew_mean          | 46.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 482         |\n",
      "|    time_elapsed         | 4884        |\n",
      "|    total_timesteps      | 1974272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010004792 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.51       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0153     |\n",
      "|    n_updates            | 4810        |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    value_loss           | 0.15        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.7        |\n",
      "|    ep_rew_mean          | 46.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 483         |\n",
      "|    time_elapsed         | 4894        |\n",
      "|    total_timesteps      | 1978368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011132854 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.54       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0159     |\n",
      "|    n_updates            | 4820        |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 0.127       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1980000, episode_reward=46.28 +/- 6.44\n",
      "Episode length: 77.20 +/- 9.02\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 77.2        |\n",
      "|    mean_reward          | 46.3        |\n",
      "|    std_reward           | 6.44        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1980000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012341649 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.53       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0117     |\n",
      "|    n_updates            | 4830        |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    value_loss           | 0.0987      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 80.1     |\n",
      "|    ep_rew_mean     | 45.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 484      |\n",
      "|    time_elapsed    | 4905     |\n",
      "|    total_timesteps | 1982464  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.7        |\n",
      "|    ep_rew_mean          | 45.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 485         |\n",
      "|    time_elapsed         | 4914        |\n",
      "|    total_timesteps      | 1986560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011151465 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00102    |\n",
      "|    n_updates            | 4840        |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    value_loss           | 0.0958      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1990000, episode_reward=44.83 +/- 7.02\n",
      "Episode length: 78.80 +/- 11.04\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 78.8        |\n",
      "|    mean_reward          | 44.8        |\n",
      "|    std_reward           | 7.02        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1990000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011642147 |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.000425   |\n",
      "|    n_updates            | 4850        |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    value_loss           | 0.113       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.2     |\n",
      "|    ep_rew_mean     | 45.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 486      |\n",
      "|    time_elapsed    | 4925     |\n",
      "|    total_timesteps | 1990656  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.5        |\n",
      "|    ep_rew_mean          | 45.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 487         |\n",
      "|    time_elapsed         | 4935        |\n",
      "|    total_timesteps      | 1994752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010933177 |\n",
      "|    clip_fraction        | 0.284       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.012      |\n",
      "|    n_updates            | 4860        |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    value_loss           | 0.101       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.4        |\n",
      "|    ep_rew_mean          | 45.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 488         |\n",
      "|    time_elapsed         | 4945        |\n",
      "|    total_timesteps      | 1998848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011451449 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.53       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00599    |\n",
      "|    n_updates            | 4870        |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 0.115       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2000000, episode_reward=45.38 +/- 6.66\n",
      "Episode length: 83.30 +/- 11.43\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 83.3        |\n",
      "|    mean_reward          | 45.4        |\n",
      "|    std_reward           | 6.66        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2000000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011909028 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0105     |\n",
      "|    n_updates            | 4880        |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    value_loss           | 0.107       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 80.4     |\n",
      "|    ep_rew_mean     | 46.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 489      |\n",
      "|    time_elapsed    | 4956     |\n",
      "|    total_timesteps | 2002944  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.8        |\n",
      "|    ep_rew_mean          | 46.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 490         |\n",
      "|    time_elapsed         | 4965        |\n",
      "|    total_timesteps      | 2007040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011890717 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.51       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00225    |\n",
      "|    n_updates            | 4890        |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    value_loss           | 0.108       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2010000, episode_reward=46.06 +/- 4.55\n",
      "Episode length: 78.20 +/- 7.65\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 78.2        |\n",
      "|    mean_reward          | 46.1        |\n",
      "|    std_reward           | 4.55        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2010000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009764111 |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0113      |\n",
      "|    n_updates            | 4900        |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 0.103       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.4     |\n",
      "|    ep_rew_mean     | 46.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 491      |\n",
      "|    time_elapsed    | 4976     |\n",
      "|    total_timesteps | 2011136  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 80.6        |\n",
      "|    ep_rew_mean          | 46.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 492         |\n",
      "|    time_elapsed         | 4986        |\n",
      "|    total_timesteps      | 2015232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010995282 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.51       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00658     |\n",
      "|    n_updates            | 4910        |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    value_loss           | 0.0894      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.4        |\n",
      "|    ep_rew_mean          | 47.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 493         |\n",
      "|    time_elapsed         | 4996        |\n",
      "|    total_timesteps      | 2019328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010420466 |\n",
      "|    clip_fraction        | 0.293       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.51       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0134      |\n",
      "|    n_updates            | 4920        |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    value_loss           | 0.0899      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2020000, episode_reward=44.93 +/- 5.91\n",
      "Episode length: 77.80 +/- 6.98\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 77.8        |\n",
      "|    mean_reward          | 44.9        |\n",
      "|    std_reward           | 5.91        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2020000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011576278 |\n",
      "|    clip_fraction        | 0.307       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0125     |\n",
      "|    n_updates            | 4930        |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    value_loss           | 0.0896      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.5     |\n",
      "|    ep_rew_mean     | 46.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 494      |\n",
      "|    time_elapsed    | 5007     |\n",
      "|    total_timesteps | 2023424  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.2        |\n",
      "|    ep_rew_mean          | 47.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 495         |\n",
      "|    time_elapsed         | 5016        |\n",
      "|    total_timesteps      | 2027520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013622025 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0028     |\n",
      "|    n_updates            | 4940        |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 0.0986      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2030000, episode_reward=48.31 +/- 4.28\n",
      "Episode length: 77.60 +/- 8.63\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 77.6        |\n",
      "|    mean_reward          | 48.3        |\n",
      "|    std_reward           | 4.28        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2030000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012310666 |\n",
      "|    clip_fraction        | 0.287       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.51       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0112      |\n",
      "|    n_updates            | 4950        |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    value_loss           | 0.108       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.2     |\n",
      "|    ep_rew_mean     | 47.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 496      |\n",
      "|    time_elapsed    | 5027     |\n",
      "|    total_timesteps | 2031616  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78          |\n",
      "|    ep_rew_mean          | 47          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 497         |\n",
      "|    time_elapsed         | 5037        |\n",
      "|    total_timesteps      | 2035712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013546769 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00643    |\n",
      "|    n_updates            | 4960        |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    value_loss           | 0.112       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.3        |\n",
      "|    ep_rew_mean          | 46.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 498         |\n",
      "|    time_elapsed         | 5046        |\n",
      "|    total_timesteps      | 2039808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011751428 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00643    |\n",
      "|    n_updates            | 4970        |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 0.15        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2040000, episode_reward=48.24 +/- 3.90\n",
      "Episode length: 76.90 +/- 8.58\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 76.9        |\n",
      "|    mean_reward          | 48.2        |\n",
      "|    std_reward           | 3.9         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2040000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010528356 |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.53       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00108     |\n",
      "|    n_updates            | 4980        |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    value_loss           | 0.116       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.8     |\n",
      "|    ep_rew_mean     | 46.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 499      |\n",
      "|    time_elapsed    | 5057     |\n",
      "|    total_timesteps | 2043904  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.3        |\n",
      "|    ep_rew_mean          | 46          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 500         |\n",
      "|    time_elapsed         | 5067        |\n",
      "|    total_timesteps      | 2048000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011099998 |\n",
      "|    clip_fraction        | 0.317       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.53       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.01       |\n",
      "|    n_updates            | 4990        |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    value_loss           | 0.096       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2050000, episode_reward=43.97 +/- 4.66\n",
      "Episode length: 79.40 +/- 8.10\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 79.4        |\n",
      "|    mean_reward          | 44          |\n",
      "|    std_reward           | 4.66        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2050000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010833925 |\n",
      "|    clip_fraction        | 0.289       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.000639   |\n",
      "|    n_updates            | 5000        |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    value_loss           | 0.122       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.6     |\n",
      "|    ep_rew_mean     | 46.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 501      |\n",
      "|    time_elapsed    | 5078     |\n",
      "|    total_timesteps | 2052096  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.3        |\n",
      "|    ep_rew_mean          | 46.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 502         |\n",
      "|    time_elapsed         | 5088        |\n",
      "|    total_timesteps      | 2056192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010323878 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00877    |\n",
      "|    n_updates            | 5010        |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    value_loss           | 0.127       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2060000, episode_reward=45.29 +/- 5.72\n",
      "Episode length: 78.10 +/- 9.17\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 78.1        |\n",
      "|    mean_reward          | 45.3        |\n",
      "|    std_reward           | 5.72        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2060000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010034153 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00487    |\n",
      "|    n_updates            | 5020        |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    value_loss           | 0.142       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.5     |\n",
      "|    ep_rew_mean     | 47.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 503      |\n",
      "|    time_elapsed    | 5098     |\n",
      "|    total_timesteps | 2060288  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.9        |\n",
      "|    ep_rew_mean          | 46.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 504         |\n",
      "|    time_elapsed         | 5108        |\n",
      "|    total_timesteps      | 2064384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012643982 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0145     |\n",
      "|    n_updates            | 5030        |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    value_loss           | 0.115       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.9        |\n",
      "|    ep_rew_mean          | 45.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 505         |\n",
      "|    time_elapsed         | 5118        |\n",
      "|    total_timesteps      | 2068480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012342481 |\n",
      "|    clip_fraction        | 0.313       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.51       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0098     |\n",
      "|    n_updates            | 5040        |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    value_loss           | 0.0955      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2070000, episode_reward=47.58 +/- 4.70\n",
      "Episode length: 76.20 +/- 9.66\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 76.2        |\n",
      "|    mean_reward          | 47.6        |\n",
      "|    std_reward           | 4.7         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2070000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010451193 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00665    |\n",
      "|    n_updates            | 5050        |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    value_loss           | 0.118       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.7     |\n",
      "|    ep_rew_mean     | 45.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 506      |\n",
      "|    time_elapsed    | 5128     |\n",
      "|    total_timesteps | 2072576  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.5        |\n",
      "|    ep_rew_mean          | 46.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 507         |\n",
      "|    time_elapsed         | 5138        |\n",
      "|    total_timesteps      | 2076672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010949257 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.51       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00897    |\n",
      "|    n_updates            | 5060        |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    value_loss           | 0.118       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2080000, episode_reward=47.84 +/- 6.30\n",
      "Episode length: 72.50 +/- 11.20\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 72.5        |\n",
      "|    mean_reward          | 47.8        |\n",
      "|    std_reward           | 6.3         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2080000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012119962 |\n",
      "|    clip_fraction        | 0.284       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0134     |\n",
      "|    n_updates            | 5070        |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    value_loss           | 0.117       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.8     |\n",
      "|    ep_rew_mean     | 46.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 508      |\n",
      "|    time_elapsed    | 5149     |\n",
      "|    total_timesteps | 2080768  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.9        |\n",
      "|    ep_rew_mean          | 46.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 509         |\n",
      "|    time_elapsed         | 5158        |\n",
      "|    total_timesteps      | 2084864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012544747 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.51       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0172     |\n",
      "|    n_updates            | 5080        |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    value_loss           | 0.0984      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.7        |\n",
      "|    ep_rew_mean          | 46.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 510         |\n",
      "|    time_elapsed         | 5168        |\n",
      "|    total_timesteps      | 2088960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010761782 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00787    |\n",
      "|    n_updates            | 5090        |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    value_loss           | 0.139       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2090000, episode_reward=46.34 +/- 6.72\n",
      "Episode length: 76.10 +/- 6.82\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 76.1        |\n",
      "|    mean_reward          | 46.3        |\n",
      "|    std_reward           | 6.72        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2090000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010664754 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00383    |\n",
      "|    n_updates            | 5100        |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    value_loss           | 0.109       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.6     |\n",
      "|    ep_rew_mean     | 46.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 511      |\n",
      "|    time_elapsed    | 5179     |\n",
      "|    total_timesteps | 2093056  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.8        |\n",
      "|    ep_rew_mean          | 47          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 512         |\n",
      "|    time_elapsed         | 5188        |\n",
      "|    total_timesteps      | 2097152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011048953 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.51       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0172      |\n",
      "|    n_updates            | 5110        |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    value_loss           | 0.127       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2100000, episode_reward=45.70 +/- 4.85\n",
      "Episode length: 77.50 +/- 9.09\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 77.5        |\n",
      "|    mean_reward          | 45.7        |\n",
      "|    std_reward           | 4.85        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2100000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013672975 |\n",
      "|    clip_fraction        | 0.289       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0028      |\n",
      "|    n_updates            | 5120        |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    value_loss           | 0.129       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.3     |\n",
      "|    ep_rew_mean     | 47.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 513      |\n",
      "|    time_elapsed    | 5199     |\n",
      "|    total_timesteps | 2101248  |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 79.4      |\n",
      "|    ep_rew_mean          | 46        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 404       |\n",
      "|    iterations           | 514       |\n",
      "|    time_elapsed         | 5209      |\n",
      "|    total_timesteps      | 2105344   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0125414 |\n",
      "|    clip_fraction        | 0.282     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -1.47     |\n",
      "|    explained_variance   | 0.997     |\n",
      "|    learning_rate        | 5e-05     |\n",
      "|    loss                 | -0.00977  |\n",
      "|    n_updates            | 5130      |\n",
      "|    policy_gradient_loss | -0.0149   |\n",
      "|    value_loss           | 0.111     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79          |\n",
      "|    ep_rew_mean          | 45.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 515         |\n",
      "|    time_elapsed         | 5218        |\n",
      "|    total_timesteps      | 2109440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010972947 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00562    |\n",
      "|    n_updates            | 5140        |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    value_loss           | 0.115       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2110000, episode_reward=43.04 +/- 6.15\n",
      "Episode length: 85.90 +/- 12.88\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 85.9        |\n",
      "|    mean_reward          | 43          |\n",
      "|    std_reward           | 6.15        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2110000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009617977 |\n",
      "|    clip_fraction        | 0.267       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0126      |\n",
      "|    n_updates            | 5150        |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    value_loss           | 0.148       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.5     |\n",
      "|    ep_rew_mean     | 45.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 516      |\n",
      "|    time_elapsed    | 5230     |\n",
      "|    total_timesteps | 2113536  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 80.2        |\n",
      "|    ep_rew_mean          | 45.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 517         |\n",
      "|    time_elapsed         | 5239        |\n",
      "|    total_timesteps      | 2117632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012301912 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00684    |\n",
      "|    n_updates            | 5160        |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    value_loss           | 0.108       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2120000, episode_reward=45.69 +/- 6.30\n",
      "Episode length: 79.90 +/- 9.55\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 79.9        |\n",
      "|    mean_reward          | 45.7        |\n",
      "|    std_reward           | 6.3         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2120000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017031498 |\n",
      "|    clip_fraction        | 0.314       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.000548    |\n",
      "|    n_updates            | 5170        |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    value_loss           | 0.103       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.4     |\n",
      "|    ep_rew_mean     | 45.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 518      |\n",
      "|    time_elapsed    | 5250     |\n",
      "|    total_timesteps | 2121728  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79          |\n",
      "|    ep_rew_mean          | 45.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 519         |\n",
      "|    time_elapsed         | 5260        |\n",
      "|    total_timesteps      | 2125824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012976902 |\n",
      "|    clip_fraction        | 0.309       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0157     |\n",
      "|    n_updates            | 5180        |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    value_loss           | 0.112       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.6        |\n",
      "|    ep_rew_mean          | 46          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 520         |\n",
      "|    time_elapsed         | 5269        |\n",
      "|    total_timesteps      | 2129920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011008624 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.46       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00376    |\n",
      "|    n_updates            | 5190        |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    value_loss           | 0.111       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2130000, episode_reward=45.80 +/- 5.87\n",
      "Episode length: 79.50 +/- 9.56\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 79.5        |\n",
      "|    mean_reward          | 45.8        |\n",
      "|    std_reward           | 5.87        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2130000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010338347 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.000127    |\n",
      "|    n_updates            | 5200        |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    value_loss           | 0.108       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.5     |\n",
      "|    ep_rew_mean     | 46.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 521      |\n",
      "|    time_elapsed    | 5280     |\n",
      "|    total_timesteps | 2134016  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.3        |\n",
      "|    ep_rew_mean          | 46.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 522         |\n",
      "|    time_elapsed         | 5290        |\n",
      "|    total_timesteps      | 2138112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011764686 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.45       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00186    |\n",
      "|    n_updates            | 5210        |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    value_loss           | 0.133       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2140000, episode_reward=46.20 +/- 5.50\n",
      "Episode length: 79.40 +/- 11.57\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 79.4         |\n",
      "|    mean_reward          | 46.2         |\n",
      "|    std_reward           | 5.5          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2140000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0111046545 |\n",
      "|    clip_fraction        | 0.27         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.48        |\n",
      "|    explained_variance   | 0.996        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0116       |\n",
      "|    n_updates            | 5220         |\n",
      "|    policy_gradient_loss | -0.0137      |\n",
      "|    value_loss           | 0.12         |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 80       |\n",
      "|    ep_rew_mean     | 45.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 523      |\n",
      "|    time_elapsed    | 5301     |\n",
      "|    total_timesteps | 2142208  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 79.2       |\n",
      "|    ep_rew_mean          | 46.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 404        |\n",
      "|    iterations           | 524        |\n",
      "|    time_elapsed         | 5310       |\n",
      "|    total_timesteps      | 2146304    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01231572 |\n",
      "|    clip_fraction        | 0.299      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.47      |\n",
      "|    explained_variance   | 0.997      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | 0.00142    |\n",
      "|    n_updates            | 5230       |\n",
      "|    policy_gradient_loss | -0.0148    |\n",
      "|    value_loss           | 0.106      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2150000, episode_reward=48.73 +/- 4.16\n",
      "Episode length: 76.60 +/- 13.37\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 76.6         |\n",
      "|    mean_reward          | 48.7         |\n",
      "|    std_reward           | 4.16         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2150000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0139469495 |\n",
      "|    clip_fraction        | 0.283        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.46        |\n",
      "|    explained_variance   | 0.996        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.000978    |\n",
      "|    n_updates            | 5240         |\n",
      "|    policy_gradient_loss | -0.0137      |\n",
      "|    value_loss           | 0.13         |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.5     |\n",
      "|    ep_rew_mean     | 47       |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 525      |\n",
      "|    time_elapsed    | 5321     |\n",
      "|    total_timesteps | 2150400  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.4        |\n",
      "|    ep_rew_mean          | 46.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 526         |\n",
      "|    time_elapsed         | 5331        |\n",
      "|    total_timesteps      | 2154496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011332164 |\n",
      "|    clip_fraction        | 0.301       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0136     |\n",
      "|    n_updates            | 5250        |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    value_loss           | 0.112       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.3        |\n",
      "|    ep_rew_mean          | 47.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 527         |\n",
      "|    time_elapsed         | 5340        |\n",
      "|    total_timesteps      | 2158592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012771874 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.45       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0153     |\n",
      "|    n_updates            | 5260        |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 0.0921      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2160000, episode_reward=47.68 +/- 6.78\n",
      "Episode length: 76.70 +/- 9.27\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 76.7        |\n",
      "|    mean_reward          | 47.7        |\n",
      "|    std_reward           | 6.78        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2160000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012263676 |\n",
      "|    clip_fraction        | 0.314       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.46       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00214    |\n",
      "|    n_updates            | 5270        |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    value_loss           | 0.096       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.1     |\n",
      "|    ep_rew_mean     | 48.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 528      |\n",
      "|    time_elapsed    | 5351     |\n",
      "|    total_timesteps | 2162688  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.3        |\n",
      "|    ep_rew_mean          | 47          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 529         |\n",
      "|    time_elapsed         | 5361        |\n",
      "|    total_timesteps      | 2166784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011305867 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.46       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00458     |\n",
      "|    n_updates            | 5280        |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    value_loss           | 0.11        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2170000, episode_reward=47.19 +/- 7.34\n",
      "Episode length: 80.90 +/- 10.89\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 80.9        |\n",
      "|    mean_reward          | 47.2        |\n",
      "|    std_reward           | 7.34        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2170000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011785079 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.51       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0106     |\n",
      "|    n_updates            | 5290        |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    value_loss           | 0.119       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.3     |\n",
      "|    ep_rew_mean     | 46.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 530      |\n",
      "|    time_elapsed    | 5372     |\n",
      "|    total_timesteps | 2170880  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.4        |\n",
      "|    ep_rew_mean          | 47.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 531         |\n",
      "|    time_elapsed         | 5382        |\n",
      "|    total_timesteps      | 2174976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010626797 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0151      |\n",
      "|    n_updates            | 5300        |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    value_loss           | 0.115       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79          |\n",
      "|    ep_rew_mean          | 47.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 532         |\n",
      "|    time_elapsed         | 5391        |\n",
      "|    total_timesteps      | 2179072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012001736 |\n",
      "|    clip_fraction        | 0.321       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00408    |\n",
      "|    n_updates            | 5310        |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 0.0905      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2180000, episode_reward=47.29 +/- 4.57\n",
      "Episode length: 80.30 +/- 7.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 80.3        |\n",
      "|    mean_reward          | 47.3        |\n",
      "|    std_reward           | 4.57        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2180000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012642324 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00589    |\n",
      "|    n_updates            | 5320        |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    value_loss           | 0.1         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.3     |\n",
      "|    ep_rew_mean     | 46.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 533      |\n",
      "|    time_elapsed    | 5402     |\n",
      "|    total_timesteps | 2183168  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.8        |\n",
      "|    ep_rew_mean          | 47.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 534         |\n",
      "|    time_elapsed         | 5412        |\n",
      "|    total_timesteps      | 2187264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011937186 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0032     |\n",
      "|    n_updates            | 5330        |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    value_loss           | 0.122       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2190000, episode_reward=47.27 +/- 4.75\n",
      "Episode length: 71.40 +/- 4.90\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 71.4        |\n",
      "|    mean_reward          | 47.3        |\n",
      "|    std_reward           | 4.75        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2190000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011612959 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0169     |\n",
      "|    n_updates            | 5340        |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    value_loss           | 0.121       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.3     |\n",
      "|    ep_rew_mean     | 47.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 535      |\n",
      "|    time_elapsed    | 5422     |\n",
      "|    total_timesteps | 2191360  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.7        |\n",
      "|    ep_rew_mean          | 47.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 536         |\n",
      "|    time_elapsed         | 5432        |\n",
      "|    total_timesteps      | 2195456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011457197 |\n",
      "|    clip_fraction        | 0.293       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0222      |\n",
      "|    n_updates            | 5350        |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 0.122       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.9        |\n",
      "|    ep_rew_mean          | 47.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 537         |\n",
      "|    time_elapsed         | 5442        |\n",
      "|    total_timesteps      | 2199552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011530414 |\n",
      "|    clip_fraction        | 0.302       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00592     |\n",
      "|    n_updates            | 5360        |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    value_loss           | 0.108       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2200000, episode_reward=48.53 +/- 6.78\n",
      "Episode length: 77.50 +/- 9.27\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 77.5        |\n",
      "|    mean_reward          | 48.5        |\n",
      "|    std_reward           | 6.78        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2200000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012657751 |\n",
      "|    clip_fraction        | 0.301       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00454    |\n",
      "|    n_updates            | 5370        |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    value_loss           | 0.155       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.5     |\n",
      "|    ep_rew_mean     | 46.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 538      |\n",
      "|    time_elapsed    | 5453     |\n",
      "|    total_timesteps | 2203648  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.5        |\n",
      "|    ep_rew_mean          | 46          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 539         |\n",
      "|    time_elapsed         | 5462        |\n",
      "|    total_timesteps      | 2207744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011874497 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.000739    |\n",
      "|    n_updates            | 5380        |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    value_loss           | 0.135       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2210000, episode_reward=47.66 +/- 7.77\n",
      "Episode length: 80.00 +/- 11.64\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 80          |\n",
      "|    mean_reward          | 47.7        |\n",
      "|    std_reward           | 7.77        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2210000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010765348 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00176     |\n",
      "|    n_updates            | 5390        |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    value_loss           | 0.164       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.7     |\n",
      "|    ep_rew_mean     | 47.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 540      |\n",
      "|    time_elapsed    | 5473     |\n",
      "|    total_timesteps | 2211840  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.4        |\n",
      "|    ep_rew_mean          | 47.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 541         |\n",
      "|    time_elapsed         | 5483        |\n",
      "|    total_timesteps      | 2215936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012722023 |\n",
      "|    clip_fraction        | 0.301       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0025     |\n",
      "|    n_updates            | 5400        |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    value_loss           | 0.109       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2220000, episode_reward=45.75 +/- 4.87\n",
      "Episode length: 83.40 +/- 10.71\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 83.4        |\n",
      "|    mean_reward          | 45.8        |\n",
      "|    std_reward           | 4.87        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2220000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009799349 |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00309     |\n",
      "|    n_updates            | 5410        |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 0.159       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79       |\n",
      "|    ep_rew_mean     | 46.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 542      |\n",
      "|    time_elapsed    | 5494     |\n",
      "|    total_timesteps | 2220032  |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 79.6      |\n",
      "|    ep_rew_mean          | 46.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 404       |\n",
      "|    iterations           | 543       |\n",
      "|    time_elapsed         | 5503      |\n",
      "|    total_timesteps      | 2224128   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0127112 |\n",
      "|    clip_fraction        | 0.298     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -1.5      |\n",
      "|    explained_variance   | 0.996     |\n",
      "|    learning_rate        | 5e-05     |\n",
      "|    loss                 | 0.0125    |\n",
      "|    n_updates            | 5420      |\n",
      "|    policy_gradient_loss | -0.0161   |\n",
      "|    value_loss           | 0.126     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.1        |\n",
      "|    ep_rew_mean          | 47.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 544         |\n",
      "|    time_elapsed         | 5513        |\n",
      "|    total_timesteps      | 2228224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011543239 |\n",
      "|    clip_fraction        | 0.309       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00669     |\n",
      "|    n_updates            | 5430        |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    value_loss           | 0.142       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2230000, episode_reward=45.74 +/- 4.90\n",
      "Episode length: 84.30 +/- 11.11\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 84.3        |\n",
      "|    mean_reward          | 45.7        |\n",
      "|    std_reward           | 4.9         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2230000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011842404 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0148      |\n",
      "|    n_updates            | 5440        |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    value_loss           | 0.156       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.7     |\n",
      "|    ep_rew_mean     | 47.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 545      |\n",
      "|    time_elapsed    | 5524     |\n",
      "|    total_timesteps | 2232320  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.8        |\n",
      "|    ep_rew_mean          | 47.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 546         |\n",
      "|    time_elapsed         | 5533        |\n",
      "|    total_timesteps      | 2236416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009313181 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0161     |\n",
      "|    n_updates            | 5450        |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    value_loss           | 0.143       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2240000, episode_reward=48.88 +/- 2.24\n",
      "Episode length: 78.00 +/- 10.68\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 78           |\n",
      "|    mean_reward          | 48.9         |\n",
      "|    std_reward           | 2.24         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2240000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0145828575 |\n",
      "|    clip_fraction        | 0.308        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.5         |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00871     |\n",
      "|    n_updates            | 5460         |\n",
      "|    policy_gradient_loss | -0.0159      |\n",
      "|    value_loss           | 0.11         |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.8     |\n",
      "|    ep_rew_mean     | 46.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 547      |\n",
      "|    time_elapsed    | 5544     |\n",
      "|    total_timesteps | 2240512  |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 79.2      |\n",
      "|    ep_rew_mean          | 46.3      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 404       |\n",
      "|    iterations           | 548       |\n",
      "|    time_elapsed         | 5554      |\n",
      "|    total_timesteps      | 2244608   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0116808 |\n",
      "|    clip_fraction        | 0.287     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -1.51     |\n",
      "|    explained_variance   | 0.995     |\n",
      "|    learning_rate        | 5e-05     |\n",
      "|    loss                 | -0.00333  |\n",
      "|    n_updates            | 5470      |\n",
      "|    policy_gradient_loss | -0.0147   |\n",
      "|    value_loss           | 0.131     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.9        |\n",
      "|    ep_rew_mean          | 46.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 549         |\n",
      "|    time_elapsed         | 5564        |\n",
      "|    total_timesteps      | 2248704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013099669 |\n",
      "|    clip_fraction        | 0.302       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.51       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.000302   |\n",
      "|    n_updates            | 5480        |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    value_loss           | 0.142       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2250000, episode_reward=49.62 +/- 3.52\n",
      "Episode length: 77.10 +/- 4.35\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 77.1        |\n",
      "|    mean_reward          | 49.6        |\n",
      "|    std_reward           | 3.52        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2250000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015224446 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.53       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0133     |\n",
      "|    n_updates            | 5490        |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    value_loss           | 0.124       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.3     |\n",
      "|    ep_rew_mean     | 45.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 550      |\n",
      "|    time_elapsed    | 5575     |\n",
      "|    total_timesteps | 2252800  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.3        |\n",
      "|    ep_rew_mean          | 46          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 551         |\n",
      "|    time_elapsed         | 5584        |\n",
      "|    total_timesteps      | 2256896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011465209 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0051      |\n",
      "|    n_updates            | 5500        |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    value_loss           | 0.146       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2260000, episode_reward=46.52 +/- 4.02\n",
      "Episode length: 78.40 +/- 7.58\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 78.4        |\n",
      "|    mean_reward          | 46.5        |\n",
      "|    std_reward           | 4.02        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2260000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013193628 |\n",
      "|    clip_fraction        | 0.328       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00411    |\n",
      "|    n_updates            | 5510        |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    value_loss           | 0.114       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.5     |\n",
      "|    ep_rew_mean     | 47.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 552      |\n",
      "|    time_elapsed    | 5595     |\n",
      "|    total_timesteps | 2260992  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.5        |\n",
      "|    ep_rew_mean          | 47.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 553         |\n",
      "|    time_elapsed         | 5605        |\n",
      "|    total_timesteps      | 2265088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013560882 |\n",
      "|    clip_fraction        | 0.301       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.51       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00189    |\n",
      "|    n_updates            | 5520        |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    value_loss           | 0.121       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 79.8       |\n",
      "|    ep_rew_mean          | 45.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 404        |\n",
      "|    iterations           | 554        |\n",
      "|    time_elapsed         | 5615       |\n",
      "|    total_timesteps      | 2269184    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01221714 |\n",
      "|    clip_fraction        | 0.333      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.54      |\n",
      "|    explained_variance   | 0.997      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | 0.00453    |\n",
      "|    n_updates            | 5530       |\n",
      "|    policy_gradient_loss | -0.0144    |\n",
      "|    value_loss           | 0.112      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2270000, episode_reward=47.78 +/- 4.78\n",
      "Episode length: 79.20 +/- 11.44\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 79.2        |\n",
      "|    mean_reward          | 47.8        |\n",
      "|    std_reward           | 4.78        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2270000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013630275 |\n",
      "|    clip_fraction        | 0.313       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.54       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0254      |\n",
      "|    n_updates            | 5540        |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    value_loss           | 0.116       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.7     |\n",
      "|    ep_rew_mean     | 46.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 555      |\n",
      "|    time_elapsed    | 5625     |\n",
      "|    total_timesteps | 2273280  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.2        |\n",
      "|    ep_rew_mean          | 47.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 556         |\n",
      "|    time_elapsed         | 5635        |\n",
      "|    total_timesteps      | 2277376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011030205 |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00311    |\n",
      "|    n_updates            | 5550        |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    value_loss           | 0.135       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2280000, episode_reward=51.34 +/- 2.73\n",
      "Episode length: 77.30 +/- 11.62\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 77.3        |\n",
      "|    mean_reward          | 51.3        |\n",
      "|    std_reward           | 2.73        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2280000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014396528 |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.000121    |\n",
      "|    n_updates            | 5560        |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    value_loss           | 0.111       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78       |\n",
      "|    ep_rew_mean     | 47.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 557      |\n",
      "|    time_elapsed    | 5646     |\n",
      "|    total_timesteps | 2281472  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.9        |\n",
      "|    ep_rew_mean          | 47.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 558         |\n",
      "|    time_elapsed         | 5655        |\n",
      "|    total_timesteps      | 2285568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012455517 |\n",
      "|    clip_fraction        | 0.28        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00507    |\n",
      "|    n_updates            | 5570        |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    value_loss           | 0.107       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.6        |\n",
      "|    ep_rew_mean          | 46.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 559         |\n",
      "|    time_elapsed         | 5665        |\n",
      "|    total_timesteps      | 2289664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011422541 |\n",
      "|    clip_fraction        | 0.305       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.53       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00159    |\n",
      "|    n_updates            | 5580        |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    value_loss           | 0.157       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2290000, episode_reward=49.02 +/- 5.39\n",
      "Episode length: 78.10 +/- 6.55\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 78.1        |\n",
      "|    mean_reward          | 49          |\n",
      "|    std_reward           | 5.39        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2290000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010633744 |\n",
      "|    clip_fraction        | 0.28        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.53       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.000957    |\n",
      "|    n_updates            | 5590        |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    value_loss           | 0.133       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.9     |\n",
      "|    ep_rew_mean     | 47.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 560      |\n",
      "|    time_elapsed    | 5676     |\n",
      "|    total_timesteps | 2293760  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.6        |\n",
      "|    ep_rew_mean          | 47          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 561         |\n",
      "|    time_elapsed         | 5685        |\n",
      "|    total_timesteps      | 2297856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011693859 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.51       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 8.56e-05    |\n",
      "|    n_updates            | 5600        |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    value_loss           | 0.141       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2300000, episode_reward=48.14 +/- 2.93\n",
      "Episode length: 79.50 +/- 8.91\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 79.5        |\n",
      "|    mean_reward          | 48.1        |\n",
      "|    std_reward           | 2.93        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2300000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013021024 |\n",
      "|    clip_fraction        | 0.301       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.54       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.000187    |\n",
      "|    n_updates            | 5610        |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    value_loss           | 0.125       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.9     |\n",
      "|    ep_rew_mean     | 47       |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 562      |\n",
      "|    time_elapsed    | 5696     |\n",
      "|    total_timesteps | 2301952  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 79.7       |\n",
      "|    ep_rew_mean          | 46.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 404        |\n",
      "|    iterations           | 563        |\n",
      "|    time_elapsed         | 5706       |\n",
      "|    total_timesteps      | 2306048    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01016221 |\n",
      "|    clip_fraction        | 0.283      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.52      |\n",
      "|    explained_variance   | 0.997      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.0018    |\n",
      "|    n_updates            | 5620       |\n",
      "|    policy_gradient_loss | -0.0173    |\n",
      "|    value_loss           | 0.12       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2310000, episode_reward=48.63 +/- 4.66\n",
      "Episode length: 75.10 +/- 7.50\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 75.1        |\n",
      "|    mean_reward          | 48.6        |\n",
      "|    std_reward           | 4.66        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2310000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013862133 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00713     |\n",
      "|    n_updates            | 5630        |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    value_loss           | 0.152       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.5     |\n",
      "|    ep_rew_mean     | 46.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 564      |\n",
      "|    time_elapsed    | 5717     |\n",
      "|    total_timesteps | 2310144  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.6        |\n",
      "|    ep_rew_mean          | 46          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 565         |\n",
      "|    time_elapsed         | 5726        |\n",
      "|    total_timesteps      | 2314240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012091658 |\n",
      "|    clip_fraction        | 0.289       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.55       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00847     |\n",
      "|    n_updates            | 5640        |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    value_loss           | 0.16        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.7        |\n",
      "|    ep_rew_mean          | 46.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 566         |\n",
      "|    time_elapsed         | 5736        |\n",
      "|    total_timesteps      | 2318336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014573259 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.53       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00478    |\n",
      "|    n_updates            | 5650        |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    value_loss           | 0.188       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2320000, episode_reward=47.88 +/- 4.80\n",
      "Episode length: 77.00 +/- 9.07\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 77          |\n",
      "|    mean_reward          | 47.9        |\n",
      "|    std_reward           | 4.8         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2320000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014478233 |\n",
      "|    clip_fraction        | 0.326       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.51       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00836    |\n",
      "|    n_updates            | 5660        |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    value_loss           | 0.123       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.3     |\n",
      "|    ep_rew_mean     | 46.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 567      |\n",
      "|    time_elapsed    | 5747     |\n",
      "|    total_timesteps | 2322432  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.3        |\n",
      "|    ep_rew_mean          | 48.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 568         |\n",
      "|    time_elapsed         | 5757        |\n",
      "|    total_timesteps      | 2326528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011586402 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.51       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0244     |\n",
      "|    n_updates            | 5670        |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    value_loss           | 0.102       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2330000, episode_reward=49.69 +/- 5.19\n",
      "Episode length: 77.90 +/- 8.46\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 77.9        |\n",
      "|    mean_reward          | 49.7        |\n",
      "|    std_reward           | 5.19        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2330000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013972668 |\n",
      "|    clip_fraction        | 0.319       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.51       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00378    |\n",
      "|    n_updates            | 5680        |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    value_loss           | 0.0937      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.7     |\n",
      "|    ep_rew_mean     | 47.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 569      |\n",
      "|    time_elapsed    | 5767     |\n",
      "|    total_timesteps | 2330624  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.2        |\n",
      "|    ep_rew_mean          | 47.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 570         |\n",
      "|    time_elapsed         | 5777        |\n",
      "|    total_timesteps      | 2334720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011320685 |\n",
      "|    clip_fraction        | 0.302       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0141     |\n",
      "|    n_updates            | 5690        |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    value_loss           | 0.104       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.5        |\n",
      "|    ep_rew_mean          | 47.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 571         |\n",
      "|    time_elapsed         | 5787        |\n",
      "|    total_timesteps      | 2338816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012245799 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0154     |\n",
      "|    n_updates            | 5700        |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    value_loss           | 0.109       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2340000, episode_reward=48.45 +/- 5.72\n",
      "Episode length: 76.20 +/- 7.04\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 76.2        |\n",
      "|    mean_reward          | 48.5        |\n",
      "|    std_reward           | 5.72        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2340000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011409365 |\n",
      "|    clip_fraction        | 0.303       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.51       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0152     |\n",
      "|    n_updates            | 5710        |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    value_loss           | 0.103       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.2     |\n",
      "|    ep_rew_mean     | 47.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 572      |\n",
      "|    time_elapsed    | 5798     |\n",
      "|    total_timesteps | 2342912  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.1        |\n",
      "|    ep_rew_mean          | 47.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 573         |\n",
      "|    time_elapsed         | 5807        |\n",
      "|    total_timesteps      | 2347008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013912965 |\n",
      "|    clip_fraction        | 0.309       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.009      |\n",
      "|    n_updates            | 5720        |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    value_loss           | 0.0935      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2350000, episode_reward=47.02 +/- 5.84\n",
      "Episode length: 77.40 +/- 9.89\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 77.4        |\n",
      "|    mean_reward          | 47          |\n",
      "|    std_reward           | 5.84        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2350000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012617889 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00523     |\n",
      "|    n_updates            | 5730        |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    value_loss           | 0.141       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79       |\n",
      "|    ep_rew_mean     | 46.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 574      |\n",
      "|    time_elapsed    | 5818     |\n",
      "|    total_timesteps | 2351104  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.4        |\n",
      "|    ep_rew_mean          | 47.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 575         |\n",
      "|    time_elapsed         | 5828        |\n",
      "|    total_timesteps      | 2355200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012642826 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.51       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.011      |\n",
      "|    n_updates            | 5740        |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    value_loss           | 0.121       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77          |\n",
      "|    ep_rew_mean          | 47.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 576         |\n",
      "|    time_elapsed         | 5838        |\n",
      "|    total_timesteps      | 2359296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011593549 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0034      |\n",
      "|    n_updates            | 5750        |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    value_loss           | 0.128       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2360000, episode_reward=49.77 +/- 5.21\n",
      "Episode length: 81.10 +/- 11.62\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 81.1        |\n",
      "|    mean_reward          | 49.8        |\n",
      "|    std_reward           | 5.21        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2360000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012741906 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00157     |\n",
      "|    n_updates            | 5760        |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    value_loss           | 0.12        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.3     |\n",
      "|    ep_rew_mean     | 47.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 577      |\n",
      "|    time_elapsed    | 5848     |\n",
      "|    total_timesteps | 2363392  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.2        |\n",
      "|    ep_rew_mean          | 47          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 578         |\n",
      "|    time_elapsed         | 5858        |\n",
      "|    total_timesteps      | 2367488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014890242 |\n",
      "|    clip_fraction        | 0.314       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.014       |\n",
      "|    n_updates            | 5770        |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    value_loss           | 0.13        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2370000, episode_reward=46.20 +/- 7.73\n",
      "Episode length: 76.30 +/- 8.09\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 76.3        |\n",
      "|    mean_reward          | 46.2        |\n",
      "|    std_reward           | 7.73        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2370000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011353973 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.51       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0144     |\n",
      "|    n_updates            | 5780        |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    value_loss           | 0.152       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.6     |\n",
      "|    ep_rew_mean     | 47.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 579      |\n",
      "|    time_elapsed    | 5869     |\n",
      "|    total_timesteps | 2371584  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.3        |\n",
      "|    ep_rew_mean          | 48.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 580         |\n",
      "|    time_elapsed         | 5879        |\n",
      "|    total_timesteps      | 2375680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011864055 |\n",
      "|    clip_fraction        | 0.32        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00374    |\n",
      "|    n_updates            | 5790        |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    value_loss           | 0.108       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.5        |\n",
      "|    ep_rew_mean          | 48          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 581         |\n",
      "|    time_elapsed         | 5888        |\n",
      "|    total_timesteps      | 2379776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012297952 |\n",
      "|    clip_fraction        | 0.294       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00272    |\n",
      "|    n_updates            | 5800        |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    value_loss           | 0.105       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2380000, episode_reward=51.44 +/- 5.38\n",
      "Episode length: 75.10 +/- 10.71\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 75.1        |\n",
      "|    mean_reward          | 51.4        |\n",
      "|    std_reward           | 5.38        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2380000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011827631 |\n",
      "|    clip_fraction        | 0.31        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.000889   |\n",
      "|    n_updates            | 5810        |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    value_loss           | 0.104       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.7     |\n",
      "|    ep_rew_mean     | 48       |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 582      |\n",
      "|    time_elapsed    | 5899     |\n",
      "|    total_timesteps | 2383872  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.1        |\n",
      "|    ep_rew_mean          | 47.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 583         |\n",
      "|    time_elapsed         | 5909        |\n",
      "|    total_timesteps      | 2387968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011706921 |\n",
      "|    clip_fraction        | 0.313       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.51       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00437     |\n",
      "|    n_updates            | 5820        |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    value_loss           | 0.0915      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2390000, episode_reward=50.19 +/- 2.88\n",
      "Episode length: 75.30 +/- 12.39\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 75.3        |\n",
      "|    mean_reward          | 50.2        |\n",
      "|    std_reward           | 2.88        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2390000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011579068 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0031     |\n",
      "|    n_updates            | 5830        |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    value_loss           | 0.119       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77       |\n",
      "|    ep_rew_mean     | 47.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 584      |\n",
      "|    time_elapsed    | 5920     |\n",
      "|    total_timesteps | 2392064  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.4        |\n",
      "|    ep_rew_mean          | 47.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 585         |\n",
      "|    time_elapsed         | 5929        |\n",
      "|    total_timesteps      | 2396160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010641741 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.000586    |\n",
      "|    n_updates            | 5840        |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    value_loss           | 0.126       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2400000, episode_reward=49.55 +/- 3.81\n",
      "Episode length: 74.30 +/- 8.94\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 74.3        |\n",
      "|    mean_reward          | 49.6        |\n",
      "|    std_reward           | 3.81        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2400000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012282701 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0062     |\n",
      "|    n_updates            | 5850        |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    value_loss           | 0.131       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.3     |\n",
      "|    ep_rew_mean     | 47.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 586      |\n",
      "|    time_elapsed    | 5940     |\n",
      "|    total_timesteps | 2400256  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.8        |\n",
      "|    ep_rew_mean          | 47.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 587         |\n",
      "|    time_elapsed         | 5950        |\n",
      "|    total_timesteps      | 2404352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012472093 |\n",
      "|    clip_fraction        | 0.305       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00661    |\n",
      "|    n_updates            | 5860        |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    value_loss           | 0.118       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.7        |\n",
      "|    ep_rew_mean          | 47          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 588         |\n",
      "|    time_elapsed         | 5960        |\n",
      "|    total_timesteps      | 2408448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013232995 |\n",
      "|    clip_fraction        | 0.314       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00958    |\n",
      "|    n_updates            | 5870        |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    value_loss           | 0.138       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2410000, episode_reward=48.54 +/- 4.92\n",
      "Episode length: 77.30 +/- 9.04\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 77.3        |\n",
      "|    mean_reward          | 48.5        |\n",
      "|    std_reward           | 4.92        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2410000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009674359 |\n",
      "|    clip_fraction        | 0.293       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00817    |\n",
      "|    n_updates            | 5880        |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    value_loss           | 0.128       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.2     |\n",
      "|    ep_rew_mean     | 46.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 589      |\n",
      "|    time_elapsed    | 5971     |\n",
      "|    total_timesteps | 2412544  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.2        |\n",
      "|    ep_rew_mean          | 48          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 590         |\n",
      "|    time_elapsed         | 5980        |\n",
      "|    total_timesteps      | 2416640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011831684 |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00504    |\n",
      "|    n_updates            | 5890        |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    value_loss           | 0.107       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2420000, episode_reward=50.64 +/- 3.61\n",
      "Episode length: 73.30 +/- 6.34\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 73.3       |\n",
      "|    mean_reward          | 50.6       |\n",
      "|    std_reward           | 3.61       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2420000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01107015 |\n",
      "|    clip_fraction        | 0.308      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.45      |\n",
      "|    explained_variance   | 0.997      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | 0.00073    |\n",
      "|    n_updates            | 5900       |\n",
      "|    policy_gradient_loss | -0.0169    |\n",
      "|    value_loss           | 0.111      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 76.5     |\n",
      "|    ep_rew_mean     | 49.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 591      |\n",
      "|    time_elapsed    | 5991     |\n",
      "|    total_timesteps | 2420736  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.9        |\n",
      "|    ep_rew_mean          | 48.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 592         |\n",
      "|    time_elapsed         | 6001        |\n",
      "|    total_timesteps      | 2424832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014758263 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00116     |\n",
      "|    n_updates            | 5910        |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    value_loss           | 0.117       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79          |\n",
      "|    ep_rew_mean          | 47.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 593         |\n",
      "|    time_elapsed         | 6011        |\n",
      "|    total_timesteps      | 2428928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011346135 |\n",
      "|    clip_fraction        | 0.294       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00788    |\n",
      "|    n_updates            | 5920        |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    value_loss           | 0.0933      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2430000, episode_reward=48.71 +/- 5.03\n",
      "Episode length: 81.30 +/- 10.33\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 81.3        |\n",
      "|    mean_reward          | 48.7        |\n",
      "|    std_reward           | 5.03        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2430000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012791717 |\n",
      "|    clip_fraction        | 0.301       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0141      |\n",
      "|    n_updates            | 5930        |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    value_loss           | 0.122       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.8     |\n",
      "|    ep_rew_mean     | 46.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 594      |\n",
      "|    time_elapsed    | 6022     |\n",
      "|    total_timesteps | 2433024  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.4        |\n",
      "|    ep_rew_mean          | 47.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 595         |\n",
      "|    time_elapsed         | 6031        |\n",
      "|    total_timesteps      | 2437120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011895487 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00719    |\n",
      "|    n_updates            | 5940        |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    value_loss           | 0.105       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2440000, episode_reward=49.52 +/- 3.78\n",
      "Episode length: 75.20 +/- 9.31\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 75.2        |\n",
      "|    mean_reward          | 49.5        |\n",
      "|    std_reward           | 3.78        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2440000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011433358 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0104     |\n",
      "|    n_updates            | 5950        |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    value_loss           | 0.118       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 76.8     |\n",
      "|    ep_rew_mean     | 48.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 596      |\n",
      "|    time_elapsed    | 6042     |\n",
      "|    total_timesteps | 2441216  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.4        |\n",
      "|    ep_rew_mean          | 48.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 597         |\n",
      "|    time_elapsed         | 6052        |\n",
      "|    total_timesteps      | 2445312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011541475 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00252     |\n",
      "|    n_updates            | 5960        |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    value_loss           | 0.118       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.4        |\n",
      "|    ep_rew_mean          | 47.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 598         |\n",
      "|    time_elapsed         | 6061        |\n",
      "|    total_timesteps      | 2449408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013909176 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.45       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00178    |\n",
      "|    n_updates            | 5970        |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    value_loss           | 0.107       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2450000, episode_reward=48.49 +/- 4.28\n",
      "Episode length: 82.20 +/- 10.77\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 82.2        |\n",
      "|    mean_reward          | 48.5        |\n",
      "|    std_reward           | 4.28        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2450000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011890939 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00301    |\n",
      "|    n_updates            | 5980        |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 0.12        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.9     |\n",
      "|    ep_rew_mean     | 46.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 599      |\n",
      "|    time_elapsed    | 6072     |\n",
      "|    total_timesteps | 2453504  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.5        |\n",
      "|    ep_rew_mean          | 47.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 600         |\n",
      "|    time_elapsed         | 6082        |\n",
      "|    total_timesteps      | 2457600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012209773 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00564     |\n",
      "|    n_updates            | 5990        |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    value_loss           | 0.133       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2460000, episode_reward=51.14 +/- 4.60\n",
      "Episode length: 75.60 +/- 5.80\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 75.6        |\n",
      "|    mean_reward          | 51.1        |\n",
      "|    std_reward           | 4.6         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2460000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012053383 |\n",
      "|    clip_fraction        | 0.305       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00132     |\n",
      "|    n_updates            | 6000        |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    value_loss           | 0.126       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78       |\n",
      "|    ep_rew_mean     | 48.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 601      |\n",
      "|    time_elapsed    | 6093     |\n",
      "|    total_timesteps | 2461696  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.9        |\n",
      "|    ep_rew_mean          | 47.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 602         |\n",
      "|    time_elapsed         | 6103        |\n",
      "|    total_timesteps      | 2465792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012621847 |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.46       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00321    |\n",
      "|    n_updates            | 6010        |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    value_loss           | 0.104       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.1        |\n",
      "|    ep_rew_mean          | 48.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 603         |\n",
      "|    time_elapsed         | 6112        |\n",
      "|    total_timesteps      | 2469888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014774614 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0126     |\n",
      "|    n_updates            | 6020        |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    value_loss           | 0.099       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2470000, episode_reward=51.31 +/- 2.59\n",
      "Episode length: 74.20 +/- 7.78\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 74.2        |\n",
      "|    mean_reward          | 51.3        |\n",
      "|    std_reward           | 2.59        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2470000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012234656 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.45       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00984     |\n",
      "|    n_updates            | 6030        |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    value_loss           | 0.119       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.1     |\n",
      "|    ep_rew_mean     | 48.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 604      |\n",
      "|    time_elapsed    | 6123     |\n",
      "|    total_timesteps | 2473984  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.2        |\n",
      "|    ep_rew_mean          | 48.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 605         |\n",
      "|    time_elapsed         | 6132        |\n",
      "|    total_timesteps      | 2478080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012186372 |\n",
      "|    clip_fraction        | 0.284       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.45       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0107      |\n",
      "|    n_updates            | 6040        |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    value_loss           | 0.115       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2480000, episode_reward=49.98 +/- 3.89\n",
      "Episode length: 75.60 +/- 9.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 75.6        |\n",
      "|    mean_reward          | 50          |\n",
      "|    std_reward           | 3.89        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2480000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009312996 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.45       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0168      |\n",
      "|    n_updates            | 6050        |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    value_loss           | 0.136       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 76.9     |\n",
      "|    ep_rew_mean     | 48.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 606      |\n",
      "|    time_elapsed    | 6143     |\n",
      "|    total_timesteps | 2482176  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.8        |\n",
      "|    ep_rew_mean          | 47.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 607         |\n",
      "|    time_elapsed         | 6153        |\n",
      "|    total_timesteps      | 2486272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011860778 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.012      |\n",
      "|    n_updates            | 6060        |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    value_loss           | 0.113       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2490000, episode_reward=47.33 +/- 3.12\n",
      "Episode length: 79.70 +/- 9.63\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 79.7        |\n",
      "|    mean_reward          | 47.3        |\n",
      "|    std_reward           | 3.12        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2490000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012572355 |\n",
      "|    clip_fraction        | 0.289       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.44       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00125     |\n",
      "|    n_updates            | 6070        |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    value_loss           | 0.147       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.1     |\n",
      "|    ep_rew_mean     | 47.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 608      |\n",
      "|    time_elapsed    | 6164     |\n",
      "|    total_timesteps | 2490368  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.2        |\n",
      "|    ep_rew_mean          | 48.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 609         |\n",
      "|    time_elapsed         | 6173        |\n",
      "|    total_timesteps      | 2494464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013018208 |\n",
      "|    clip_fraction        | 0.302       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00226    |\n",
      "|    n_updates            | 6080        |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    value_loss           | 0.121       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.1        |\n",
      "|    ep_rew_mean          | 48          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 610         |\n",
      "|    time_elapsed         | 6183        |\n",
      "|    total_timesteps      | 2498560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010755084 |\n",
      "|    clip_fraction        | 0.294       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.46       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.000306    |\n",
      "|    n_updates            | 6090        |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    value_loss           | 0.133       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2500000, episode_reward=48.38 +/- 6.87\n",
      "Episode length: 80.60 +/- 7.13\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 80.6        |\n",
      "|    mean_reward          | 48.4        |\n",
      "|    std_reward           | 6.87        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2500000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011931517 |\n",
      "|    clip_fraction        | 0.284       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0108     |\n",
      "|    n_updates            | 6100        |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    value_loss           | 0.122       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.2     |\n",
      "|    ep_rew_mean     | 47.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 611      |\n",
      "|    time_elapsed    | 6194     |\n",
      "|    total_timesteps | 2502656  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.7        |\n",
      "|    ep_rew_mean          | 47.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 612         |\n",
      "|    time_elapsed         | 6203        |\n",
      "|    total_timesteps      | 2506752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010418931 |\n",
      "|    clip_fraction        | 0.313       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.46       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0139     |\n",
      "|    n_updates            | 6110        |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    value_loss           | 0.134       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2510000, episode_reward=50.47 +/- 4.67\n",
      "Episode length: 74.90 +/- 8.99\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 74.9        |\n",
      "|    mean_reward          | 50.5        |\n",
      "|    std_reward           | 4.67        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2510000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014271736 |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.46       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00462     |\n",
      "|    n_updates            | 6120        |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    value_loss           | 0.156       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 76.8     |\n",
      "|    ep_rew_mean     | 48.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 613      |\n",
      "|    time_elapsed    | 6214     |\n",
      "|    total_timesteps | 2510848  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78          |\n",
      "|    ep_rew_mean          | 47.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 614         |\n",
      "|    time_elapsed         | 6224        |\n",
      "|    total_timesteps      | 2514944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014193926 |\n",
      "|    clip_fraction        | 0.35        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00583    |\n",
      "|    n_updates            | 6130        |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    value_loss           | 0.083       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.4        |\n",
      "|    ep_rew_mean          | 47.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 615         |\n",
      "|    time_elapsed         | 6234        |\n",
      "|    total_timesteps      | 2519040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011664504 |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.46       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00791     |\n",
      "|    n_updates            | 6140        |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    value_loss           | 0.104       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2520000, episode_reward=44.98 +/- 4.06\n",
      "Episode length: 81.40 +/- 8.25\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 81.4        |\n",
      "|    mean_reward          | 45          |\n",
      "|    std_reward           | 4.06        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2520000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011916835 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0087     |\n",
      "|    n_updates            | 6150        |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    value_loss           | 0.111       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.7     |\n",
      "|    ep_rew_mean     | 47.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 616      |\n",
      "|    time_elapsed    | 6245     |\n",
      "|    total_timesteps | 2523136  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.9        |\n",
      "|    ep_rew_mean          | 48          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 617         |\n",
      "|    time_elapsed         | 6255        |\n",
      "|    total_timesteps      | 2527232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010000117 |\n",
      "|    clip_fraction        | 0.284       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.46       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00623     |\n",
      "|    n_updates            | 6160        |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    value_loss           | 0.169       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2530000, episode_reward=50.37 +/- 3.94\n",
      "Episode length: 80.40 +/- 6.92\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 80.4        |\n",
      "|    mean_reward          | 50.4        |\n",
      "|    std_reward           | 3.94        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2530000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013890412 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0121     |\n",
      "|    n_updates            | 6170        |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    value_loss           | 0.101       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.6     |\n",
      "|    ep_rew_mean     | 48       |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 618      |\n",
      "|    time_elapsed    | 6266     |\n",
      "|    total_timesteps | 2531328  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78          |\n",
      "|    ep_rew_mean          | 48.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 619         |\n",
      "|    time_elapsed         | 6276        |\n",
      "|    total_timesteps      | 2535424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011875607 |\n",
      "|    clip_fraction        | 0.289       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0164     |\n",
      "|    n_updates            | 6180        |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    value_loss           | 0.108       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78          |\n",
      "|    ep_rew_mean          | 48.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 620         |\n",
      "|    time_elapsed         | 6285        |\n",
      "|    total_timesteps      | 2539520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012884464 |\n",
      "|    clip_fraction        | 0.31        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00501    |\n",
      "|    n_updates            | 6190        |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    value_loss           | 0.15        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2540000, episode_reward=49.18 +/- 4.00\n",
      "Episode length: 81.70 +/- 8.64\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 81.7        |\n",
      "|    mean_reward          | 49.2        |\n",
      "|    std_reward           | 4           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2540000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013537578 |\n",
      "|    clip_fraction        | 0.305       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00574     |\n",
      "|    n_updates            | 6200        |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    value_loss           | 0.123       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.2     |\n",
      "|    ep_rew_mean     | 48.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 621      |\n",
      "|    time_elapsed    | 6296     |\n",
      "|    total_timesteps | 2543616  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 77.1       |\n",
      "|    ep_rew_mean          | 47.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 404        |\n",
      "|    iterations           | 622        |\n",
      "|    time_elapsed         | 6306       |\n",
      "|    total_timesteps      | 2547712    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01277951 |\n",
      "|    clip_fraction        | 0.318      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.49      |\n",
      "|    explained_variance   | 0.997      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.0127    |\n",
      "|    n_updates            | 6210       |\n",
      "|    policy_gradient_loss | -0.0164    |\n",
      "|    value_loss           | 0.114      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2550000, episode_reward=51.01 +/- 4.24\n",
      "Episode length: 75.70 +/- 9.25\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 75.7       |\n",
      "|    mean_reward          | 51         |\n",
      "|    std_reward           | 4.24       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2550000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01182943 |\n",
      "|    clip_fraction        | 0.317      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.49      |\n",
      "|    explained_variance   | 0.996      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.00551   |\n",
      "|    n_updates            | 6220       |\n",
      "|    policy_gradient_loss | -0.0186    |\n",
      "|    value_loss           | 0.126      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 75.3     |\n",
      "|    ep_rew_mean     | 47.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 623      |\n",
      "|    time_elapsed    | 6317     |\n",
      "|    total_timesteps | 2551808  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.4        |\n",
      "|    ep_rew_mean          | 46.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 624         |\n",
      "|    time_elapsed         | 6326        |\n",
      "|    total_timesteps      | 2555904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012311539 |\n",
      "|    clip_fraction        | 0.303       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0116     |\n",
      "|    n_updates            | 6230        |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    value_loss           | 0.126       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2560000, episode_reward=51.39 +/- 3.79\n",
      "Episode length: 73.20 +/- 9.86\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 73.2        |\n",
      "|    mean_reward          | 51.4        |\n",
      "|    std_reward           | 3.79        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2560000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013317865 |\n",
      "|    clip_fraction        | 0.309       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.51       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.000291    |\n",
      "|    n_updates            | 6240        |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    value_loss           | 0.135       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 80.4     |\n",
      "|    ep_rew_mean     | 46.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 625      |\n",
      "|    time_elapsed    | 6337     |\n",
      "|    total_timesteps | 2560000  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.7        |\n",
      "|    ep_rew_mean          | 48          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 626         |\n",
      "|    time_elapsed         | 6347        |\n",
      "|    total_timesteps      | 2564096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011996381 |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.51       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0102     |\n",
      "|    n_updates            | 6250        |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 0.124       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 76.8       |\n",
      "|    ep_rew_mean          | 46.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 404        |\n",
      "|    iterations           | 627        |\n",
      "|    time_elapsed         | 6356       |\n",
      "|    total_timesteps      | 2568192    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01260454 |\n",
      "|    clip_fraction        | 0.281      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.5       |\n",
      "|    explained_variance   | 0.996      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.0004    |\n",
      "|    n_updates            | 6260       |\n",
      "|    policy_gradient_loss | -0.0155    |\n",
      "|    value_loss           | 0.165      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2570000, episode_reward=49.17 +/- 6.34\n",
      "Episode length: 77.20 +/- 10.81\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 77.2        |\n",
      "|    mean_reward          | 49.2        |\n",
      "|    std_reward           | 6.34        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2570000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014978387 |\n",
      "|    clip_fraction        | 0.314       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00369    |\n",
      "|    n_updates            | 6270        |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    value_loss           | 0.153       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.2     |\n",
      "|    ep_rew_mean     | 46.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 628      |\n",
      "|    time_elapsed    | 6367     |\n",
      "|    total_timesteps | 2572288  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.2        |\n",
      "|    ep_rew_mean          | 47.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 629         |\n",
      "|    time_elapsed         | 6377        |\n",
      "|    total_timesteps      | 2576384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014268309 |\n",
      "|    clip_fraction        | 0.334       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0114      |\n",
      "|    n_updates            | 6280        |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    value_loss           | 0.119       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2580000, episode_reward=46.25 +/- 4.92\n",
      "Episode length: 79.50 +/- 6.20\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 79.5        |\n",
      "|    mean_reward          | 46.3        |\n",
      "|    std_reward           | 4.92        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2580000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012411246 |\n",
      "|    clip_fraction        | 0.312       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00544    |\n",
      "|    n_updates            | 6290        |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    value_loss           | 0.109       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.4     |\n",
      "|    ep_rew_mean     | 46.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 630      |\n",
      "|    time_elapsed    | 6388     |\n",
      "|    total_timesteps | 2580480  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.4        |\n",
      "|    ep_rew_mean          | 47.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 631         |\n",
      "|    time_elapsed         | 6397        |\n",
      "|    total_timesteps      | 2584576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014479624 |\n",
      "|    clip_fraction        | 0.31        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 1.63e-05    |\n",
      "|    n_updates            | 6300        |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    value_loss           | 0.11        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.5        |\n",
      "|    ep_rew_mean          | 47.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 632         |\n",
      "|    time_elapsed         | 6407        |\n",
      "|    total_timesteps      | 2588672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012287339 |\n",
      "|    clip_fraction        | 0.303       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.46       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00133    |\n",
      "|    n_updates            | 6310        |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    value_loss           | 0.114       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2590000, episode_reward=48.17 +/- 5.50\n",
      "Episode length: 78.30 +/- 12.85\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 78.3        |\n",
      "|    mean_reward          | 48.2        |\n",
      "|    std_reward           | 5.5         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2590000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011597303 |\n",
      "|    clip_fraction        | 0.287       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00348    |\n",
      "|    n_updates            | 6320        |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    value_loss           | 0.158       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.8     |\n",
      "|    ep_rew_mean     | 47.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 633      |\n",
      "|    time_elapsed    | 6418     |\n",
      "|    total_timesteps | 2592768  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78.6         |\n",
      "|    ep_rew_mean          | 47.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 403          |\n",
      "|    iterations           | 634          |\n",
      "|    time_elapsed         | 6428         |\n",
      "|    total_timesteps      | 2596864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0140402615 |\n",
      "|    clip_fraction        | 0.292        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.44        |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0599       |\n",
      "|    n_updates            | 6330         |\n",
      "|    policy_gradient_loss | -0.0137      |\n",
      "|    value_loss           | 0.121        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2600000, episode_reward=48.48 +/- 8.09\n",
      "Episode length: 75.90 +/- 8.97\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 75.9       |\n",
      "|    mean_reward          | 48.5       |\n",
      "|    std_reward           | 8.09       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2600000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01133813 |\n",
      "|    clip_fraction        | 0.286      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.45      |\n",
      "|    explained_variance   | 0.997      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.00832   |\n",
      "|    n_updates            | 6340       |\n",
      "|    policy_gradient_loss | -0.0138    |\n",
      "|    value_loss           | 0.128      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.3     |\n",
      "|    ep_rew_mean     | 47.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 635      |\n",
      "|    time_elapsed    | 6438     |\n",
      "|    total_timesteps | 2600960  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.6        |\n",
      "|    ep_rew_mean          | 47.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 636         |\n",
      "|    time_elapsed         | 6448        |\n",
      "|    total_timesteps      | 2605056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011486877 |\n",
      "|    clip_fraction        | 0.294       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.44       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0112      |\n",
      "|    n_updates            | 6350        |\n",
      "|    policy_gradient_loss | -0.0181     |\n",
      "|    value_loss           | 0.129       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78          |\n",
      "|    ep_rew_mean          | 48.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 637         |\n",
      "|    time_elapsed         | 6458        |\n",
      "|    total_timesteps      | 2609152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012543656 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00982    |\n",
      "|    n_updates            | 6360        |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    value_loss           | 0.13        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2610000, episode_reward=49.71 +/- 4.11\n",
      "Episode length: 84.80 +/- 5.86\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 84.8       |\n",
      "|    mean_reward          | 49.7       |\n",
      "|    std_reward           | 4.11       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2610000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01513656 |\n",
      "|    clip_fraction        | 0.315      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.46      |\n",
      "|    explained_variance   | 0.997      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.0106    |\n",
      "|    n_updates            | 6370       |\n",
      "|    policy_gradient_loss | -0.0147    |\n",
      "|    value_loss           | 0.114      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.7     |\n",
      "|    ep_rew_mean     | 48.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 638      |\n",
      "|    time_elapsed    | 6469     |\n",
      "|    total_timesteps | 2613248  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.7        |\n",
      "|    ep_rew_mean          | 48.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 639         |\n",
      "|    time_elapsed         | 6478        |\n",
      "|    total_timesteps      | 2617344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012647839 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00882    |\n",
      "|    n_updates            | 6380        |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    value_loss           | 0.126       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2620000, episode_reward=49.94 +/- 4.79\n",
      "Episode length: 84.10 +/- 7.97\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 84.1        |\n",
      "|    mean_reward          | 49.9        |\n",
      "|    std_reward           | 4.79        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2620000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013201859 |\n",
      "|    clip_fraction        | 0.32        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0053     |\n",
      "|    n_updates            | 6390        |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    value_loss           | 0.118       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.7     |\n",
      "|    ep_rew_mean     | 47.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 640      |\n",
      "|    time_elapsed    | 6490     |\n",
      "|    total_timesteps | 2621440  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.2        |\n",
      "|    ep_rew_mean          | 47.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 641         |\n",
      "|    time_elapsed         | 6499        |\n",
      "|    total_timesteps      | 2625536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014374604 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00812     |\n",
      "|    n_updates            | 6400        |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    value_loss           | 0.165       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.6        |\n",
      "|    ep_rew_mean          | 47.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 642         |\n",
      "|    time_elapsed         | 6509        |\n",
      "|    total_timesteps      | 2629632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014281574 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00835    |\n",
      "|    n_updates            | 6410        |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    value_loss           | 0.115       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2630000, episode_reward=48.44 +/- 6.32\n",
      "Episode length: 82.90 +/- 10.27\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 82.9        |\n",
      "|    mean_reward          | 48.4        |\n",
      "|    std_reward           | 6.32        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2630000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015454202 |\n",
      "|    clip_fraction        | 0.325       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0129     |\n",
      "|    n_updates            | 6420        |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 0.101       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.9     |\n",
      "|    ep_rew_mean     | 47.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 643      |\n",
      "|    time_elapsed    | 6520     |\n",
      "|    total_timesteps | 2633728  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.4        |\n",
      "|    ep_rew_mean          | 47.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 644         |\n",
      "|    time_elapsed         | 6530        |\n",
      "|    total_timesteps      | 2637824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013587121 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.46       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0262      |\n",
      "|    n_updates            | 6430        |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    value_loss           | 0.112       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2640000, episode_reward=51.72 +/- 2.49\n",
      "Episode length: 72.70 +/- 6.84\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 72.7         |\n",
      "|    mean_reward          | 51.7         |\n",
      "|    std_reward           | 2.49         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2640000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0123662595 |\n",
      "|    clip_fraction        | 0.294        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.47        |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00789     |\n",
      "|    n_updates            | 6440         |\n",
      "|    policy_gradient_loss | -0.0165      |\n",
      "|    value_loss           | 0.122        |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.2     |\n",
      "|    ep_rew_mean     | 47.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 645      |\n",
      "|    time_elapsed    | 6540     |\n",
      "|    total_timesteps | 2641920  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79          |\n",
      "|    ep_rew_mean          | 47.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 646         |\n",
      "|    time_elapsed         | 6550        |\n",
      "|    total_timesteps      | 2646016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012421867 |\n",
      "|    clip_fraction        | 0.315       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.45       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00838     |\n",
      "|    n_updates            | 6450        |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    value_loss           | 0.124       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2650000, episode_reward=48.12 +/- 6.55\n",
      "Episode length: 76.50 +/- 12.13\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 76.5        |\n",
      "|    mean_reward          | 48.1        |\n",
      "|    std_reward           | 6.55        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2650000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011371791 |\n",
      "|    clip_fraction        | 0.294       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.000357   |\n",
      "|    n_updates            | 6460        |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    value_loss           | 0.144       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.3     |\n",
      "|    ep_rew_mean     | 47.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 647      |\n",
      "|    time_elapsed    | 6561     |\n",
      "|    total_timesteps | 2650112  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.6        |\n",
      "|    ep_rew_mean          | 47.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 648         |\n",
      "|    time_elapsed         | 6571        |\n",
      "|    total_timesteps      | 2654208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016579632 |\n",
      "|    clip_fraction        | 0.324       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.015      |\n",
      "|    n_updates            | 6470        |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    value_loss           | 0.116       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.6        |\n",
      "|    ep_rew_mean          | 48          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 649         |\n",
      "|    time_elapsed         | 6581        |\n",
      "|    total_timesteps      | 2658304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012592307 |\n",
      "|    clip_fraction        | 0.315       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0039      |\n",
      "|    n_updates            | 6480        |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    value_loss           | 0.104       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2660000, episode_reward=51.66 +/- 3.92\n",
      "Episode length: 77.70 +/- 8.82\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 77.7        |\n",
      "|    mean_reward          | 51.7        |\n",
      "|    std_reward           | 3.92        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2660000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014004243 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.46       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00944    |\n",
      "|    n_updates            | 6490        |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    value_loss           | 0.0962      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.3     |\n",
      "|    ep_rew_mean     | 48.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 650      |\n",
      "|    time_elapsed    | 6591     |\n",
      "|    total_timesteps | 2662400  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78.6         |\n",
      "|    ep_rew_mean          | 48.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 403          |\n",
      "|    iterations           | 651          |\n",
      "|    time_elapsed         | 6601         |\n",
      "|    total_timesteps      | 2666496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0122914575 |\n",
      "|    clip_fraction        | 0.318        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.5         |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.00801      |\n",
      "|    n_updates            | 6500         |\n",
      "|    policy_gradient_loss | -0.0144      |\n",
      "|    value_loss           | 0.0971       |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2670000, episode_reward=49.01 +/- 5.11\n",
      "Episode length: 75.20 +/- 10.22\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 75.2        |\n",
      "|    mean_reward          | 49          |\n",
      "|    std_reward           | 5.11        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2670000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015618941 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00484    |\n",
      "|    n_updates            | 6510        |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    value_loss           | 0.0935      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.9     |\n",
      "|    ep_rew_mean     | 47.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 652      |\n",
      "|    time_elapsed    | 6612     |\n",
      "|    total_timesteps | 2670592  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 80.1        |\n",
      "|    ep_rew_mean          | 47.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 653         |\n",
      "|    time_elapsed         | 6622        |\n",
      "|    total_timesteps      | 2674688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013478052 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.45       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.012      |\n",
      "|    n_updates            | 6520        |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    value_loss           | 0.117       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.5        |\n",
      "|    ep_rew_mean          | 47.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 654         |\n",
      "|    time_elapsed         | 6631        |\n",
      "|    total_timesteps      | 2678784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011667976 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.46       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0108     |\n",
      "|    n_updates            | 6530        |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    value_loss           | 0.0956      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2680000, episode_reward=48.80 +/- 4.83\n",
      "Episode length: 79.60 +/- 11.46\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 79.6        |\n",
      "|    mean_reward          | 48.8        |\n",
      "|    std_reward           | 4.83        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2680000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014994029 |\n",
      "|    clip_fraction        | 0.318       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0072      |\n",
      "|    n_updates            | 6540        |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    value_loss           | 0.0921      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.9     |\n",
      "|    ep_rew_mean     | 48       |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 655      |\n",
      "|    time_elapsed    | 6643     |\n",
      "|    total_timesteps | 2682880  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 78.7       |\n",
      "|    ep_rew_mean          | 47.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 403        |\n",
      "|    iterations           | 656        |\n",
      "|    time_elapsed         | 6652       |\n",
      "|    total_timesteps      | 2686976    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01319585 |\n",
      "|    clip_fraction        | 0.308      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.48      |\n",
      "|    explained_variance   | 0.997      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.015     |\n",
      "|    n_updates            | 6550       |\n",
      "|    policy_gradient_loss | -0.0161    |\n",
      "|    value_loss           | 0.0986     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2690000, episode_reward=49.77 +/- 4.14\n",
      "Episode length: 77.30 +/- 5.71\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 77.3         |\n",
      "|    mean_reward          | 49.8         |\n",
      "|    std_reward           | 4.14         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2690000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0096789785 |\n",
      "|    clip_fraction        | 0.254        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.45        |\n",
      "|    explained_variance   | 0.994        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00154     |\n",
      "|    n_updates            | 6560         |\n",
      "|    policy_gradient_loss | -0.0132      |\n",
      "|    value_loss           | 0.169        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.2     |\n",
      "|    ep_rew_mean     | 47.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 657      |\n",
      "|    time_elapsed    | 6663     |\n",
      "|    total_timesteps | 2691072  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78.4         |\n",
      "|    ep_rew_mean          | 47.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 403          |\n",
      "|    iterations           | 658          |\n",
      "|    time_elapsed         | 6673         |\n",
      "|    total_timesteps      | 2695168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0104966145 |\n",
      "|    clip_fraction        | 0.287        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.45        |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00385     |\n",
      "|    n_updates            | 6570         |\n",
      "|    policy_gradient_loss | -0.0154      |\n",
      "|    value_loss           | 0.108        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.8        |\n",
      "|    ep_rew_mean          | 47.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 659         |\n",
      "|    time_elapsed         | 6683        |\n",
      "|    total_timesteps      | 2699264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014865794 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.46       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0115     |\n",
      "|    n_updates            | 6580        |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    value_loss           | 0.0999      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2700000, episode_reward=50.56 +/- 5.94\n",
      "Episode length: 79.30 +/- 10.93\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 79.3         |\n",
      "|    mean_reward          | 50.6         |\n",
      "|    std_reward           | 5.94         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2700000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0135654155 |\n",
      "|    clip_fraction        | 0.312        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.47        |\n",
      "|    explained_variance   | 0.998        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00522     |\n",
      "|    n_updates            | 6590         |\n",
      "|    policy_gradient_loss | -0.0166      |\n",
      "|    value_loss           | 0.0978       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.7     |\n",
      "|    ep_rew_mean     | 47.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 660      |\n",
      "|    time_elapsed    | 6694     |\n",
      "|    total_timesteps | 2703360  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78          |\n",
      "|    ep_rew_mean          | 47.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 661         |\n",
      "|    time_elapsed         | 6703        |\n",
      "|    total_timesteps      | 2707456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012564225 |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.45       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00436    |\n",
      "|    n_updates            | 6600        |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    value_loss           | 0.0906      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2710000, episode_reward=48.04 +/- 3.97\n",
      "Episode length: 83.70 +/- 9.65\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 83.7        |\n",
      "|    mean_reward          | 48          |\n",
      "|    std_reward           | 3.97        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2710000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012179608 |\n",
      "|    clip_fraction        | 0.289       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00875    |\n",
      "|    n_updates            | 6610        |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    value_loss           | 0.113       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.5     |\n",
      "|    ep_rew_mean     | 47       |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 662      |\n",
      "|    time_elapsed    | 6714     |\n",
      "|    total_timesteps | 2711552  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.6        |\n",
      "|    ep_rew_mean          | 46.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 663         |\n",
      "|    time_elapsed         | 6724        |\n",
      "|    total_timesteps      | 2715648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011360587 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.46       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00774     |\n",
      "|    n_updates            | 6620        |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 0.138       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.5        |\n",
      "|    ep_rew_mean          | 47.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 664         |\n",
      "|    time_elapsed         | 6734        |\n",
      "|    total_timesteps      | 2719744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011508226 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.46       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00355     |\n",
      "|    n_updates            | 6630        |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    value_loss           | 0.123       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2720000, episode_reward=48.44 +/- 3.46\n",
      "Episode length: 77.80 +/- 10.49\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 77.8        |\n",
      "|    mean_reward          | 48.4        |\n",
      "|    std_reward           | 3.46        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2720000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012659529 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.43       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00389    |\n",
      "|    n_updates            | 6640        |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    value_loss           | 0.116       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.2     |\n",
      "|    ep_rew_mean     | 48       |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 665      |\n",
      "|    time_elapsed    | 6744     |\n",
      "|    total_timesteps | 2723840  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77          |\n",
      "|    ep_rew_mean          | 47.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 666         |\n",
      "|    time_elapsed         | 6754        |\n",
      "|    total_timesteps      | 2727936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011756629 |\n",
      "|    clip_fraction        | 0.31        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0177     |\n",
      "|    n_updates            | 6650        |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    value_loss           | 0.109       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2730000, episode_reward=49.81 +/- 4.59\n",
      "Episode length: 78.30 +/- 9.84\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 78.3        |\n",
      "|    mean_reward          | 49.8        |\n",
      "|    std_reward           | 4.59        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2730000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013606563 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.45       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00202     |\n",
      "|    n_updates            | 6660        |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    value_loss           | 0.127       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.9     |\n",
      "|    ep_rew_mean     | 47.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 667      |\n",
      "|    time_elapsed    | 6765     |\n",
      "|    total_timesteps | 2732032  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 80         |\n",
      "|    ep_rew_mean          | 46.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 403        |\n",
      "|    iterations           | 668        |\n",
      "|    time_elapsed         | 6775       |\n",
      "|    total_timesteps      | 2736128    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01367405 |\n",
      "|    clip_fraction        | 0.304      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.47      |\n",
      "|    explained_variance   | 0.996      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | 0.00173    |\n",
      "|    n_updates            | 6670       |\n",
      "|    policy_gradient_loss | -0.0151    |\n",
      "|    value_loss           | 0.133      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2740000, episode_reward=49.13 +/- 3.95\n",
      "Episode length: 75.90 +/- 7.05\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 75.9        |\n",
      "|    mean_reward          | 49.1        |\n",
      "|    std_reward           | 3.95        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2740000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011111563 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.44       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00124    |\n",
      "|    n_updates            | 6680        |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    value_loss           | 0.137       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.3     |\n",
      "|    ep_rew_mean     | 48.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 669      |\n",
      "|    time_elapsed    | 6786     |\n",
      "|    total_timesteps | 2740224  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.4        |\n",
      "|    ep_rew_mean          | 48.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 670         |\n",
      "|    time_elapsed         | 6795        |\n",
      "|    total_timesteps      | 2744320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012771217 |\n",
      "|    clip_fraction        | 0.302       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.44       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00201     |\n",
      "|    n_updates            | 6690        |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    value_loss           | 0.135       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.2        |\n",
      "|    ep_rew_mean          | 48.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 671         |\n",
      "|    time_elapsed         | 6805        |\n",
      "|    total_timesteps      | 2748416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012639383 |\n",
      "|    clip_fraction        | 0.301       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.43       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0103      |\n",
      "|    n_updates            | 6700        |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    value_loss           | 0.101       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2750000, episode_reward=49.50 +/- 5.35\n",
      "Episode length: 79.00 +/- 10.02\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 79          |\n",
      "|    mean_reward          | 49.5        |\n",
      "|    std_reward           | 5.35        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2750000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017779775 |\n",
      "|    clip_fraction        | 0.327       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00755    |\n",
      "|    n_updates            | 6710        |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 0.11        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.1     |\n",
      "|    ep_rew_mean     | 47.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 672      |\n",
      "|    time_elapsed    | 6816     |\n",
      "|    total_timesteps | 2752512  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78          |\n",
      "|    ep_rew_mean          | 48.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 673         |\n",
      "|    time_elapsed         | 6826        |\n",
      "|    total_timesteps      | 2756608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012112345 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00823    |\n",
      "|    n_updates            | 6720        |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    value_loss           | 0.12        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2760000, episode_reward=45.58 +/- 7.03\n",
      "Episode length: 89.50 +/- 11.99\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 89.5        |\n",
      "|    mean_reward          | 45.6        |\n",
      "|    std_reward           | 7.03        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2760000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014020467 |\n",
      "|    clip_fraction        | 0.314       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00754    |\n",
      "|    n_updates            | 6730        |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    value_loss           | 0.123       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.9     |\n",
      "|    ep_rew_mean     | 47.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 674      |\n",
      "|    time_elapsed    | 6837     |\n",
      "|    total_timesteps | 2760704  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.3        |\n",
      "|    ep_rew_mean          | 48          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 675         |\n",
      "|    time_elapsed         | 6847        |\n",
      "|    total_timesteps      | 2764800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012719519 |\n",
      "|    clip_fraction        | 0.284       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.000755    |\n",
      "|    n_updates            | 6740        |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    value_loss           | 0.147       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.5        |\n",
      "|    ep_rew_mean          | 48.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 676         |\n",
      "|    time_elapsed         | 6856        |\n",
      "|    total_timesteps      | 2768896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011628366 |\n",
      "|    clip_fraction        | 0.317       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00683    |\n",
      "|    n_updates            | 6750        |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    value_loss           | 0.123       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2770000, episode_reward=52.09 +/- 3.35\n",
      "Episode length: 74.40 +/- 6.86\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 74.4        |\n",
      "|    mean_reward          | 52.1        |\n",
      "|    std_reward           | 3.35        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2770000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013005195 |\n",
      "|    clip_fraction        | 0.329       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.51       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00652     |\n",
      "|    n_updates            | 6760        |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    value_loss           | 0.117       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78       |\n",
      "|    ep_rew_mean     | 48       |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 677      |\n",
      "|    time_elapsed    | 6867     |\n",
      "|    total_timesteps | 2772992  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.3        |\n",
      "|    ep_rew_mean          | 48.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 678         |\n",
      "|    time_elapsed         | 6877        |\n",
      "|    total_timesteps      | 2777088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013429496 |\n",
      "|    clip_fraction        | 0.32        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00574    |\n",
      "|    n_updates            | 6770        |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    value_loss           | 0.117       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2780000, episode_reward=49.71 +/- 5.10\n",
      "Episode length: 76.90 +/- 10.24\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 76.9       |\n",
      "|    mean_reward          | 49.7       |\n",
      "|    std_reward           | 5.1        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2780000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01294696 |\n",
      "|    clip_fraction        | 0.295      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.51      |\n",
      "|    explained_variance   | 0.997      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.0072    |\n",
      "|    n_updates            | 6780       |\n",
      "|    policy_gradient_loss | -0.0162    |\n",
      "|    value_loss           | 0.136      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78       |\n",
      "|    ep_rew_mean     | 47.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 679      |\n",
      "|    time_elapsed    | 6888     |\n",
      "|    total_timesteps | 2781184  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 78.5       |\n",
      "|    ep_rew_mean          | 47.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 403        |\n",
      "|    iterations           | 680        |\n",
      "|    time_elapsed         | 6897       |\n",
      "|    total_timesteps      | 2785280    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01187177 |\n",
      "|    clip_fraction        | 0.283      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.5       |\n",
      "|    explained_variance   | 0.996      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.00298   |\n",
      "|    n_updates            | 6790       |\n",
      "|    policy_gradient_loss | -0.0155    |\n",
      "|    value_loss           | 0.138      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.6        |\n",
      "|    ep_rew_mean          | 47.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 681         |\n",
      "|    time_elapsed         | 6907        |\n",
      "|    total_timesteps      | 2789376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012744242 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00506     |\n",
      "|    n_updates            | 6800        |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    value_loss           | 0.134       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2790000, episode_reward=50.49 +/- 3.95\n",
      "Episode length: 75.40 +/- 10.71\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 75.4        |\n",
      "|    mean_reward          | 50.5        |\n",
      "|    std_reward           | 3.95        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2790000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013213603 |\n",
      "|    clip_fraction        | 0.303       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.012      |\n",
      "|    n_updates            | 6810        |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    value_loss           | 0.106       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 76.6     |\n",
      "|    ep_rew_mean     | 48.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 682      |\n",
      "|    time_elapsed    | 6918     |\n",
      "|    total_timesteps | 2793472  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 77.5       |\n",
      "|    ep_rew_mean          | 48.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 403        |\n",
      "|    iterations           | 683        |\n",
      "|    time_elapsed         | 6927       |\n",
      "|    total_timesteps      | 2797568    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01097488 |\n",
      "|    clip_fraction        | 0.284      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.49      |\n",
      "|    explained_variance   | 0.997      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.000732  |\n",
      "|    n_updates            | 6820       |\n",
      "|    policy_gradient_loss | -0.0158    |\n",
      "|    value_loss           | 0.123      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2800000, episode_reward=50.66 +/- 4.16\n",
      "Episode length: 75.90 +/- 9.14\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 75.9        |\n",
      "|    mean_reward          | 50.7        |\n",
      "|    std_reward           | 4.16        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2800000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014123559 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00945    |\n",
      "|    n_updates            | 6830        |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    value_loss           | 0.1         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.8     |\n",
      "|    ep_rew_mean     | 47.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 684      |\n",
      "|    time_elapsed    | 6938     |\n",
      "|    total_timesteps | 2801664  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 77.7       |\n",
      "|    ep_rew_mean          | 48.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 403        |\n",
      "|    iterations           | 685        |\n",
      "|    time_elapsed         | 6948       |\n",
      "|    total_timesteps      | 2805760    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01293749 |\n",
      "|    clip_fraction        | 0.309      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.5       |\n",
      "|    explained_variance   | 0.997      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.00716   |\n",
      "|    n_updates            | 6840       |\n",
      "|    policy_gradient_loss | -0.0175    |\n",
      "|    value_loss           | 0.107      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.9        |\n",
      "|    ep_rew_mean          | 48.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 686         |\n",
      "|    time_elapsed         | 6957        |\n",
      "|    total_timesteps      | 2809856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012460589 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.46       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00269    |\n",
      "|    n_updates            | 6850        |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    value_loss           | 0.116       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2810000, episode_reward=48.88 +/- 4.48\n",
      "Episode length: 80.90 +/- 8.07\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 80.9        |\n",
      "|    mean_reward          | 48.9        |\n",
      "|    std_reward           | 4.48        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2810000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012759991 |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.038       |\n",
      "|    n_updates            | 6860        |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    value_loss           | 0.141       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.4     |\n",
      "|    ep_rew_mean     | 47.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 687      |\n",
      "|    time_elapsed    | 6968     |\n",
      "|    total_timesteps | 2813952  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.4        |\n",
      "|    ep_rew_mean          | 48.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 688         |\n",
      "|    time_elapsed         | 6978        |\n",
      "|    total_timesteps      | 2818048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014801192 |\n",
      "|    clip_fraction        | 0.315       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0016      |\n",
      "|    n_updates            | 6870        |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    value_loss           | 0.104       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2820000, episode_reward=50.60 +/- 4.50\n",
      "Episode length: 77.70 +/- 9.13\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 77.7        |\n",
      "|    mean_reward          | 50.6        |\n",
      "|    std_reward           | 4.5         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2820000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013028393 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.46       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0042      |\n",
      "|    n_updates            | 6880        |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    value_loss           | 0.114       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.1     |\n",
      "|    ep_rew_mean     | 48.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 689      |\n",
      "|    time_elapsed    | 6989     |\n",
      "|    total_timesteps | 2822144  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 80.1         |\n",
      "|    ep_rew_mean          | 46.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 403          |\n",
      "|    iterations           | 690          |\n",
      "|    time_elapsed         | 6999         |\n",
      "|    total_timesteps      | 2826240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0133444145 |\n",
      "|    clip_fraction        | 0.296        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.48        |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.00581      |\n",
      "|    n_updates            | 6890         |\n",
      "|    policy_gradient_loss | -0.0152      |\n",
      "|    value_loss           | 0.117        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2830000, episode_reward=49.38 +/- 4.94\n",
      "Episode length: 74.40 +/- 10.87\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 74.4        |\n",
      "|    mean_reward          | 49.4        |\n",
      "|    std_reward           | 4.94        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2830000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014215189 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00762    |\n",
      "|    n_updates            | 6900        |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    value_loss           | 0.105       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.1     |\n",
      "|    ep_rew_mean     | 47.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 691      |\n",
      "|    time_elapsed    | 7009     |\n",
      "|    total_timesteps | 2830336  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.1        |\n",
      "|    ep_rew_mean          | 47.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 692         |\n",
      "|    time_elapsed         | 7019        |\n",
      "|    total_timesteps      | 2834432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013756294 |\n",
      "|    clip_fraction        | 0.32        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0036      |\n",
      "|    n_updates            | 6910        |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    value_loss           | 0.101       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78.7         |\n",
      "|    ep_rew_mean          | 48           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 403          |\n",
      "|    iterations           | 693          |\n",
      "|    time_elapsed         | 7029         |\n",
      "|    total_timesteps      | 2838528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0120178815 |\n",
      "|    clip_fraction        | 0.314        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.5         |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.012       |\n",
      "|    n_updates            | 6920         |\n",
      "|    policy_gradient_loss | -0.0146      |\n",
      "|    value_loss           | 0.116        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2840000, episode_reward=48.35 +/- 5.07\n",
      "Episode length: 82.20 +/- 7.05\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 82.2        |\n",
      "|    mean_reward          | 48.3        |\n",
      "|    std_reward           | 5.07        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2840000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012160472 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00973    |\n",
      "|    n_updates            | 6930        |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    value_loss           | 0.102       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.5     |\n",
      "|    ep_rew_mean     | 48       |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 694      |\n",
      "|    time_elapsed    | 7040     |\n",
      "|    total_timesteps | 2842624  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.5        |\n",
      "|    ep_rew_mean          | 48.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 695         |\n",
      "|    time_elapsed         | 7049        |\n",
      "|    total_timesteps      | 2846720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013422201 |\n",
      "|    clip_fraction        | 0.309       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00882    |\n",
      "|    n_updates            | 6940        |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    value_loss           | 0.0964      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2850000, episode_reward=49.09 +/- 4.13\n",
      "Episode length: 78.20 +/- 9.85\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 78.2        |\n",
      "|    mean_reward          | 49.1        |\n",
      "|    std_reward           | 4.13        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2850000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013702931 |\n",
      "|    clip_fraction        | 0.317       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00745    |\n",
      "|    n_updates            | 6950        |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    value_loss           | 0.106       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.4     |\n",
      "|    ep_rew_mean     | 47.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 696      |\n",
      "|    time_elapsed    | 7060     |\n",
      "|    total_timesteps | 2850816  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.8        |\n",
      "|    ep_rew_mean          | 47.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 697         |\n",
      "|    time_elapsed         | 7070        |\n",
      "|    total_timesteps      | 2854912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012364072 |\n",
      "|    clip_fraction        | 0.319       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00448    |\n",
      "|    n_updates            | 6960        |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    value_loss           | 0.105       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 80.9        |\n",
      "|    ep_rew_mean          | 47          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 698         |\n",
      "|    time_elapsed         | 7080        |\n",
      "|    total_timesteps      | 2859008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012576779 |\n",
      "|    clip_fraction        | 0.294       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00443    |\n",
      "|    n_updates            | 6970        |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    value_loss           | 0.117       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2860000, episode_reward=50.27 +/- 4.28\n",
      "Episode length: 77.20 +/- 11.49\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 77.2        |\n",
      "|    mean_reward          | 50.3        |\n",
      "|    std_reward           | 4.28        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2860000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012947752 |\n",
      "|    clip_fraction        | 0.317       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00752    |\n",
      "|    n_updates            | 6980        |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    value_loss           | 0.0861      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 80.6     |\n",
      "|    ep_rew_mean     | 47.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 699      |\n",
      "|    time_elapsed    | 7091     |\n",
      "|    total_timesteps | 2863104  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.4        |\n",
      "|    ep_rew_mean          | 47.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 700         |\n",
      "|    time_elapsed         | 7100        |\n",
      "|    total_timesteps      | 2867200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011817075 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00458    |\n",
      "|    n_updates            | 6990        |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    value_loss           | 0.1         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2870000, episode_reward=47.59 +/- 6.19\n",
      "Episode length: 78.50 +/- 12.67\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 78.5        |\n",
      "|    mean_reward          | 47.6        |\n",
      "|    std_reward           | 6.19        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2870000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012499357 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00421    |\n",
      "|    n_updates            | 7000        |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    value_loss           | 0.122       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79       |\n",
      "|    ep_rew_mean     | 47.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 701      |\n",
      "|    time_elapsed    | 7111     |\n",
      "|    total_timesteps | 2871296  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.4        |\n",
      "|    ep_rew_mean          | 48.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 702         |\n",
      "|    time_elapsed         | 7121        |\n",
      "|    total_timesteps      | 2875392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013991642 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.45       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.000248    |\n",
      "|    n_updates            | 7010        |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    value_loss           | 0.124       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77          |\n",
      "|    ep_rew_mean          | 48.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 703         |\n",
      "|    time_elapsed         | 7130        |\n",
      "|    total_timesteps      | 2879488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011857063 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00404     |\n",
      "|    n_updates            | 7020        |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    value_loss           | 0.0915      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2880000, episode_reward=50.12 +/- 4.17\n",
      "Episode length: 75.10 +/- 7.69\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 75.1        |\n",
      "|    mean_reward          | 50.1        |\n",
      "|    std_reward           | 4.17        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2880000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012952078 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00433     |\n",
      "|    n_updates            | 7030        |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    value_loss           | 0.139       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.2     |\n",
      "|    ep_rew_mean     | 48.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 704      |\n",
      "|    time_elapsed    | 7141     |\n",
      "|    total_timesteps | 2883584  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.4        |\n",
      "|    ep_rew_mean          | 47.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 705         |\n",
      "|    time_elapsed         | 7151        |\n",
      "|    total_timesteps      | 2887680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012532545 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0056      |\n",
      "|    n_updates            | 7040        |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 0.112       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2890000, episode_reward=46.52 +/- 6.01\n",
      "Episode length: 83.50 +/- 7.13\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 83.5        |\n",
      "|    mean_reward          | 46.5        |\n",
      "|    std_reward           | 6.01        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2890000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013680512 |\n",
      "|    clip_fraction        | 0.315       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0165      |\n",
      "|    n_updates            | 7050        |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    value_loss           | 0.119       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78       |\n",
      "|    ep_rew_mean     | 47.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 706      |\n",
      "|    time_elapsed    | 7162     |\n",
      "|    total_timesteps | 2891776  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78          |\n",
      "|    ep_rew_mean          | 48.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 707         |\n",
      "|    time_elapsed         | 7172        |\n",
      "|    total_timesteps      | 2895872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015623976 |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00581    |\n",
      "|    n_updates            | 7060        |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    value_loss           | 0.103       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.4        |\n",
      "|    ep_rew_mean          | 48.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 708         |\n",
      "|    time_elapsed         | 7181        |\n",
      "|    total_timesteps      | 2899968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011340337 |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00977    |\n",
      "|    n_updates            | 7070        |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    value_loss           | 0.102       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2900000, episode_reward=49.94 +/- 3.59\n",
      "Episode length: 75.40 +/- 9.09\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 75.4        |\n",
      "|    mean_reward          | 49.9        |\n",
      "|    std_reward           | 3.59        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2900000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014754973 |\n",
      "|    clip_fraction        | 0.321       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.000136    |\n",
      "|    n_updates            | 7080        |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    value_loss           | 0.114       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 76.8     |\n",
      "|    ep_rew_mean     | 48.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 709      |\n",
      "|    time_elapsed    | 7192     |\n",
      "|    total_timesteps | 2904064  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.2        |\n",
      "|    ep_rew_mean          | 48.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 710         |\n",
      "|    time_elapsed         | 7202        |\n",
      "|    total_timesteps      | 2908160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014932461 |\n",
      "|    clip_fraction        | 0.339       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0116     |\n",
      "|    n_updates            | 7090        |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    value_loss           | 0.103       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2910000, episode_reward=50.54 +/- 3.58\n",
      "Episode length: 78.90 +/- 6.89\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 78.9        |\n",
      "|    mean_reward          | 50.5        |\n",
      "|    std_reward           | 3.58        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2910000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012550447 |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00633    |\n",
      "|    n_updates            | 7100        |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    value_loss           | 0.113       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.3     |\n",
      "|    ep_rew_mean     | 48.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 711      |\n",
      "|    time_elapsed    | 7213     |\n",
      "|    total_timesteps | 2912256  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.6        |\n",
      "|    ep_rew_mean          | 48.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 712         |\n",
      "|    time_elapsed         | 7222        |\n",
      "|    total_timesteps      | 2916352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013735519 |\n",
      "|    clip_fraction        | 0.309       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.000761    |\n",
      "|    n_updates            | 7110        |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 0.11        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2920000, episode_reward=47.81 +/- 6.84\n",
      "Episode length: 78.60 +/- 7.43\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 78.6        |\n",
      "|    mean_reward          | 47.8        |\n",
      "|    std_reward           | 6.84        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2920000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011641022 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.46       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0116      |\n",
      "|    n_updates            | 7120        |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    value_loss           | 0.14        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.9     |\n",
      "|    ep_rew_mean     | 48.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 713      |\n",
      "|    time_elapsed    | 7233     |\n",
      "|    total_timesteps | 2920448  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.3        |\n",
      "|    ep_rew_mean          | 47.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 714         |\n",
      "|    time_elapsed         | 7243        |\n",
      "|    total_timesteps      | 2924544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012365008 |\n",
      "|    clip_fraction        | 0.314       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0134     |\n",
      "|    n_updates            | 7130        |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    value_loss           | 0.106       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.8        |\n",
      "|    ep_rew_mean          | 47.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 715         |\n",
      "|    time_elapsed         | 7253        |\n",
      "|    total_timesteps      | 2928640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013539677 |\n",
      "|    clip_fraction        | 0.319       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0206     |\n",
      "|    n_updates            | 7140        |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    value_loss           | 0.126       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2930000, episode_reward=47.28 +/- 3.46\n",
      "Episode length: 81.10 +/- 5.94\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 81.1        |\n",
      "|    mean_reward          | 47.3        |\n",
      "|    std_reward           | 3.46        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2930000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013413271 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.000737   |\n",
      "|    n_updates            | 7150        |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    value_loss           | 0.132       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.6     |\n",
      "|    ep_rew_mean     | 47.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 716      |\n",
      "|    time_elapsed    | 7264     |\n",
      "|    total_timesteps | 2932736  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.3        |\n",
      "|    ep_rew_mean          | 48.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 717         |\n",
      "|    time_elapsed         | 7273        |\n",
      "|    total_timesteps      | 2936832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012911556 |\n",
      "|    clip_fraction        | 0.315       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.46       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0195     |\n",
      "|    n_updates            | 7160        |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    value_loss           | 0.11        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2940000, episode_reward=44.30 +/- 2.19\n",
      "Episode length: 84.00 +/- 6.93\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 84          |\n",
      "|    mean_reward          | 44.3        |\n",
      "|    std_reward           | 2.19        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2940000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014927145 |\n",
      "|    clip_fraction        | 0.332       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.46       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00352     |\n",
      "|    n_updates            | 7170        |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 0.104       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.2     |\n",
      "|    ep_rew_mean     | 48.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 718      |\n",
      "|    time_elapsed    | 7284     |\n",
      "|    total_timesteps | 2940928  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78          |\n",
      "|    ep_rew_mean          | 48          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 719         |\n",
      "|    time_elapsed         | 7294        |\n",
      "|    total_timesteps      | 2945024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016244516 |\n",
      "|    clip_fraction        | 0.339       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0171     |\n",
      "|    n_updates            | 7180        |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    value_loss           | 0.102       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.9        |\n",
      "|    ep_rew_mean          | 48          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 720         |\n",
      "|    time_elapsed         | 7303        |\n",
      "|    total_timesteps      | 2949120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014547469 |\n",
      "|    clip_fraction        | 0.303       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.45       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00244     |\n",
      "|    n_updates            | 7190        |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    value_loss           | 0.116       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2950000, episode_reward=46.26 +/- 4.21\n",
      "Episode length: 84.30 +/- 9.56\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 84.3        |\n",
      "|    mean_reward          | 46.3        |\n",
      "|    std_reward           | 4.21        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2950000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013001394 |\n",
      "|    clip_fraction        | 0.328       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0105     |\n",
      "|    n_updates            | 7200        |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    value_loss           | 0.102       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.8     |\n",
      "|    ep_rew_mean     | 47.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 721      |\n",
      "|    time_elapsed    | 7314     |\n",
      "|    total_timesteps | 2953216  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.1        |\n",
      "|    ep_rew_mean          | 48          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 722         |\n",
      "|    time_elapsed         | 7324        |\n",
      "|    total_timesteps      | 2957312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013835548 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.45       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00474     |\n",
      "|    n_updates            | 7210        |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    value_loss           | 0.119       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2960000, episode_reward=50.03 +/- 4.62\n",
      "Episode length: 73.70 +/- 9.69\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 73.7       |\n",
      "|    mean_reward          | 50         |\n",
      "|    std_reward           | 4.62       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2960000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01424059 |\n",
      "|    clip_fraction        | 0.332      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.46      |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.0112    |\n",
      "|    n_updates            | 7220       |\n",
      "|    policy_gradient_loss | -0.0163    |\n",
      "|    value_loss           | 0.0972     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.9     |\n",
      "|    ep_rew_mean     | 47.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 723      |\n",
      "|    time_elapsed    | 7335     |\n",
      "|    total_timesteps | 2961408  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.7        |\n",
      "|    ep_rew_mean          | 47.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 724         |\n",
      "|    time_elapsed         | 7344        |\n",
      "|    total_timesteps      | 2965504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013648231 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.46       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00616    |\n",
      "|    n_updates            | 7230        |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    value_loss           | 0.11        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.9        |\n",
      "|    ep_rew_mean          | 47.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 725         |\n",
      "|    time_elapsed         | 7354        |\n",
      "|    total_timesteps      | 2969600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017238624 |\n",
      "|    clip_fraction        | 0.326       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.45       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00522     |\n",
      "|    n_updates            | 7240        |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    value_loss           | 0.107       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2970000, episode_reward=47.49 +/- 5.67\n",
      "Episode length: 75.10 +/- 8.64\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 75.1        |\n",
      "|    mean_reward          | 47.5        |\n",
      "|    std_reward           | 5.67        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2970000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011195123 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.43       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00455     |\n",
      "|    n_updates            | 7250        |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    value_loss           | 0.124       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.2     |\n",
      "|    ep_rew_mean     | 47.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 726      |\n",
      "|    time_elapsed    | 7365     |\n",
      "|    total_timesteps | 2973696  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.1        |\n",
      "|    ep_rew_mean          | 48.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 727         |\n",
      "|    time_elapsed         | 7375        |\n",
      "|    total_timesteps      | 2977792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012966212 |\n",
      "|    clip_fraction        | 0.3         |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.012      |\n",
      "|    n_updates            | 7260        |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    value_loss           | 0.146       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2980000, episode_reward=49.40 +/- 5.24\n",
      "Episode length: 78.10 +/- 10.97\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 78.1        |\n",
      "|    mean_reward          | 49.4        |\n",
      "|    std_reward           | 5.24        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2980000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013546198 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.018      |\n",
      "|    n_updates            | 7270        |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    value_loss           | 0.0953      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.7     |\n",
      "|    ep_rew_mean     | 48.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 728      |\n",
      "|    time_elapsed    | 7386     |\n",
      "|    total_timesteps | 2981888  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.6        |\n",
      "|    ep_rew_mean          | 48          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 729         |\n",
      "|    time_elapsed         | 7395        |\n",
      "|    total_timesteps      | 2985984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012773558 |\n",
      "|    clip_fraction        | 0.312       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0107     |\n",
      "|    n_updates            | 7280        |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    value_loss           | 0.105       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2990000, episode_reward=47.54 +/- 5.64\n",
      "Episode length: 81.00 +/- 8.53\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 81          |\n",
      "|    mean_reward          | 47.5        |\n",
      "|    std_reward           | 5.64        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2990000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011804227 |\n",
      "|    clip_fraction        | 0.334       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0244     |\n",
      "|    n_updates            | 7290        |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    value_loss           | 0.0861      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.5     |\n",
      "|    ep_rew_mean     | 48.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 730      |\n",
      "|    time_elapsed    | 7406     |\n",
      "|    total_timesteps | 2990080  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.9        |\n",
      "|    ep_rew_mean          | 48.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 731         |\n",
      "|    time_elapsed         | 7416        |\n",
      "|    total_timesteps      | 2994176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013164516 |\n",
      "|    clip_fraction        | 0.315       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0122     |\n",
      "|    n_updates            | 7300        |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    value_loss           | 0.0986      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.4        |\n",
      "|    ep_rew_mean          | 48.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 732         |\n",
      "|    time_elapsed         | 7426        |\n",
      "|    total_timesteps      | 2998272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013314128 |\n",
      "|    clip_fraction        | 0.301       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00512    |\n",
      "|    n_updates            | 7310        |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    value_loss           | 0.0825      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3000000, episode_reward=47.51 +/- 4.73\n",
      "Episode length: 79.70 +/- 10.20\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 79.7        |\n",
      "|    mean_reward          | 47.5        |\n",
      "|    std_reward           | 4.73        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3000000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012842108 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.41       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00455     |\n",
      "|    n_updates            | 7320        |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    value_loss           | 0.122       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 76.6     |\n",
      "|    ep_rew_mean     | 48.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 733      |\n",
      "|    time_elapsed    | 7437     |\n",
      "|    total_timesteps | 3002368  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77          |\n",
      "|    ep_rew_mean          | 49.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 734         |\n",
      "|    time_elapsed         | 7446        |\n",
      "|    total_timesteps      | 3006464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013847413 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00516    |\n",
      "|    n_updates            | 7330        |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    value_loss           | 0.132       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3010000, episode_reward=49.31 +/- 4.77\n",
      "Episode length: 76.90 +/- 9.43\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 76.9        |\n",
      "|    mean_reward          | 49.3        |\n",
      "|    std_reward           | 4.77        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3010000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012198147 |\n",
      "|    clip_fraction        | 0.3         |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.000124    |\n",
      "|    n_updates            | 7340        |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 0.107       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.7     |\n",
      "|    ep_rew_mean     | 48.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 735      |\n",
      "|    time_elapsed    | 7457     |\n",
      "|    total_timesteps | 3010560  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.4        |\n",
      "|    ep_rew_mean          | 48.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 736         |\n",
      "|    time_elapsed         | 7467        |\n",
      "|    total_timesteps      | 3014656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013032852 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.41       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0134      |\n",
      "|    n_updates            | 7350        |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    value_loss           | 0.147       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.7        |\n",
      "|    ep_rew_mean          | 49.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 737         |\n",
      "|    time_elapsed         | 7477        |\n",
      "|    total_timesteps      | 3018752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011981271 |\n",
      "|    clip_fraction        | 0.294       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0151     |\n",
      "|    n_updates            | 7360        |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    value_loss           | 0.107       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3020000, episode_reward=50.36 +/- 4.57\n",
      "Episode length: 75.00 +/- 8.07\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 75          |\n",
      "|    mean_reward          | 50.4        |\n",
      "|    std_reward           | 4.57        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3020000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013251174 |\n",
      "|    clip_fraction        | 0.336       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0102     |\n",
      "|    n_updates            | 7370        |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    value_loss           | 0.097       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.8     |\n",
      "|    ep_rew_mean     | 48.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 738      |\n",
      "|    time_elapsed    | 7487     |\n",
      "|    total_timesteps | 3022848  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 80.8         |\n",
      "|    ep_rew_mean          | 47.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 403          |\n",
      "|    iterations           | 739          |\n",
      "|    time_elapsed         | 7497         |\n",
      "|    total_timesteps      | 3026944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0128002865 |\n",
      "|    clip_fraction        | 0.307        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 0.996        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.00471      |\n",
      "|    n_updates            | 7380         |\n",
      "|    policy_gradient_loss | -0.0155      |\n",
      "|    value_loss           | 0.119        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3030000, episode_reward=49.90 +/- 6.74\n",
      "Episode length: 73.90 +/- 8.22\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 73.9        |\n",
      "|    mean_reward          | 49.9        |\n",
      "|    std_reward           | 6.74        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3030000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012795065 |\n",
      "|    clip_fraction        | 0.3         |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.41       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00733    |\n",
      "|    n_updates            | 7390        |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 0.125       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.6     |\n",
      "|    ep_rew_mean     | 48.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 740      |\n",
      "|    time_elapsed    | 7508     |\n",
      "|    total_timesteps | 3031040  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.2        |\n",
      "|    ep_rew_mean          | 49.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 741         |\n",
      "|    time_elapsed         | 7518        |\n",
      "|    total_timesteps      | 3035136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013483688 |\n",
      "|    clip_fraction        | 0.328       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00435    |\n",
      "|    n_updates            | 7400        |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    value_loss           | 0.112       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.6        |\n",
      "|    ep_rew_mean          | 49.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 742         |\n",
      "|    time_elapsed         | 7527        |\n",
      "|    total_timesteps      | 3039232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013063796 |\n",
      "|    clip_fraction        | 0.312       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00454    |\n",
      "|    n_updates            | 7410        |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    value_loss           | 0.111       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3040000, episode_reward=49.00 +/- 2.89\n",
      "Episode length: 83.80 +/- 6.13\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 83.8        |\n",
      "|    mean_reward          | 49          |\n",
      "|    std_reward           | 2.89        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3040000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012601705 |\n",
      "|    clip_fraction        | 0.302       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0177     |\n",
      "|    n_updates            | 7420        |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    value_loss           | 0.095       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.9     |\n",
      "|    ep_rew_mean     | 49.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 743      |\n",
      "|    time_elapsed    | 7538     |\n",
      "|    total_timesteps | 3043328  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.2        |\n",
      "|    ep_rew_mean          | 48.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 744         |\n",
      "|    time_elapsed         | 7548        |\n",
      "|    total_timesteps      | 3047424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014168186 |\n",
      "|    clip_fraction        | 0.331       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0158     |\n",
      "|    n_updates            | 7430        |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    value_loss           | 0.0868      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3050000, episode_reward=48.68 +/- 5.33\n",
      "Episode length: 80.10 +/- 10.28\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 80.1       |\n",
      "|    mean_reward          | 48.7       |\n",
      "|    std_reward           | 5.33       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3050000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01176995 |\n",
      "|    clip_fraction        | 0.273      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.38      |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.0183    |\n",
      "|    n_updates            | 7440       |\n",
      "|    policy_gradient_loss | -0.0161    |\n",
      "|    value_loss           | 0.103      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.4     |\n",
      "|    ep_rew_mean     | 48.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 745      |\n",
      "|    time_elapsed    | 7559     |\n",
      "|    total_timesteps | 3051520  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.6        |\n",
      "|    ep_rew_mean          | 48.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 746         |\n",
      "|    time_elapsed         | 7568        |\n",
      "|    total_timesteps      | 3055616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012482714 |\n",
      "|    clip_fraction        | 0.313       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00725    |\n",
      "|    n_updates            | 7450        |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    value_loss           | 0.111       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.7        |\n",
      "|    ep_rew_mean          | 49          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 747         |\n",
      "|    time_elapsed         | 7578        |\n",
      "|    total_timesteps      | 3059712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012128843 |\n",
      "|    clip_fraction        | 0.326       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.37       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00594    |\n",
      "|    n_updates            | 7460        |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    value_loss           | 0.102       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3060000, episode_reward=49.23 +/- 4.35\n",
      "Episode length: 79.50 +/- 8.50\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 79.5        |\n",
      "|    mean_reward          | 49.2        |\n",
      "|    std_reward           | 4.35        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3060000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015126715 |\n",
      "|    clip_fraction        | 0.289       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.37       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00495    |\n",
      "|    n_updates            | 7470        |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    value_loss           | 0.12        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.5     |\n",
      "|    ep_rew_mean     | 47.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 748      |\n",
      "|    time_elapsed    | 7589     |\n",
      "|    total_timesteps | 3063808  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.7        |\n",
      "|    ep_rew_mean          | 48.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 749         |\n",
      "|    time_elapsed         | 7599        |\n",
      "|    total_timesteps      | 3067904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016213192 |\n",
      "|    clip_fraction        | 0.289       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0118      |\n",
      "|    n_updates            | 7480        |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    value_loss           | 0.121       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3070000, episode_reward=46.43 +/- 5.05\n",
      "Episode length: 83.30 +/- 10.84\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 83.3        |\n",
      "|    mean_reward          | 46.4        |\n",
      "|    std_reward           | 5.05        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3070000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012559405 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00612    |\n",
      "|    n_updates            | 7490        |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    value_loss           | 0.109       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.6     |\n",
      "|    ep_rew_mean     | 48.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 750      |\n",
      "|    time_elapsed    | 7610     |\n",
      "|    total_timesteps | 3072000  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 77.6         |\n",
      "|    ep_rew_mean          | 49.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 403          |\n",
      "|    iterations           | 751          |\n",
      "|    time_elapsed         | 7619         |\n",
      "|    total_timesteps      | 3076096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0134931775 |\n",
      "|    clip_fraction        | 0.304        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.35        |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00766     |\n",
      "|    n_updates            | 7500         |\n",
      "|    policy_gradient_loss | -0.0141      |\n",
      "|    value_loss           | 0.103        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3080000, episode_reward=46.43 +/- 8.32\n",
      "Episode length: 83.40 +/- 14.32\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 83.4        |\n",
      "|    mean_reward          | 46.4        |\n",
      "|    std_reward           | 8.32        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3080000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012842776 |\n",
      "|    clip_fraction        | 0.302       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0104     |\n",
      "|    n_updates            | 7510        |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    value_loss           | 0.114       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.7     |\n",
      "|    ep_rew_mean     | 49.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 752      |\n",
      "|    time_elapsed    | 7630     |\n",
      "|    total_timesteps | 3080192  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 76.9         |\n",
      "|    ep_rew_mean          | 49.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 403          |\n",
      "|    iterations           | 753          |\n",
      "|    time_elapsed         | 7640         |\n",
      "|    total_timesteps      | 3084288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0124204485 |\n",
      "|    clip_fraction        | 0.296        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.35        |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.00239      |\n",
      "|    n_updates            | 7520         |\n",
      "|    policy_gradient_loss | -0.0142      |\n",
      "|    value_loss           | 0.121        |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 78.5       |\n",
      "|    ep_rew_mean          | 48.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 403        |\n",
      "|    iterations           | 754        |\n",
      "|    time_elapsed         | 7649       |\n",
      "|    total_timesteps      | 3088384    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01220911 |\n",
      "|    clip_fraction        | 0.312      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.35      |\n",
      "|    explained_variance   | 0.997      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | 0.00224    |\n",
      "|    n_updates            | 7530       |\n",
      "|    policy_gradient_loss | -0.0154    |\n",
      "|    value_loss           | 0.0967     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3090000, episode_reward=51.53 +/- 3.17\n",
      "Episode length: 78.30 +/- 5.59\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 78.3        |\n",
      "|    mean_reward          | 51.5        |\n",
      "|    std_reward           | 3.17        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3090000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014396992 |\n",
      "|    clip_fraction        | 0.3         |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00867    |\n",
      "|    n_updates            | 7540        |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    value_loss           | 0.0982      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.5     |\n",
      "|    ep_rew_mean     | 48.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 755      |\n",
      "|    time_elapsed    | 7660     |\n",
      "|    total_timesteps | 3092480  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.7        |\n",
      "|    ep_rew_mean          | 49          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 756         |\n",
      "|    time_elapsed         | 7670        |\n",
      "|    total_timesteps      | 3096576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012282595 |\n",
      "|    clip_fraction        | 0.289       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00175    |\n",
      "|    n_updates            | 7550        |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 0.108       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3100000, episode_reward=48.47 +/- 5.12\n",
      "Episode length: 79.30 +/- 10.48\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 79.3       |\n",
      "|    mean_reward          | 48.5       |\n",
      "|    std_reward           | 5.12       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3100000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01320911 |\n",
      "|    clip_fraction        | 0.288      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.33      |\n",
      "|    explained_variance   | 0.997      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.00183   |\n",
      "|    n_updates            | 7560       |\n",
      "|    policy_gradient_loss | -0.0147    |\n",
      "|    value_loss           | 0.11       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.4     |\n",
      "|    ep_rew_mean     | 49       |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 757      |\n",
      "|    time_elapsed    | 7681     |\n",
      "|    total_timesteps | 3100672  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79          |\n",
      "|    ep_rew_mean          | 48.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 758         |\n",
      "|    time_elapsed         | 7691        |\n",
      "|    total_timesteps      | 3104768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014717378 |\n",
      "|    clip_fraction        | 0.317       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00272    |\n",
      "|    n_updates            | 7570        |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    value_loss           | 0.102       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78          |\n",
      "|    ep_rew_mean          | 49.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 759         |\n",
      "|    time_elapsed         | 7701        |\n",
      "|    total_timesteps      | 3108864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013836451 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00687    |\n",
      "|    n_updates            | 7580        |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    value_loss           | 0.113       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3110000, episode_reward=50.36 +/- 4.10\n",
      "Episode length: 75.10 +/- 7.73\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 75.1        |\n",
      "|    mean_reward          | 50.4        |\n",
      "|    std_reward           | 4.1         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3110000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013985208 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00936    |\n",
      "|    n_updates            | 7590        |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    value_loss           | 0.119       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78       |\n",
      "|    ep_rew_mean     | 49.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 760      |\n",
      "|    time_elapsed    | 7711     |\n",
      "|    total_timesteps | 3112960  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.8        |\n",
      "|    ep_rew_mean          | 48.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 761         |\n",
      "|    time_elapsed         | 7721        |\n",
      "|    total_timesteps      | 3117056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015345196 |\n",
      "|    clip_fraction        | 0.325       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00644    |\n",
      "|    n_updates            | 7600        |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    value_loss           | 0.103       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3120000, episode_reward=50.70 +/- 5.36\n",
      "Episode length: 76.30 +/- 8.64\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 76.3        |\n",
      "|    mean_reward          | 50.7        |\n",
      "|    std_reward           | 5.36        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3120000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016049819 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00804     |\n",
      "|    n_updates            | 7610        |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    value_loss           | 0.106       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.8     |\n",
      "|    ep_rew_mean     | 48.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 762      |\n",
      "|    time_elapsed    | 7732     |\n",
      "|    total_timesteps | 3121152  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 78.4       |\n",
      "|    ep_rew_mean          | 49.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 403        |\n",
      "|    iterations           | 763        |\n",
      "|    time_elapsed         | 7742       |\n",
      "|    total_timesteps      | 3125248    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01446092 |\n",
      "|    clip_fraction        | 0.307      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.33      |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.0167    |\n",
      "|    n_updates            | 7620       |\n",
      "|    policy_gradient_loss | -0.0143    |\n",
      "|    value_loss           | 0.101      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.8        |\n",
      "|    ep_rew_mean          | 49.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 764         |\n",
      "|    time_elapsed         | 7751        |\n",
      "|    total_timesteps      | 3129344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014653621 |\n",
      "|    clip_fraction        | 0.305       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00657    |\n",
      "|    n_updates            | 7630        |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    value_loss           | 0.108       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3130000, episode_reward=50.93 +/- 5.16\n",
      "Episode length: 74.10 +/- 9.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 74.1        |\n",
      "|    mean_reward          | 50.9        |\n",
      "|    std_reward           | 5.16        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3130000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012058416 |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00598     |\n",
      "|    n_updates            | 7640        |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    value_loss           | 0.0941      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.1     |\n",
      "|    ep_rew_mean     | 50.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 765      |\n",
      "|    time_elapsed    | 7762     |\n",
      "|    total_timesteps | 3133440  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.7        |\n",
      "|    ep_rew_mean          | 49.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 766         |\n",
      "|    time_elapsed         | 7772        |\n",
      "|    total_timesteps      | 3137536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014335498 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00633    |\n",
      "|    n_updates            | 7650        |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    value_loss           | 0.0894      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3140000, episode_reward=51.15 +/- 4.11\n",
      "Episode length: 80.20 +/- 8.68\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 80.2        |\n",
      "|    mean_reward          | 51.1        |\n",
      "|    std_reward           | 4.11        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3140000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014943873 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0144     |\n",
      "|    n_updates            | 7660        |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    value_loss           | 0.122       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.3     |\n",
      "|    ep_rew_mean     | 48.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 767      |\n",
      "|    time_elapsed    | 7783     |\n",
      "|    total_timesteps | 3141632  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.4        |\n",
      "|    ep_rew_mean          | 49.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 768         |\n",
      "|    time_elapsed         | 7793        |\n",
      "|    total_timesteps      | 3145728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015297594 |\n",
      "|    clip_fraction        | 0.315       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0134     |\n",
      "|    n_updates            | 7670        |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    value_loss           | 0.103       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.6        |\n",
      "|    ep_rew_mean          | 49.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 769         |\n",
      "|    time_elapsed         | 7802        |\n",
      "|    total_timesteps      | 3149824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012129772 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0135     |\n",
      "|    n_updates            | 7680        |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    value_loss           | 0.0913      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3150000, episode_reward=52.04 +/- 2.99\n",
      "Episode length: 73.50 +/- 6.99\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 73.5        |\n",
      "|    mean_reward          | 52          |\n",
      "|    std_reward           | 2.99        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3150000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013763453 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00362     |\n",
      "|    n_updates            | 7690        |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    value_loss           | 0.116       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.6     |\n",
      "|    ep_rew_mean     | 49.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 770      |\n",
      "|    time_elapsed    | 7813     |\n",
      "|    total_timesteps | 3153920  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.6        |\n",
      "|    ep_rew_mean          | 49.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 771         |\n",
      "|    time_elapsed         | 7823        |\n",
      "|    total_timesteps      | 3158016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018243287 |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.013      |\n",
      "|    n_updates            | 7700        |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    value_loss           | 0.105       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3160000, episode_reward=51.60 +/- 3.87\n",
      "Episode length: 78.40 +/- 7.72\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 78.4        |\n",
      "|    mean_reward          | 51.6        |\n",
      "|    std_reward           | 3.87        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3160000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016080067 |\n",
      "|    clip_fraction        | 0.309       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00327    |\n",
      "|    n_updates            | 7710        |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 0.0995      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.4     |\n",
      "|    ep_rew_mean     | 49.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 772      |\n",
      "|    time_elapsed    | 7833     |\n",
      "|    total_timesteps | 3162112  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.6        |\n",
      "|    ep_rew_mean          | 49          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 773         |\n",
      "|    time_elapsed         | 7843        |\n",
      "|    total_timesteps      | 3166208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012707945 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00237    |\n",
      "|    n_updates            | 7720        |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    value_loss           | 0.112       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3170000, episode_reward=49.78 +/- 4.85\n",
      "Episode length: 78.50 +/- 8.39\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 78.5        |\n",
      "|    mean_reward          | 49.8        |\n",
      "|    std_reward           | 4.85        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3170000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014200682 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0165     |\n",
      "|    n_updates            | 7730        |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    value_loss           | 0.114       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.9     |\n",
      "|    ep_rew_mean     | 48.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 774      |\n",
      "|    time_elapsed    | 7854     |\n",
      "|    total_timesteps | 3170304  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.7        |\n",
      "|    ep_rew_mean          | 49          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 775         |\n",
      "|    time_elapsed         | 7864        |\n",
      "|    total_timesteps      | 3174400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015156699 |\n",
      "|    clip_fraction        | 0.307       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00739    |\n",
      "|    n_updates            | 7740        |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 0.114       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.9        |\n",
      "|    ep_rew_mean          | 49.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 776         |\n",
      "|    time_elapsed         | 7873        |\n",
      "|    total_timesteps      | 3178496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017826516 |\n",
      "|    clip_fraction        | 0.318       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00738    |\n",
      "|    n_updates            | 7750        |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    value_loss           | 0.0941      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3180000, episode_reward=49.50 +/- 5.00\n",
      "Episode length: 79.50 +/- 4.46\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 79.5        |\n",
      "|    mean_reward          | 49.5        |\n",
      "|    std_reward           | 5           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3180000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013094792 |\n",
      "|    clip_fraction        | 0.301       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00274    |\n",
      "|    n_updates            | 7760        |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    value_loss           | 0.0909      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.5     |\n",
      "|    ep_rew_mean     | 49.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 777      |\n",
      "|    time_elapsed    | 7884     |\n",
      "|    total_timesteps | 3182592  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.8        |\n",
      "|    ep_rew_mean          | 49.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 778         |\n",
      "|    time_elapsed         | 7894        |\n",
      "|    total_timesteps      | 3186688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014426979 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00951    |\n",
      "|    n_updates            | 7770        |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    value_loss           | 0.0896      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3190000, episode_reward=50.30 +/- 4.85\n",
      "Episode length: 78.90 +/- 13.06\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 78.9        |\n",
      "|    mean_reward          | 50.3        |\n",
      "|    std_reward           | 4.85        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3190000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013276397 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0012      |\n",
      "|    n_updates            | 7780        |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    value_loss           | 0.121       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 76.5     |\n",
      "|    ep_rew_mean     | 49.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 779      |\n",
      "|    time_elapsed    | 7905     |\n",
      "|    total_timesteps | 3190784  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.2        |\n",
      "|    ep_rew_mean          | 48.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 780         |\n",
      "|    time_elapsed         | 7914        |\n",
      "|    total_timesteps      | 3194880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014674351 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00365    |\n",
      "|    n_updates            | 7790        |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    value_loss           | 0.11        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 80.2        |\n",
      "|    ep_rew_mean          | 48.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 781         |\n",
      "|    time_elapsed         | 7924        |\n",
      "|    total_timesteps      | 3198976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017550096 |\n",
      "|    clip_fraction        | 0.3         |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00123     |\n",
      "|    n_updates            | 7800        |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    value_loss           | 0.11        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3200000, episode_reward=50.51 +/- 6.90\n",
      "Episode length: 79.60 +/- 10.98\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 79.6        |\n",
      "|    mean_reward          | 50.5        |\n",
      "|    std_reward           | 6.9         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3200000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014629278 |\n",
      "|    clip_fraction        | 0.317       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0168     |\n",
      "|    n_updates            | 7810        |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    value_loss           | 0.102       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.6     |\n",
      "|    ep_rew_mean     | 49.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 782      |\n",
      "|    time_elapsed    | 7935     |\n",
      "|    total_timesteps | 3203072  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.6        |\n",
      "|    ep_rew_mean          | 49.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 783         |\n",
      "|    time_elapsed         | 7945        |\n",
      "|    total_timesteps      | 3207168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015285488 |\n",
      "|    clip_fraction        | 0.301       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00457    |\n",
      "|    n_updates            | 7820        |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    value_loss           | 0.0757      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3210000, episode_reward=52.73 +/- 3.01\n",
      "Episode length: 75.30 +/- 11.93\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 75.3       |\n",
      "|    mean_reward          | 52.7       |\n",
      "|    std_reward           | 3.01       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3210000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01836576 |\n",
      "|    clip_fraction        | 0.328      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.34      |\n",
      "|    explained_variance   | 0.997      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.013     |\n",
      "|    n_updates            | 7830       |\n",
      "|    policy_gradient_loss | -0.0156    |\n",
      "|    value_loss           | 0.0986     |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.7     |\n",
      "|    ep_rew_mean     | 49.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 784      |\n",
      "|    time_elapsed    | 7955     |\n",
      "|    total_timesteps | 3211264  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 78.4       |\n",
      "|    ep_rew_mean          | 49.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 403        |\n",
      "|    iterations           | 785        |\n",
      "|    time_elapsed         | 7965       |\n",
      "|    total_timesteps      | 3215360    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01492444 |\n",
      "|    clip_fraction        | 0.283      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.32      |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.00588   |\n",
      "|    n_updates            | 7840       |\n",
      "|    policy_gradient_loss | -0.0149    |\n",
      "|    value_loss           | 0.0923     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79          |\n",
      "|    ep_rew_mean          | 48.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 786         |\n",
      "|    time_elapsed         | 7975        |\n",
      "|    total_timesteps      | 3219456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013588007 |\n",
      "|    clip_fraction        | 0.294       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0106     |\n",
      "|    n_updates            | 7850        |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    value_loss           | 0.116       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3220000, episode_reward=50.28 +/- 3.89\n",
      "Episode length: 76.90 +/- 9.78\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 76.9        |\n",
      "|    mean_reward          | 50.3        |\n",
      "|    std_reward           | 3.89        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3220000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012336383 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00214    |\n",
      "|    n_updates            | 7860        |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    value_loss           | 0.112       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.9     |\n",
      "|    ep_rew_mean     | 48.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 787      |\n",
      "|    time_elapsed    | 7986     |\n",
      "|    total_timesteps | 3223552  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78.2         |\n",
      "|    ep_rew_mean          | 49.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 403          |\n",
      "|    iterations           | 788          |\n",
      "|    time_elapsed         | 7996         |\n",
      "|    total_timesteps      | 3227648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0143004935 |\n",
      "|    clip_fraction        | 0.313        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.33        |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.00537      |\n",
      "|    n_updates            | 7870         |\n",
      "|    policy_gradient_loss | -0.015       |\n",
      "|    value_loss           | 0.103        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3230000, episode_reward=48.84 +/- 5.74\n",
      "Episode length: 78.30 +/- 9.03\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 78.3        |\n",
      "|    mean_reward          | 48.8        |\n",
      "|    std_reward           | 5.74        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3230000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015145468 |\n",
      "|    clip_fraction        | 0.33        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00467    |\n",
      "|    n_updates            | 7880        |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    value_loss           | 0.0934      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.7     |\n",
      "|    ep_rew_mean     | 48.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 789      |\n",
      "|    time_elapsed    | 8007     |\n",
      "|    total_timesteps | 3231744  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.6        |\n",
      "|    ep_rew_mean          | 48.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 790         |\n",
      "|    time_elapsed         | 8016        |\n",
      "|    total_timesteps      | 3235840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013862723 |\n",
      "|    clip_fraction        | 0.318       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0102     |\n",
      "|    n_updates            | 7890        |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    value_loss           | 0.102       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.1        |\n",
      "|    ep_rew_mean          | 49.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 791         |\n",
      "|    time_elapsed         | 8026        |\n",
      "|    total_timesteps      | 3239936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014000921 |\n",
      "|    clip_fraction        | 0.324       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.000105    |\n",
      "|    n_updates            | 7900        |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    value_loss           | 0.105       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3240000, episode_reward=49.17 +/- 4.87\n",
      "Episode length: 78.40 +/- 12.03\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 78.4        |\n",
      "|    mean_reward          | 49.2        |\n",
      "|    std_reward           | 4.87        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3240000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012395838 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0012     |\n",
      "|    n_updates            | 7910        |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    value_loss           | 0.141       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79       |\n",
      "|    ep_rew_mean     | 48.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 792      |\n",
      "|    time_elapsed    | 8037     |\n",
      "|    total_timesteps | 3244032  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.8        |\n",
      "|    ep_rew_mean          | 49          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 793         |\n",
      "|    time_elapsed         | 8046        |\n",
      "|    total_timesteps      | 3248128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014132306 |\n",
      "|    clip_fraction        | 0.289       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00547    |\n",
      "|    n_updates            | 7920        |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 0.101       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3250000, episode_reward=51.12 +/- 3.84\n",
      "Episode length: 78.30 +/- 12.49\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 78.3        |\n",
      "|    mean_reward          | 51.1        |\n",
      "|    std_reward           | 3.84        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3250000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015448119 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00199     |\n",
      "|    n_updates            | 7930        |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    value_loss           | 0.15        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.2     |\n",
      "|    ep_rew_mean     | 49.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 794      |\n",
      "|    time_elapsed    | 8057     |\n",
      "|    total_timesteps | 3252224  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 77.3         |\n",
      "|    ep_rew_mean          | 50.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 403          |\n",
      "|    iterations           | 795          |\n",
      "|    time_elapsed         | 8067         |\n",
      "|    total_timesteps      | 3256320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0151177775 |\n",
      "|    clip_fraction        | 0.303        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.32        |\n",
      "|    explained_variance   | 0.998        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00858     |\n",
      "|    n_updates            | 7940         |\n",
      "|    policy_gradient_loss | -0.0157      |\n",
      "|    value_loss           | 0.1          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3260000, episode_reward=49.23 +/- 5.65\n",
      "Episode length: 81.50 +/- 11.35\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 81.5         |\n",
      "|    mean_reward          | 49.2         |\n",
      "|    std_reward           | 5.65         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3260000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0153758265 |\n",
      "|    clip_fraction        | 0.319        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.32        |\n",
      "|    explained_variance   | 0.998        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0065       |\n",
      "|    n_updates            | 7950         |\n",
      "|    policy_gradient_loss | -0.0132      |\n",
      "|    value_loss           | 0.102        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.3     |\n",
      "|    ep_rew_mean     | 49.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 796      |\n",
      "|    time_elapsed    | 8078     |\n",
      "|    total_timesteps | 3260416  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.6        |\n",
      "|    ep_rew_mean          | 49.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 797         |\n",
      "|    time_elapsed         | 8088        |\n",
      "|    total_timesteps      | 3264512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014784797 |\n",
      "|    clip_fraction        | 0.31        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.016       |\n",
      "|    n_updates            | 7960        |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 0.115       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 77.9         |\n",
      "|    ep_rew_mean          | 49.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 403          |\n",
      "|    iterations           | 798          |\n",
      "|    time_elapsed         | 8097         |\n",
      "|    total_timesteps      | 3268608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0151286945 |\n",
      "|    clip_fraction        | 0.309        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.35        |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0104      |\n",
      "|    n_updates            | 7970         |\n",
      "|    policy_gradient_loss | -0.0154      |\n",
      "|    value_loss           | 0.125        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3270000, episode_reward=48.04 +/- 5.48\n",
      "Episode length: 84.50 +/- 8.62\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 84.5        |\n",
      "|    mean_reward          | 48          |\n",
      "|    std_reward           | 5.48        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3270000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014989795 |\n",
      "|    clip_fraction        | 0.287       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0118     |\n",
      "|    n_updates            | 7980        |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    value_loss           | 0.116       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.4     |\n",
      "|    ep_rew_mean     | 49.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 799      |\n",
      "|    time_elapsed    | 8108     |\n",
      "|    total_timesteps | 3272704  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77          |\n",
      "|    ep_rew_mean          | 49.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 800         |\n",
      "|    time_elapsed         | 8118        |\n",
      "|    total_timesteps      | 3276800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013748337 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00188    |\n",
      "|    n_updates            | 7990        |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    value_loss           | 0.107       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3280000, episode_reward=50.66 +/- 6.57\n",
      "Episode length: 80.70 +/- 14.61\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 80.7        |\n",
      "|    mean_reward          | 50.7        |\n",
      "|    std_reward           | 6.57        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3280000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013869857 |\n",
      "|    clip_fraction        | 0.318       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.011       |\n",
      "|    n_updates            | 8000        |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    value_loss           | 0.101       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.1     |\n",
      "|    ep_rew_mean     | 49.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 801      |\n",
      "|    time_elapsed    | 8129     |\n",
      "|    total_timesteps | 3280896  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.9        |\n",
      "|    ep_rew_mean          | 49.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 802         |\n",
      "|    time_elapsed         | 8138        |\n",
      "|    total_timesteps      | 3284992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011874758 |\n",
      "|    clip_fraction        | 0.287       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00987    |\n",
      "|    n_updates            | 8010        |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    value_loss           | 0.117       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.1        |\n",
      "|    ep_rew_mean          | 49.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 803         |\n",
      "|    time_elapsed         | 8148        |\n",
      "|    total_timesteps      | 3289088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012076076 |\n",
      "|    clip_fraction        | 0.303       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00582    |\n",
      "|    n_updates            | 8020        |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    value_loss           | 0.104       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3290000, episode_reward=51.78 +/- 3.60\n",
      "Episode length: 81.20 +/- 7.68\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 81.2        |\n",
      "|    mean_reward          | 51.8        |\n",
      "|    std_reward           | 3.6         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3290000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012924941 |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0116     |\n",
      "|    n_updates            | 8030        |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    value_loss           | 0.101       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.9     |\n",
      "|    ep_rew_mean     | 49.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 804      |\n",
      "|    time_elapsed    | 8159     |\n",
      "|    total_timesteps | 3293184  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78          |\n",
      "|    ep_rew_mean          | 49.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 805         |\n",
      "|    time_elapsed         | 8169        |\n",
      "|    total_timesteps      | 3297280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011744559 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00104     |\n",
      "|    n_updates            | 8040        |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    value_loss           | 0.112       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3300000, episode_reward=49.40 +/- 7.17\n",
      "Episode length: 77.90 +/- 11.65\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 77.9         |\n",
      "|    mean_reward          | 49.4         |\n",
      "|    std_reward           | 7.17         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3300000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0126123745 |\n",
      "|    clip_fraction        | 0.288        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.32        |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00912     |\n",
      "|    n_updates            | 8050         |\n",
      "|    policy_gradient_loss | -0.0149      |\n",
      "|    value_loss           | 0.101        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.2     |\n",
      "|    ep_rew_mean     | 49.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 806      |\n",
      "|    time_elapsed    | 8179     |\n",
      "|    total_timesteps | 3301376  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.6        |\n",
      "|    ep_rew_mean          | 50.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 807         |\n",
      "|    time_elapsed         | 8189        |\n",
      "|    total_timesteps      | 3305472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013327599 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0048      |\n",
      "|    n_updates            | 8060        |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    value_loss           | 0.116       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.6        |\n",
      "|    ep_rew_mean          | 49.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 808         |\n",
      "|    time_elapsed         | 8199        |\n",
      "|    total_timesteps      | 3309568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016156828 |\n",
      "|    clip_fraction        | 0.335       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.000152    |\n",
      "|    n_updates            | 8070        |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 0.0836      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3310000, episode_reward=49.86 +/- 5.57\n",
      "Episode length: 81.50 +/- 9.37\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 81.5        |\n",
      "|    mean_reward          | 49.9        |\n",
      "|    std_reward           | 5.57        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3310000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013699856 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00395     |\n",
      "|    n_updates            | 8080        |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    value_loss           | 0.108       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.1     |\n",
      "|    ep_rew_mean     | 49.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 809      |\n",
      "|    time_elapsed    | 8210     |\n",
      "|    total_timesteps | 3313664  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.6        |\n",
      "|    ep_rew_mean          | 49.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 810         |\n",
      "|    time_elapsed         | 8219        |\n",
      "|    total_timesteps      | 3317760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016211085 |\n",
      "|    clip_fraction        | 0.318       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00859    |\n",
      "|    n_updates            | 8090        |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    value_loss           | 0.0778      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3320000, episode_reward=50.43 +/- 3.76\n",
      "Episode length: 78.90 +/- 7.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 78.9        |\n",
      "|    mean_reward          | 50.4        |\n",
      "|    std_reward           | 3.76        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3320000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011781394 |\n",
      "|    clip_fraction        | 0.313       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00733    |\n",
      "|    n_updates            | 8100        |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    value_loss           | 0.124       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78       |\n",
      "|    ep_rew_mean     | 49.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 811      |\n",
      "|    time_elapsed    | 8230     |\n",
      "|    total_timesteps | 3321856  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.2        |\n",
      "|    ep_rew_mean          | 49.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 812         |\n",
      "|    time_elapsed         | 8240        |\n",
      "|    total_timesteps      | 3325952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015159898 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.000227    |\n",
      "|    n_updates            | 8110        |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    value_loss           | 0.0923      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3330000, episode_reward=51.06 +/- 4.64\n",
      "Episode length: 75.70 +/- 8.71\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 75.7        |\n",
      "|    mean_reward          | 51.1        |\n",
      "|    std_reward           | 4.64        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3330000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015360272 |\n",
      "|    clip_fraction        | 0.315       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0126     |\n",
      "|    n_updates            | 8120        |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    value_loss           | 0.0849      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.6     |\n",
      "|    ep_rew_mean     | 49.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 813      |\n",
      "|    time_elapsed    | 8251     |\n",
      "|    total_timesteps | 3330048  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.6        |\n",
      "|    ep_rew_mean          | 49.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 814         |\n",
      "|    time_elapsed         | 8261        |\n",
      "|    total_timesteps      | 3334144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014448741 |\n",
      "|    clip_fraction        | 0.307       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.000337   |\n",
      "|    n_updates            | 8130        |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    value_loss           | 0.1         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 75.8       |\n",
      "|    ep_rew_mean          | 49.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 403        |\n",
      "|    iterations           | 815        |\n",
      "|    time_elapsed         | 8270       |\n",
      "|    total_timesteps      | 3338240    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01258667 |\n",
      "|    clip_fraction        | 0.305      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.29      |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | 0.00201    |\n",
      "|    n_updates            | 8140       |\n",
      "|    policy_gradient_loss | -0.015     |\n",
      "|    value_loss           | 0.105      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3340000, episode_reward=50.49 +/- 4.76\n",
      "Episode length: 81.90 +/- 10.15\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 81.9        |\n",
      "|    mean_reward          | 50.5        |\n",
      "|    std_reward           | 4.76        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3340000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015335839 |\n",
      "|    clip_fraction        | 0.303       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00274    |\n",
      "|    n_updates            | 8150        |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    value_loss           | 0.119       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.3     |\n",
      "|    ep_rew_mean     | 49.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 816      |\n",
      "|    time_elapsed    | 8281     |\n",
      "|    total_timesteps | 3342336  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 77.7         |\n",
      "|    ep_rew_mean          | 49.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 403          |\n",
      "|    iterations           | 817          |\n",
      "|    time_elapsed         | 8291         |\n",
      "|    total_timesteps      | 3346432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0110572865 |\n",
      "|    clip_fraction        | 0.276        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.3         |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.00685      |\n",
      "|    n_updates            | 8160         |\n",
      "|    policy_gradient_loss | -0.0138      |\n",
      "|    value_loss           | 0.112        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3350000, episode_reward=49.85 +/- 3.34\n",
      "Episode length: 83.20 +/- 7.22\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 83.2        |\n",
      "|    mean_reward          | 49.8        |\n",
      "|    std_reward           | 3.34        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3350000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012118238 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0148     |\n",
      "|    n_updates            | 8170        |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    value_loss           | 0.0982      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 75.5     |\n",
      "|    ep_rew_mean     | 50.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 818      |\n",
      "|    time_elapsed    | 8302     |\n",
      "|    total_timesteps | 3350528  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.1        |\n",
      "|    ep_rew_mean          | 50.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 819         |\n",
      "|    time_elapsed         | 8312        |\n",
      "|    total_timesteps      | 3354624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017090464 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0048      |\n",
      "|    n_updates            | 8180        |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    value_loss           | 0.112       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.8        |\n",
      "|    ep_rew_mean          | 50.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 820         |\n",
      "|    time_elapsed         | 8321        |\n",
      "|    total_timesteps      | 3358720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013738962 |\n",
      "|    clip_fraction        | 0.301       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00855    |\n",
      "|    n_updates            | 8190        |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    value_loss           | 0.106       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3360000, episode_reward=51.66 +/- 6.01\n",
      "Episode length: 76.60 +/- 9.16\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 76.6       |\n",
      "|    mean_reward          | 51.7       |\n",
      "|    std_reward           | 6.01       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3360000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01606308 |\n",
      "|    clip_fraction        | 0.339      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.32      |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.00882   |\n",
      "|    n_updates            | 8200       |\n",
      "|    policy_gradient_loss | -0.0138    |\n",
      "|    value_loss           | 0.0862     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.1     |\n",
      "|    ep_rew_mean     | 49.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 821      |\n",
      "|    time_elapsed    | 8332     |\n",
      "|    total_timesteps | 3362816  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.3        |\n",
      "|    ep_rew_mean          | 48.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 822         |\n",
      "|    time_elapsed         | 8342        |\n",
      "|    total_timesteps      | 3366912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012209266 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00881    |\n",
      "|    n_updates            | 8210        |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    value_loss           | 0.107       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3370000, episode_reward=53.01 +/- 5.61\n",
      "Episode length: 74.60 +/- 7.34\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 74.6        |\n",
      "|    mean_reward          | 53          |\n",
      "|    std_reward           | 5.61        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3370000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015287142 |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00492    |\n",
      "|    n_updates            | 8220        |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    value_loss           | 0.107       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.8     |\n",
      "|    ep_rew_mean     | 49.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 823      |\n",
      "|    time_elapsed    | 8353     |\n",
      "|    total_timesteps | 3371008  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.1        |\n",
      "|    ep_rew_mean          | 50.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 824         |\n",
      "|    time_elapsed         | 8362        |\n",
      "|    total_timesteps      | 3375104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014458425 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0149     |\n",
      "|    n_updates            | 8230        |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 0.0799      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.1        |\n",
      "|    ep_rew_mean          | 49.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 825         |\n",
      "|    time_elapsed         | 8372        |\n",
      "|    total_timesteps      | 3379200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013074789 |\n",
      "|    clip_fraction        | 0.307       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.021       |\n",
      "|    n_updates            | 8240        |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    value_loss           | 0.11        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3380000, episode_reward=49.37 +/- 4.00\n",
      "Episode length: 80.80 +/- 7.73\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 80.8        |\n",
      "|    mean_reward          | 49.4        |\n",
      "|    std_reward           | 4           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3380000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013184624 |\n",
      "|    clip_fraction        | 0.305       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00732    |\n",
      "|    n_updates            | 8250        |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    value_loss           | 0.102       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.5     |\n",
      "|    ep_rew_mean     | 49       |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 826      |\n",
      "|    time_elapsed    | 8383     |\n",
      "|    total_timesteps | 3383296  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.5        |\n",
      "|    ep_rew_mean          | 49.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 827         |\n",
      "|    time_elapsed         | 8393        |\n",
      "|    total_timesteps      | 3387392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015533777 |\n",
      "|    clip_fraction        | 0.325       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0056     |\n",
      "|    n_updates            | 8260        |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    value_loss           | 0.0948      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3390000, episode_reward=49.93 +/- 5.55\n",
      "Episode length: 76.60 +/- 11.69\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 76.6        |\n",
      "|    mean_reward          | 49.9        |\n",
      "|    std_reward           | 5.55        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3390000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014415793 |\n",
      "|    clip_fraction        | 0.314       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0107      |\n",
      "|    n_updates            | 8270        |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    value_loss           | 0.0821      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.9     |\n",
      "|    ep_rew_mean     | 49.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 828      |\n",
      "|    time_elapsed    | 8404     |\n",
      "|    total_timesteps | 3391488  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 80.1        |\n",
      "|    ep_rew_mean          | 49          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 829         |\n",
      "|    time_elapsed         | 8413        |\n",
      "|    total_timesteps      | 3395584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014268937 |\n",
      "|    clip_fraction        | 0.309       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0124     |\n",
      "|    n_updates            | 8280        |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    value_loss           | 0.0875      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.5        |\n",
      "|    ep_rew_mean          | 48.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 830         |\n",
      "|    time_elapsed         | 8423        |\n",
      "|    total_timesteps      | 3399680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014453368 |\n",
      "|    clip_fraction        | 0.314       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00823    |\n",
      "|    n_updates            | 8290        |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    value_loss           | 0.0846      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3400000, episode_reward=53.49 +/- 3.82\n",
      "Episode length: 72.10 +/- 10.93\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 72.1        |\n",
      "|    mean_reward          | 53.5        |\n",
      "|    std_reward           | 3.82        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3400000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015212504 |\n",
      "|    clip_fraction        | 0.317       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00669    |\n",
      "|    n_updates            | 8300        |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    value_loss           | 0.0947      |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.1     |\n",
      "|    ep_rew_mean     | 48.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 831      |\n",
      "|    time_elapsed    | 8434     |\n",
      "|    total_timesteps | 3403776  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.1        |\n",
      "|    ep_rew_mean          | 49.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 832         |\n",
      "|    time_elapsed         | 8443        |\n",
      "|    total_timesteps      | 3407872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014288374 |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0166     |\n",
      "|    n_updates            | 8310        |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    value_loss           | 0.117       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3410000, episode_reward=51.18 +/- 2.82\n",
      "Episode length: 79.90 +/- 8.01\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 79.9       |\n",
      "|    mean_reward          | 51.2       |\n",
      "|    std_reward           | 2.82       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3410000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01778257 |\n",
      "|    clip_fraction        | 0.303      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.31      |\n",
      "|    explained_variance   | 0.997      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.0146    |\n",
      "|    n_updates            | 8320       |\n",
      "|    policy_gradient_loss | -0.0132    |\n",
      "|    value_loss           | 0.111      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 76.8     |\n",
      "|    ep_rew_mean     | 49.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 833      |\n",
      "|    time_elapsed    | 8454     |\n",
      "|    total_timesteps | 3411968  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 78         |\n",
      "|    ep_rew_mean          | 49.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 403        |\n",
      "|    iterations           | 834        |\n",
      "|    time_elapsed         | 8464       |\n",
      "|    total_timesteps      | 3416064    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01542901 |\n",
      "|    clip_fraction        | 0.299      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.31      |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.00659   |\n",
      "|    n_updates            | 8330       |\n",
      "|    policy_gradient_loss | -0.015     |\n",
      "|    value_loss           | 0.0945     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3420000, episode_reward=52.40 +/- 4.99\n",
      "Episode length: 77.00 +/- 9.02\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 77          |\n",
      "|    mean_reward          | 52.4        |\n",
      "|    std_reward           | 4.99        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3420000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014518831 |\n",
      "|    clip_fraction        | 0.312       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0295     |\n",
      "|    n_updates            | 8340        |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    value_loss           | 0.0913      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.8     |\n",
      "|    ep_rew_mean     | 49.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 835      |\n",
      "|    time_elapsed    | 8475     |\n",
      "|    total_timesteps | 3420160  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.3        |\n",
      "|    ep_rew_mean          | 49.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 836         |\n",
      "|    time_elapsed         | 8484        |\n",
      "|    total_timesteps      | 3424256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014155094 |\n",
      "|    clip_fraction        | 0.301       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0153     |\n",
      "|    n_updates            | 8350        |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 0.0912      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.8        |\n",
      "|    ep_rew_mean          | 50          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 837         |\n",
      "|    time_elapsed         | 8494        |\n",
      "|    total_timesteps      | 3428352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014519658 |\n",
      "|    clip_fraction        | 0.309       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00805     |\n",
      "|    n_updates            | 8360        |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    value_loss           | 0.0926      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3430000, episode_reward=45.33 +/- 14.40\n",
      "Episode length: 81.20 +/- 10.94\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 81.2         |\n",
      "|    mean_reward          | 45.3         |\n",
      "|    std_reward           | 14.4         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3430000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0110471565 |\n",
      "|    clip_fraction        | 0.266        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.33        |\n",
      "|    explained_variance   | 0.996        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.00236      |\n",
      "|    n_updates            | 8370         |\n",
      "|    policy_gradient_loss | -0.016       |\n",
      "|    value_loss           | 0.146        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.3     |\n",
      "|    ep_rew_mean     | 49.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 838      |\n",
      "|    time_elapsed    | 8505     |\n",
      "|    total_timesteps | 3432448  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.8        |\n",
      "|    ep_rew_mean          | 49.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 839         |\n",
      "|    time_elapsed         | 8514        |\n",
      "|    total_timesteps      | 3436544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013859018 |\n",
      "|    clip_fraction        | 0.3         |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0118     |\n",
      "|    n_updates            | 8380        |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    value_loss           | 0.111       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3440000, episode_reward=51.68 +/- 3.73\n",
      "Episode length: 75.00 +/- 7.16\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 75          |\n",
      "|    mean_reward          | 51.7        |\n",
      "|    std_reward           | 3.73        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3440000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014538588 |\n",
      "|    clip_fraction        | 0.31        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0116     |\n",
      "|    n_updates            | 8390        |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    value_loss           | 0.096       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.6     |\n",
      "|    ep_rew_mean     | 50       |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 840      |\n",
      "|    time_elapsed    | 8525     |\n",
      "|    total_timesteps | 3440640  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.2        |\n",
      "|    ep_rew_mean          | 49.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 841         |\n",
      "|    time_elapsed         | 8535        |\n",
      "|    total_timesteps      | 3444736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012387718 |\n",
      "|    clip_fraction        | 0.305       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0145     |\n",
      "|    n_updates            | 8400        |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    value_loss           | 0.103       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.9        |\n",
      "|    ep_rew_mean          | 49.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 842         |\n",
      "|    time_elapsed         | 8544        |\n",
      "|    total_timesteps      | 3448832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011656897 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00153     |\n",
      "|    n_updates            | 8410        |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    value_loss           | 0.119       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3450000, episode_reward=50.42 +/- 5.69\n",
      "Episode length: 80.40 +/- 6.89\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 80.4        |\n",
      "|    mean_reward          | 50.4        |\n",
      "|    std_reward           | 5.69        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3450000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013804631 |\n",
      "|    clip_fraction        | 0.305       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00728    |\n",
      "|    n_updates            | 8420        |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 0.121       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.4     |\n",
      "|    ep_rew_mean     | 49.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 843      |\n",
      "|    time_elapsed    | 8555     |\n",
      "|    total_timesteps | 3452928  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.1        |\n",
      "|    ep_rew_mean          | 49.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 844         |\n",
      "|    time_elapsed         | 8565        |\n",
      "|    total_timesteps      | 3457024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014556002 |\n",
      "|    clip_fraction        | 0.323       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00827    |\n",
      "|    n_updates            | 8430        |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    value_loss           | 0.102       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3460000, episode_reward=49.18 +/- 3.89\n",
      "Episode length: 79.20 +/- 7.86\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 79.2        |\n",
      "|    mean_reward          | 49.2        |\n",
      "|    std_reward           | 3.89        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3460000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013929704 |\n",
      "|    clip_fraction        | 0.328       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00401    |\n",
      "|    n_updates            | 8440        |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    value_loss           | 0.0993      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.2     |\n",
      "|    ep_rew_mean     | 48.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 845      |\n",
      "|    time_elapsed    | 8576     |\n",
      "|    total_timesteps | 3461120  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.4        |\n",
      "|    ep_rew_mean          | 49.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 846         |\n",
      "|    time_elapsed         | 8586        |\n",
      "|    total_timesteps      | 3465216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014156818 |\n",
      "|    clip_fraction        | 0.325       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0071     |\n",
      "|    n_updates            | 8450        |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    value_loss           | 0.119       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.4        |\n",
      "|    ep_rew_mean          | 49.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 847         |\n",
      "|    time_elapsed         | 8595        |\n",
      "|    total_timesteps      | 3469312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016199648 |\n",
      "|    clip_fraction        | 0.321       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0124     |\n",
      "|    n_updates            | 8460        |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    value_loss           | 0.105       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3470000, episode_reward=52.31 +/- 3.46\n",
      "Episode length: 71.40 +/- 7.47\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 71.4        |\n",
      "|    mean_reward          | 52.3        |\n",
      "|    std_reward           | 3.46        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3470000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013572418 |\n",
      "|    clip_fraction        | 0.314       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0154     |\n",
      "|    n_updates            | 8470        |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    value_loss           | 0.106       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77       |\n",
      "|    ep_rew_mean     | 49.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 848      |\n",
      "|    time_elapsed    | 8606     |\n",
      "|    total_timesteps | 3473408  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.4        |\n",
      "|    ep_rew_mean          | 49.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 849         |\n",
      "|    time_elapsed         | 8616        |\n",
      "|    total_timesteps      | 3477504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016459096 |\n",
      "|    clip_fraction        | 0.323       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00739    |\n",
      "|    n_updates            | 8480        |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 0.101       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3480000, episode_reward=50.49 +/- 4.60\n",
      "Episode length: 79.70 +/- 6.69\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 79.7        |\n",
      "|    mean_reward          | 50.5        |\n",
      "|    std_reward           | 4.6         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3480000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016737659 |\n",
      "|    clip_fraction        | 0.329       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0172     |\n",
      "|    n_updates            | 8490        |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    value_loss           | 0.0836      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.5     |\n",
      "|    ep_rew_mean     | 49.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 850      |\n",
      "|    time_elapsed    | 8627     |\n",
      "|    total_timesteps | 3481600  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 80.2       |\n",
      "|    ep_rew_mean          | 49.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 403        |\n",
      "|    iterations           | 851        |\n",
      "|    time_elapsed         | 8637       |\n",
      "|    total_timesteps      | 3485696    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01580148 |\n",
      "|    clip_fraction        | 0.322      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.35      |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.00528   |\n",
      "|    n_updates            | 8500       |\n",
      "|    policy_gradient_loss | -0.015     |\n",
      "|    value_loss           | 0.0854     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.7        |\n",
      "|    ep_rew_mean          | 49.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 852         |\n",
      "|    time_elapsed         | 8646        |\n",
      "|    total_timesteps      | 3489792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014499847 |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0129     |\n",
      "|    n_updates            | 8510        |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    value_loss           | 0.0763      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3490000, episode_reward=48.47 +/- 5.62\n",
      "Episode length: 80.40 +/- 9.30\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 80.4        |\n",
      "|    mean_reward          | 48.5        |\n",
      "|    std_reward           | 5.62        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3490000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014731498 |\n",
      "|    clip_fraction        | 0.314       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0221     |\n",
      "|    n_updates            | 8520        |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    value_loss           | 0.0891      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 80.1     |\n",
      "|    ep_rew_mean     | 49.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 853      |\n",
      "|    time_elapsed    | 8657     |\n",
      "|    total_timesteps | 3493888  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.6        |\n",
      "|    ep_rew_mean          | 49.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 854         |\n",
      "|    time_elapsed         | 8667        |\n",
      "|    total_timesteps      | 3497984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011552764 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0047     |\n",
      "|    n_updates            | 8530        |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    value_loss           | 0.0847      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3500000, episode_reward=50.65 +/- 4.35\n",
      "Episode length: 79.40 +/- 9.59\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 79.4        |\n",
      "|    mean_reward          | 50.7        |\n",
      "|    std_reward           | 4.35        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3500000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013111327 |\n",
      "|    clip_fraction        | 0.325       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00775    |\n",
      "|    n_updates            | 8540        |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    value_loss           | 0.0903      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.8     |\n",
      "|    ep_rew_mean     | 49.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 855      |\n",
      "|    time_elapsed    | 8678     |\n",
      "|    total_timesteps | 3502080  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.3        |\n",
      "|    ep_rew_mean          | 49.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 856         |\n",
      "|    time_elapsed         | 8687        |\n",
      "|    total_timesteps      | 3506176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013846973 |\n",
      "|    clip_fraction        | 0.315       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00853    |\n",
      "|    n_updates            | 8550        |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    value_loss           | 0.101       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3510000, episode_reward=51.23 +/- 3.92\n",
      "Episode length: 75.20 +/- 6.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 75.2        |\n",
      "|    mean_reward          | 51.2        |\n",
      "|    std_reward           | 3.92        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3510000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015015254 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0124     |\n",
      "|    n_updates            | 8560        |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    value_loss           | 0.0922      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.6     |\n",
      "|    ep_rew_mean     | 50.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 857      |\n",
      "|    time_elapsed    | 8698     |\n",
      "|    total_timesteps | 3510272  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.1        |\n",
      "|    ep_rew_mean          | 50.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 858         |\n",
      "|    time_elapsed         | 8707        |\n",
      "|    total_timesteps      | 3514368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014410457 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.000732    |\n",
      "|    n_updates            | 8570        |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    value_loss           | 0.0909      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.9        |\n",
      "|    ep_rew_mean          | 50.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 859         |\n",
      "|    time_elapsed         | 8717        |\n",
      "|    total_timesteps      | 3518464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015449259 |\n",
      "|    clip_fraction        | 0.327       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.000471   |\n",
      "|    n_updates            | 8580        |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    value_loss           | 0.0958      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3520000, episode_reward=51.10 +/- 3.82\n",
      "Episode length: 77.60 +/- 8.64\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 77.6        |\n",
      "|    mean_reward          | 51.1        |\n",
      "|    std_reward           | 3.82        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3520000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014561029 |\n",
      "|    clip_fraction        | 0.31        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00626    |\n",
      "|    n_updates            | 8590        |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    value_loss           | 0.121       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.6     |\n",
      "|    ep_rew_mean     | 49.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 860      |\n",
      "|    time_elapsed    | 8728     |\n",
      "|    total_timesteps | 3522560  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.4        |\n",
      "|    ep_rew_mean          | 49.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 861         |\n",
      "|    time_elapsed         | 8738        |\n",
      "|    total_timesteps      | 3526656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012797374 |\n",
      "|    clip_fraction        | 0.307       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00835    |\n",
      "|    n_updates            | 8600        |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    value_loss           | 0.0913      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3530000, episode_reward=54.04 +/- 2.92\n",
      "Episode length: 72.80 +/- 8.57\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 72.8        |\n",
      "|    mean_reward          | 54          |\n",
      "|    std_reward           | 2.92        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3530000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015666585 |\n",
      "|    clip_fraction        | 0.315       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0061     |\n",
      "|    n_updates            | 8610        |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    value_loss           | 0.0947      |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.3     |\n",
      "|    ep_rew_mean     | 50.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 862      |\n",
      "|    time_elapsed    | 8748     |\n",
      "|    total_timesteps | 3530752  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.9        |\n",
      "|    ep_rew_mean          | 50.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 863         |\n",
      "|    time_elapsed         | 8758        |\n",
      "|    total_timesteps      | 3534848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011478143 |\n",
      "|    clip_fraction        | 0.284       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00625     |\n",
      "|    n_updates            | 8620        |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    value_loss           | 0.101       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.3        |\n",
      "|    ep_rew_mean          | 50.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 864         |\n",
      "|    time_elapsed         | 8768        |\n",
      "|    total_timesteps      | 3538944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015539769 |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0215     |\n",
      "|    n_updates            | 8630        |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    value_loss           | 0.113       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3540000, episode_reward=52.70 +/- 4.56\n",
      "Episode length: 77.90 +/- 6.83\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 77.9        |\n",
      "|    mean_reward          | 52.7        |\n",
      "|    std_reward           | 4.56        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3540000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016067468 |\n",
      "|    clip_fraction        | 0.323       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00843    |\n",
      "|    n_updates            | 8640        |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    value_loss           | 0.0975      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79       |\n",
      "|    ep_rew_mean     | 49.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 865      |\n",
      "|    time_elapsed    | 8779     |\n",
      "|    total_timesteps | 3543040  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 79.2       |\n",
      "|    ep_rew_mean          | 49.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 403        |\n",
      "|    iterations           | 866        |\n",
      "|    time_elapsed         | 8788       |\n",
      "|    total_timesteps      | 3547136    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01414069 |\n",
      "|    clip_fraction        | 0.303      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.27      |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.0104    |\n",
      "|    n_updates            | 8650       |\n",
      "|    policy_gradient_loss | -0.0164    |\n",
      "|    value_loss           | 0.0957     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3550000, episode_reward=51.30 +/- 6.75\n",
      "Episode length: 80.40 +/- 10.73\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 80.4        |\n",
      "|    mean_reward          | 51.3        |\n",
      "|    std_reward           | 6.75        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3550000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013362408 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0133     |\n",
      "|    n_updates            | 8660        |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 0.0805      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.5     |\n",
      "|    ep_rew_mean     | 49.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 867      |\n",
      "|    time_elapsed    | 8799     |\n",
      "|    total_timesteps | 3551232  |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 78.4      |\n",
      "|    ep_rew_mean          | 49.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 403       |\n",
      "|    iterations           | 868       |\n",
      "|    time_elapsed         | 8809      |\n",
      "|    total_timesteps      | 3555328   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0135427 |\n",
      "|    clip_fraction        | 0.306     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -1.28     |\n",
      "|    explained_variance   | 0.998     |\n",
      "|    learning_rate        | 5e-05     |\n",
      "|    loss                 | -0.0106   |\n",
      "|    n_updates            | 8670      |\n",
      "|    policy_gradient_loss | -0.0154   |\n",
      "|    value_loss           | 0.112     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.4        |\n",
      "|    ep_rew_mean          | 49          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 869         |\n",
      "|    time_elapsed         | 8819        |\n",
      "|    total_timesteps      | 3559424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015097309 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00894     |\n",
      "|    n_updates            | 8680        |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    value_loss           | 0.0938      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3560000, episode_reward=51.94 +/- 5.63\n",
      "Episode length: 78.60 +/- 7.34\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 78.6        |\n",
      "|    mean_reward          | 51.9        |\n",
      "|    std_reward           | 5.63        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3560000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014171304 |\n",
      "|    clip_fraction        | 0.334       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00508     |\n",
      "|    n_updates            | 8690        |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    value_loss           | 0.104       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.2     |\n",
      "|    ep_rew_mean     | 49.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 870      |\n",
      "|    time_elapsed    | 8830     |\n",
      "|    total_timesteps | 3563520  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78.9         |\n",
      "|    ep_rew_mean          | 49.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 403          |\n",
      "|    iterations           | 871          |\n",
      "|    time_elapsed         | 8839         |\n",
      "|    total_timesteps      | 3567616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0153947715 |\n",
      "|    clip_fraction        | 0.338        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.3         |\n",
      "|    explained_variance   | 0.998        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0137      |\n",
      "|    n_updates            | 8700         |\n",
      "|    policy_gradient_loss | -0.0141      |\n",
      "|    value_loss           | 0.0966       |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3570000, episode_reward=53.88 +/- 2.30\n",
      "Episode length: 75.00 +/- 7.17\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 75          |\n",
      "|    mean_reward          | 53.9        |\n",
      "|    std_reward           | 2.3         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3570000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012464169 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0032     |\n",
      "|    n_updates            | 8710        |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    value_loss           | 0.145       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.6     |\n",
      "|    ep_rew_mean     | 49.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 872      |\n",
      "|    time_elapsed    | 8850     |\n",
      "|    total_timesteps | 3571712  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 80.3         |\n",
      "|    ep_rew_mean          | 49.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 403          |\n",
      "|    iterations           | 873          |\n",
      "|    time_elapsed         | 8860         |\n",
      "|    total_timesteps      | 3575808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0124104675 |\n",
      "|    clip_fraction        | 0.289        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.27        |\n",
      "|    explained_variance   | 0.996        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0111      |\n",
      "|    n_updates            | 8720         |\n",
      "|    policy_gradient_loss | -0.0163      |\n",
      "|    value_loss           | 0.131        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.7        |\n",
      "|    ep_rew_mean          | 49.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 874         |\n",
      "|    time_elapsed         | 8870        |\n",
      "|    total_timesteps      | 3579904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014588138 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00268     |\n",
      "|    n_updates            | 8730        |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    value_loss           | 0.0987      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3580000, episode_reward=50.68 +/- 4.19\n",
      "Episode length: 80.10 +/- 4.23\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 80.1        |\n",
      "|    mean_reward          | 50.7        |\n",
      "|    std_reward           | 4.19        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3580000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013623187 |\n",
      "|    clip_fraction        | 0.313       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00601    |\n",
      "|    n_updates            | 8740        |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 0.0929      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.8     |\n",
      "|    ep_rew_mean     | 50.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 875      |\n",
      "|    time_elapsed    | 8881     |\n",
      "|    total_timesteps | 3584000  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.1        |\n",
      "|    ep_rew_mean          | 50.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 876         |\n",
      "|    time_elapsed         | 8890        |\n",
      "|    total_timesteps      | 3588096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015569672 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00892    |\n",
      "|    n_updates            | 8750        |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 0.0949      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3590000, episode_reward=53.77 +/- 4.89\n",
      "Episode length: 69.50 +/- 6.80\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 69.5        |\n",
      "|    mean_reward          | 53.8        |\n",
      "|    std_reward           | 4.89        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3590000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013666259 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0123     |\n",
      "|    n_updates            | 8760        |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    value_loss           | 0.101       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.5     |\n",
      "|    ep_rew_mean     | 49.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 877      |\n",
      "|    time_elapsed    | 8901     |\n",
      "|    total_timesteps | 3592192  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.1        |\n",
      "|    ep_rew_mean          | 50.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 878         |\n",
      "|    time_elapsed         | 8910        |\n",
      "|    total_timesteps      | 3596288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018813187 |\n",
      "|    clip_fraction        | 0.321       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00331    |\n",
      "|    n_updates            | 8770        |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    value_loss           | 0.0976      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3600000, episode_reward=50.97 +/- 2.83\n",
      "Episode length: 80.30 +/- 7.91\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 80.3        |\n",
      "|    mean_reward          | 51          |\n",
      "|    std_reward           | 2.83        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3600000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011678094 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00147    |\n",
      "|    n_updates            | 8780        |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    value_loss           | 0.129       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 76.2     |\n",
      "|    ep_rew_mean     | 50.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 879      |\n",
      "|    time_elapsed    | 8921     |\n",
      "|    total_timesteps | 3600384  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.4        |\n",
      "|    ep_rew_mean          | 49.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 880         |\n",
      "|    time_elapsed         | 8931        |\n",
      "|    total_timesteps      | 3604480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017448144 |\n",
      "|    clip_fraction        | 0.31        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00798    |\n",
      "|    n_updates            | 8790        |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    value_loss           | 0.086       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.3        |\n",
      "|    ep_rew_mean          | 49.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 881         |\n",
      "|    time_elapsed         | 8940        |\n",
      "|    total_timesteps      | 3608576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012918042 |\n",
      "|    clip_fraction        | 0.293       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0131     |\n",
      "|    n_updates            | 8800        |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    value_loss           | 0.104       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3610000, episode_reward=50.00 +/- 5.64\n",
      "Episode length: 82.10 +/- 13.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 82.1         |\n",
      "|    mean_reward          | 50           |\n",
      "|    std_reward           | 5.64         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3610000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0140622165 |\n",
      "|    clip_fraction        | 0.307        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.3         |\n",
      "|    explained_variance   | 0.998        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00288     |\n",
      "|    n_updates            | 8810         |\n",
      "|    policy_gradient_loss | -0.0144      |\n",
      "|    value_loss           | 0.109        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.6     |\n",
      "|    ep_rew_mean     | 49.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 882      |\n",
      "|    time_elapsed    | 8951     |\n",
      "|    total_timesteps | 3612672  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.9        |\n",
      "|    ep_rew_mean          | 50.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 883         |\n",
      "|    time_elapsed         | 8961        |\n",
      "|    total_timesteps      | 3616768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014367596 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00182    |\n",
      "|    n_updates            | 8820        |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    value_loss           | 0.111       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3620000, episode_reward=50.18 +/- 4.59\n",
      "Episode length: 79.40 +/- 8.52\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 79.4        |\n",
      "|    mean_reward          | 50.2        |\n",
      "|    std_reward           | 4.59        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3620000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013939975 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00965     |\n",
      "|    n_updates            | 8830        |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    value_loss           | 0.131       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 76.5     |\n",
      "|    ep_rew_mean     | 49.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 884      |\n",
      "|    time_elapsed    | 8972     |\n",
      "|    total_timesteps | 3620864  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.3        |\n",
      "|    ep_rew_mean          | 50          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 885         |\n",
      "|    time_elapsed         | 8981        |\n",
      "|    total_timesteps      | 3624960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014257781 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00277    |\n",
      "|    n_updates            | 8840        |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    value_loss           | 0.115       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78.9         |\n",
      "|    ep_rew_mean          | 49.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 403          |\n",
      "|    iterations           | 886          |\n",
      "|    time_elapsed         | 8991         |\n",
      "|    total_timesteps      | 3629056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0142396875 |\n",
      "|    clip_fraction        | 0.275        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.26        |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.00231      |\n",
      "|    n_updates            | 8850         |\n",
      "|    policy_gradient_loss | -0.013       |\n",
      "|    value_loss           | 0.119        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3630000, episode_reward=49.94 +/- 4.41\n",
      "Episode length: 80.10 +/- 10.87\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 80.1        |\n",
      "|    mean_reward          | 49.9        |\n",
      "|    std_reward           | 4.41        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3630000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014852757 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00304    |\n",
      "|    n_updates            | 8860        |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    value_loss           | 0.108       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.3     |\n",
      "|    ep_rew_mean     | 49.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 887      |\n",
      "|    time_elapsed    | 9002     |\n",
      "|    total_timesteps | 3633152  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.2        |\n",
      "|    ep_rew_mean          | 49.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 888         |\n",
      "|    time_elapsed         | 9012        |\n",
      "|    total_timesteps      | 3637248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015319394 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00575    |\n",
      "|    n_updates            | 8870        |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    value_loss           | 0.081       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3640000, episode_reward=49.37 +/- 3.63\n",
      "Episode length: 78.80 +/- 10.51\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 78.8        |\n",
      "|    mean_reward          | 49.4        |\n",
      "|    std_reward           | 3.63        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3640000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014189387 |\n",
      "|    clip_fraction        | 0.333       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0119     |\n",
      "|    n_updates            | 8880        |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    value_loss           | 0.0821      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.5     |\n",
      "|    ep_rew_mean     | 48.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 889      |\n",
      "|    time_elapsed    | 9023     |\n",
      "|    total_timesteps | 3641344  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.5        |\n",
      "|    ep_rew_mean          | 48.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 890         |\n",
      "|    time_elapsed         | 9032        |\n",
      "|    total_timesteps      | 3645440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013357375 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0153     |\n",
      "|    n_updates            | 8890        |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    value_loss           | 0.1         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.3        |\n",
      "|    ep_rew_mean          | 50          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 891         |\n",
      "|    time_elapsed         | 9042        |\n",
      "|    total_timesteps      | 3649536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013433376 |\n",
      "|    clip_fraction        | 0.302       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0112     |\n",
      "|    n_updates            | 8900        |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    value_loss           | 0.105       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3650000, episode_reward=50.86 +/- 3.58\n",
      "Episode length: 80.10 +/- 9.67\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 80.1        |\n",
      "|    mean_reward          | 50.9        |\n",
      "|    std_reward           | 3.58        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3650000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014652194 |\n",
      "|    clip_fraction        | 0.3         |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -4.07e-06   |\n",
      "|    n_updates            | 8910        |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    value_loss           | 0.13        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.3     |\n",
      "|    ep_rew_mean     | 49.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 892      |\n",
      "|    time_elapsed    | 9053     |\n",
      "|    total_timesteps | 3653632  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.8        |\n",
      "|    ep_rew_mean          | 49.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 893         |\n",
      "|    time_elapsed         | 9063        |\n",
      "|    total_timesteps      | 3657728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017745763 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00598     |\n",
      "|    n_updates            | 8920        |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    value_loss           | 0.0831      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3660000, episode_reward=50.61 +/- 3.92\n",
      "Episode length: 77.20 +/- 9.65\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 77.2        |\n",
      "|    mean_reward          | 50.6        |\n",
      "|    std_reward           | 3.92        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3660000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012922861 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00461    |\n",
      "|    n_updates            | 8930        |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 0.105       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.4     |\n",
      "|    ep_rew_mean     | 49.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 894      |\n",
      "|    time_elapsed    | 9074     |\n",
      "|    total_timesteps | 3661824  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78          |\n",
      "|    ep_rew_mean          | 50.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 895         |\n",
      "|    time_elapsed         | 9083        |\n",
      "|    total_timesteps      | 3665920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012875295 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00157     |\n",
      "|    n_updates            | 8940        |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    value_loss           | 0.106       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3670000, episode_reward=49.60 +/- 4.85\n",
      "Episode length: 76.40 +/- 7.06\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 76.4        |\n",
      "|    mean_reward          | 49.6        |\n",
      "|    std_reward           | 4.85        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3670000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015103163 |\n",
      "|    clip_fraction        | 0.305       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0197     |\n",
      "|    n_updates            | 8950        |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    value_loss           | 0.0982      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.9     |\n",
      "|    ep_rew_mean     | 49.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 896      |\n",
      "|    time_elapsed    | 9094     |\n",
      "|    total_timesteps | 3670016  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.5        |\n",
      "|    ep_rew_mean          | 49          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 897         |\n",
      "|    time_elapsed         | 9104        |\n",
      "|    total_timesteps      | 3674112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016246118 |\n",
      "|    clip_fraction        | 0.313       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0204     |\n",
      "|    n_updates            | 8960        |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    value_loss           | 0.0816      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.1        |\n",
      "|    ep_rew_mean          | 49.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 898         |\n",
      "|    time_elapsed         | 9114        |\n",
      "|    total_timesteps      | 3678208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015652861 |\n",
      "|    clip_fraction        | 0.326       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0105     |\n",
      "|    n_updates            | 8970        |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    value_loss           | 0.0972      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3680000, episode_reward=51.78 +/- 4.19\n",
      "Episode length: 79.90 +/- 7.71\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 79.9        |\n",
      "|    mean_reward          | 51.8        |\n",
      "|    std_reward           | 4.19        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3680000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014055632 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0172     |\n",
      "|    n_updates            | 8980        |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    value_loss           | 0.0888      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.8     |\n",
      "|    ep_rew_mean     | 50       |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 899      |\n",
      "|    time_elapsed    | 9125     |\n",
      "|    total_timesteps | 3682304  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 80.4       |\n",
      "|    ep_rew_mean          | 49.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 403        |\n",
      "|    iterations           | 900        |\n",
      "|    time_elapsed         | 9134       |\n",
      "|    total_timesteps      | 3686400    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01870972 |\n",
      "|    clip_fraction        | 0.298      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.26      |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.0149    |\n",
      "|    n_updates            | 8990       |\n",
      "|    policy_gradient_loss | -0.0141    |\n",
      "|    value_loss           | 0.0825     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3690000, episode_reward=50.58 +/- 4.80\n",
      "Episode length: 83.90 +/- 8.97\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 83.9        |\n",
      "|    mean_reward          | 50.6        |\n",
      "|    std_reward           | 4.8         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3690000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015416108 |\n",
      "|    clip_fraction        | 0.294       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00635    |\n",
      "|    n_updates            | 9000        |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 0.101       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.5     |\n",
      "|    ep_rew_mean     | 49.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 901      |\n",
      "|    time_elapsed    | 9145     |\n",
      "|    total_timesteps | 3690496  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 77.9       |\n",
      "|    ep_rew_mean          | 49.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 403        |\n",
      "|    iterations           | 902        |\n",
      "|    time_elapsed         | 9155       |\n",
      "|    total_timesteps      | 3694592    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01716581 |\n",
      "|    clip_fraction        | 0.31       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.29      |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | 0.0124     |\n",
      "|    n_updates            | 9010       |\n",
      "|    policy_gradient_loss | -0.0164    |\n",
      "|    value_loss           | 0.0931     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78          |\n",
      "|    ep_rew_mean          | 50.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 903         |\n",
      "|    time_elapsed         | 9165        |\n",
      "|    total_timesteps      | 3698688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013626671 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00964     |\n",
      "|    n_updates            | 9020        |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 0.118       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3700000, episode_reward=52.87 +/- 4.30\n",
      "Episode length: 72.60 +/- 6.61\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 72.6        |\n",
      "|    mean_reward          | 52.9        |\n",
      "|    std_reward           | 4.3         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3700000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014695545 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00436    |\n",
      "|    n_updates            | 9030        |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 0.0988      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.8     |\n",
      "|    ep_rew_mean     | 49.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 904      |\n",
      "|    time_elapsed    | 9175     |\n",
      "|    total_timesteps | 3702784  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.5        |\n",
      "|    ep_rew_mean          | 49          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 905         |\n",
      "|    time_elapsed         | 9185        |\n",
      "|    total_timesteps      | 3706880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015363367 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0215     |\n",
      "|    n_updates            | 9040        |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    value_loss           | 0.105       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3710000, episode_reward=50.21 +/- 5.84\n",
      "Episode length: 80.60 +/- 7.98\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 80.6        |\n",
      "|    mean_reward          | 50.2        |\n",
      "|    std_reward           | 5.84        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3710000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013723461 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00216    |\n",
      "|    n_updates            | 9050        |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    value_loss           | 0.125       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.3     |\n",
      "|    ep_rew_mean     | 49.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 906      |\n",
      "|    time_elapsed    | 9196     |\n",
      "|    total_timesteps | 3710976  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77          |\n",
      "|    ep_rew_mean          | 49.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 907         |\n",
      "|    time_elapsed         | 9206        |\n",
      "|    total_timesteps      | 3715072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014226026 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00683    |\n",
      "|    n_updates            | 9060        |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    value_loss           | 0.103       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.3        |\n",
      "|    ep_rew_mean          | 49.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 908         |\n",
      "|    time_elapsed         | 9216        |\n",
      "|    total_timesteps      | 3719168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017952424 |\n",
      "|    clip_fraction        | 0.318       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00617     |\n",
      "|    n_updates            | 9070        |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    value_loss           | 0.0964      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3720000, episode_reward=51.12 +/- 4.22\n",
      "Episode length: 82.00 +/- 9.81\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 82         |\n",
      "|    mean_reward          | 51.1       |\n",
      "|    std_reward           | 4.22       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3720000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01490545 |\n",
      "|    clip_fraction        | 0.281      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.26      |\n",
      "|    explained_variance   | 0.997      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.00015   |\n",
      "|    n_updates            | 9080       |\n",
      "|    policy_gradient_loss | -0.0141    |\n",
      "|    value_loss           | 0.106      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.4     |\n",
      "|    ep_rew_mean     | 50       |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 909      |\n",
      "|    time_elapsed    | 9227     |\n",
      "|    total_timesteps | 3723264  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.6        |\n",
      "|    ep_rew_mean          | 50.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 910         |\n",
      "|    time_elapsed         | 9236        |\n",
      "|    total_timesteps      | 3727360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014393711 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.000783   |\n",
      "|    n_updates            | 9090        |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    value_loss           | 0.0901      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3730000, episode_reward=49.32 +/- 5.05\n",
      "Episode length: 81.80 +/- 11.14\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 81.8        |\n",
      "|    mean_reward          | 49.3        |\n",
      "|    std_reward           | 5.05        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3730000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014558128 |\n",
      "|    clip_fraction        | 0.318       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0104     |\n",
      "|    n_updates            | 9100        |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    value_loss           | 0.0764      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.7     |\n",
      "|    ep_rew_mean     | 50.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 911      |\n",
      "|    time_elapsed    | 9247     |\n",
      "|    total_timesteps | 3731456  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 78.6       |\n",
      "|    ep_rew_mean          | 50         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 403        |\n",
      "|    iterations           | 912        |\n",
      "|    time_elapsed         | 9257       |\n",
      "|    total_timesteps      | 3735552    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01774282 |\n",
      "|    clip_fraction        | 0.331      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.28      |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | 0.0112     |\n",
      "|    n_updates            | 9110       |\n",
      "|    policy_gradient_loss | -0.0141    |\n",
      "|    value_loss           | 0.0999     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.1        |\n",
      "|    ep_rew_mean          | 49.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 913         |\n",
      "|    time_elapsed         | 9267        |\n",
      "|    total_timesteps      | 3739648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014153588 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00168     |\n",
      "|    n_updates            | 9120        |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    value_loss           | 0.109       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3740000, episode_reward=50.25 +/- 5.69\n",
      "Episode length: 82.10 +/- 11.38\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 82.1        |\n",
      "|    mean_reward          | 50.3        |\n",
      "|    std_reward           | 5.69        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3740000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014508659 |\n",
      "|    clip_fraction        | 0.326       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00619    |\n",
      "|    n_updates            | 9130        |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    value_loss           | 0.111       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 76.6     |\n",
      "|    ep_rew_mean     | 49.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 914      |\n",
      "|    time_elapsed    | 9278     |\n",
      "|    total_timesteps | 3743744  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.8        |\n",
      "|    ep_rew_mean          | 49.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 915         |\n",
      "|    time_elapsed         | 9287        |\n",
      "|    total_timesteps      | 3747840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013404557 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0101      |\n",
      "|    n_updates            | 9140        |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    value_loss           | 0.109       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3750000, episode_reward=52.91 +/- 2.98\n",
      "Episode length: 79.50 +/- 8.57\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 79.5        |\n",
      "|    mean_reward          | 52.9        |\n",
      "|    std_reward           | 2.98        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3750000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015706837 |\n",
      "|    clip_fraction        | 0.31        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0167     |\n",
      "|    n_updates            | 9150        |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    value_loss           | 0.103       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.9     |\n",
      "|    ep_rew_mean     | 49.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 916      |\n",
      "|    time_elapsed    | 9298     |\n",
      "|    total_timesteps | 3751936  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 78.7       |\n",
      "|    ep_rew_mean          | 49.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 403        |\n",
      "|    iterations           | 917        |\n",
      "|    time_elapsed         | 9308       |\n",
      "|    total_timesteps      | 3756032    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01434239 |\n",
      "|    clip_fraction        | 0.31       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.29      |\n",
      "|    explained_variance   | 0.997      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.00857   |\n",
      "|    n_updates            | 9160       |\n",
      "|    policy_gradient_loss | -0.0152    |\n",
      "|    value_loss           | 0.13       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3760000, episode_reward=54.00 +/- 4.28\n",
      "Episode length: 79.50 +/- 12.03\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 79.5        |\n",
      "|    mean_reward          | 54          |\n",
      "|    std_reward           | 4.28        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3760000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015236774 |\n",
      "|    clip_fraction        | 0.332       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00474     |\n",
      "|    n_updates            | 9170        |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    value_loss           | 0.121       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.5     |\n",
      "|    ep_rew_mean     | 49.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 918      |\n",
      "|    time_elapsed    | 9319     |\n",
      "|    total_timesteps | 3760128  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78          |\n",
      "|    ep_rew_mean          | 50.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 919         |\n",
      "|    time_elapsed         | 9328        |\n",
      "|    total_timesteps      | 3764224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018998245 |\n",
      "|    clip_fraction        | 0.329       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00385    |\n",
      "|    n_updates            | 9180        |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 0.109       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 79.3       |\n",
      "|    ep_rew_mean          | 50.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 403        |\n",
      "|    iterations           | 920        |\n",
      "|    time_elapsed         | 9338       |\n",
      "|    total_timesteps      | 3768320    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01644978 |\n",
      "|    clip_fraction        | 0.312      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.27      |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.0116    |\n",
      "|    n_updates            | 9190       |\n",
      "|    policy_gradient_loss | -0.0151    |\n",
      "|    value_loss           | 0.0944     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3770000, episode_reward=52.90 +/- 2.35\n",
      "Episode length: 72.10 +/- 9.24\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 72.1        |\n",
      "|    mean_reward          | 52.9        |\n",
      "|    std_reward           | 2.35        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3770000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013647073 |\n",
      "|    clip_fraction        | 0.333       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0107     |\n",
      "|    n_updates            | 9200        |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    value_loss           | 0.0959      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.9     |\n",
      "|    ep_rew_mean     | 50.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 921      |\n",
      "|    time_elapsed    | 9349     |\n",
      "|    total_timesteps | 3772416  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 77.5       |\n",
      "|    ep_rew_mean          | 49.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 403        |\n",
      "|    iterations           | 922        |\n",
      "|    time_elapsed         | 9358       |\n",
      "|    total_timesteps      | 3776512    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01557153 |\n",
      "|    clip_fraction        | 0.308      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.3       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | 0.0146     |\n",
      "|    n_updates            | 9210       |\n",
      "|    policy_gradient_loss | -0.0167    |\n",
      "|    value_loss           | 0.0996     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3780000, episode_reward=52.55 +/- 3.17\n",
      "Episode length: 80.60 +/- 6.07\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 80.6        |\n",
      "|    mean_reward          | 52.6        |\n",
      "|    std_reward           | 3.17        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3780000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014860371 |\n",
      "|    clip_fraction        | 0.32        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0115      |\n",
      "|    n_updates            | 9220        |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    value_loss           | 0.0991      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.5     |\n",
      "|    ep_rew_mean     | 50.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 923      |\n",
      "|    time_elapsed    | 9369     |\n",
      "|    total_timesteps | 3780608  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 77.7         |\n",
      "|    ep_rew_mean          | 50.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 403          |\n",
      "|    iterations           | 924          |\n",
      "|    time_elapsed         | 9379         |\n",
      "|    total_timesteps      | 3784704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0123892985 |\n",
      "|    clip_fraction        | 0.302        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.3         |\n",
      "|    explained_variance   | 0.998        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.00342      |\n",
      "|    n_updates            | 9230         |\n",
      "|    policy_gradient_loss | -0.0143      |\n",
      "|    value_loss           | 0.0912       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 78         |\n",
      "|    ep_rew_mean          | 49.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 403        |\n",
      "|    iterations           | 925        |\n",
      "|    time_elapsed         | 9388       |\n",
      "|    total_timesteps      | 3788800    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01391424 |\n",
      "|    clip_fraction        | 0.316      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.31      |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.00924   |\n",
      "|    n_updates            | 9240       |\n",
      "|    policy_gradient_loss | -0.0162    |\n",
      "|    value_loss           | 0.0952     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3790000, episode_reward=51.14 +/- 3.85\n",
      "Episode length: 80.30 +/- 7.66\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 80.3        |\n",
      "|    mean_reward          | 51.1        |\n",
      "|    std_reward           | 3.85        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3790000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014134385 |\n",
      "|    clip_fraction        | 0.294       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0113     |\n",
      "|    n_updates            | 9250        |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    value_loss           | 0.105       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.2     |\n",
      "|    ep_rew_mean     | 50.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 926      |\n",
      "|    time_elapsed    | 9399     |\n",
      "|    total_timesteps | 3792896  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 79.2         |\n",
      "|    ep_rew_mean          | 50.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 403          |\n",
      "|    iterations           | 927          |\n",
      "|    time_elapsed         | 9409         |\n",
      "|    total_timesteps      | 3796992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0143062435 |\n",
      "|    clip_fraction        | 0.324        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.31        |\n",
      "|    explained_variance   | 0.998        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0188      |\n",
      "|    n_updates            | 9260         |\n",
      "|    policy_gradient_loss | -0.0181      |\n",
      "|    value_loss           | 0.0842       |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3800000, episode_reward=52.14 +/- 2.65\n",
      "Episode length: 78.20 +/- 9.92\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 78.2        |\n",
      "|    mean_reward          | 52.1        |\n",
      "|    std_reward           | 2.65        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3800000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017201511 |\n",
      "|    clip_fraction        | 0.313       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0215     |\n",
      "|    n_updates            | 9270        |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    value_loss           | 0.08        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 80.3     |\n",
      "|    ep_rew_mean     | 50       |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 928      |\n",
      "|    time_elapsed    | 9420     |\n",
      "|    total_timesteps | 3801088  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79          |\n",
      "|    ep_rew_mean          | 49.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 929         |\n",
      "|    time_elapsed         | 9430        |\n",
      "|    total_timesteps      | 3805184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012618365 |\n",
      "|    clip_fraction        | 0.317       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00124    |\n",
      "|    n_updates            | 9280        |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    value_loss           | 0.091       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.4        |\n",
      "|    ep_rew_mean          | 50.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 930         |\n",
      "|    time_elapsed         | 9439        |\n",
      "|    total_timesteps      | 3809280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014063095 |\n",
      "|    clip_fraction        | 0.31        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00507    |\n",
      "|    n_updates            | 9290        |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 0.109       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3810000, episode_reward=51.16 +/- 6.09\n",
      "Episode length: 75.10 +/- 13.32\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 75.1       |\n",
      "|    mean_reward          | 51.2       |\n",
      "|    std_reward           | 6.09       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3810000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01831726 |\n",
      "|    clip_fraction        | 0.316      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.3       |\n",
      "|    explained_variance   | 0.997      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.00988   |\n",
      "|    n_updates            | 9300       |\n",
      "|    policy_gradient_loss | -0.0147    |\n",
      "|    value_loss           | 0.109      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79       |\n",
      "|    ep_rew_mean     | 50.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 931      |\n",
      "|    time_elapsed    | 9450     |\n",
      "|    total_timesteps | 3813376  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.5        |\n",
      "|    ep_rew_mean          | 50.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 932         |\n",
      "|    time_elapsed         | 9460        |\n",
      "|    total_timesteps      | 3817472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015385384 |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00176    |\n",
      "|    n_updates            | 9310        |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    value_loss           | 0.0895      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3820000, episode_reward=53.42 +/- 3.58\n",
      "Episode length: 77.50 +/- 6.86\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 77.5        |\n",
      "|    mean_reward          | 53.4        |\n",
      "|    std_reward           | 3.58        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3820000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012723139 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00767    |\n",
      "|    n_updates            | 9320        |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    value_loss           | 0.108       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.2     |\n",
      "|    ep_rew_mean     | 50.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 933      |\n",
      "|    time_elapsed    | 9471     |\n",
      "|    total_timesteps | 3821568  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.2        |\n",
      "|    ep_rew_mean          | 50.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 934         |\n",
      "|    time_elapsed         | 9480        |\n",
      "|    total_timesteps      | 3825664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015217278 |\n",
      "|    clip_fraction        | 0.307       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00234    |\n",
      "|    n_updates            | 9330        |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    value_loss           | 0.0919      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78.3         |\n",
      "|    ep_rew_mean          | 50.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 403          |\n",
      "|    iterations           | 935          |\n",
      "|    time_elapsed         | 9490         |\n",
      "|    total_timesteps      | 3829760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0151159065 |\n",
      "|    clip_fraction        | 0.291        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.29        |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0148      |\n",
      "|    n_updates            | 9340         |\n",
      "|    policy_gradient_loss | -0.0135      |\n",
      "|    value_loss           | 0.119        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3830000, episode_reward=51.86 +/- 4.79\n",
      "Episode length: 80.50 +/- 8.87\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 80.5        |\n",
      "|    mean_reward          | 51.9        |\n",
      "|    std_reward           | 4.79        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3830000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013965007 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00748    |\n",
      "|    n_updates            | 9350        |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    value_loss           | 0.0952      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78       |\n",
      "|    ep_rew_mean     | 50       |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 936      |\n",
      "|    time_elapsed    | 9501     |\n",
      "|    total_timesteps | 3833856  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.3        |\n",
      "|    ep_rew_mean          | 49.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 937         |\n",
      "|    time_elapsed         | 9511        |\n",
      "|    total_timesteps      | 3837952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014796836 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0198     |\n",
      "|    n_updates            | 9360        |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    value_loss           | 0.103       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3840000, episode_reward=54.55 +/- 2.35\n",
      "Episode length: 72.70 +/- 8.41\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 72.7        |\n",
      "|    mean_reward          | 54.5        |\n",
      "|    std_reward           | 2.35        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3840000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015404943 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00127    |\n",
      "|    n_updates            | 9370        |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    value_loss           | 0.0831      |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 76.9     |\n",
      "|    ep_rew_mean     | 50       |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 938      |\n",
      "|    time_elapsed    | 9521     |\n",
      "|    total_timesteps | 3842048  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.6        |\n",
      "|    ep_rew_mean          | 50.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 939         |\n",
      "|    time_elapsed         | 9531        |\n",
      "|    total_timesteps      | 3846144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014143198 |\n",
      "|    clip_fraction        | 0.303       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00102     |\n",
      "|    n_updates            | 9380        |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    value_loss           | 0.135       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3850000, episode_reward=52.96 +/- 3.99\n",
      "Episode length: 75.30 +/- 10.80\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 75.3        |\n",
      "|    mean_reward          | 53          |\n",
      "|    std_reward           | 3.99        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3850000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017839104 |\n",
      "|    clip_fraction        | 0.3         |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00747     |\n",
      "|    n_updates            | 9390        |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    value_loss           | 0.103       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.8     |\n",
      "|    ep_rew_mean     | 50.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 940      |\n",
      "|    time_elapsed    | 9542     |\n",
      "|    total_timesteps | 3850240  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.9        |\n",
      "|    ep_rew_mean          | 51.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 941         |\n",
      "|    time_elapsed         | 9551        |\n",
      "|    total_timesteps      | 3854336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015649559 |\n",
      "|    clip_fraction        | 0.312       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0157     |\n",
      "|    n_updates            | 9400        |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    value_loss           | 0.0845      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.7        |\n",
      "|    ep_rew_mean          | 52          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 942         |\n",
      "|    time_elapsed         | 9561        |\n",
      "|    total_timesteps      | 3858432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014670389 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.000645   |\n",
      "|    n_updates            | 9410        |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    value_loss           | 0.0882      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3860000, episode_reward=52.52 +/- 5.09\n",
      "Episode length: 77.60 +/- 8.06\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 77.6        |\n",
      "|    mean_reward          | 52.5        |\n",
      "|    std_reward           | 5.09        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3860000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014625058 |\n",
      "|    clip_fraction        | 0.318       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0116     |\n",
      "|    n_updates            | 9420        |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    value_loss           | 0.0685      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.6     |\n",
      "|    ep_rew_mean     | 50.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 943      |\n",
      "|    time_elapsed    | 9572     |\n",
      "|    total_timesteps | 3862528  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.1        |\n",
      "|    ep_rew_mean          | 49.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 944         |\n",
      "|    time_elapsed         | 9581        |\n",
      "|    total_timesteps      | 3866624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014164694 |\n",
      "|    clip_fraction        | 0.289       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00244     |\n",
      "|    n_updates            | 9430        |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    value_loss           | 0.129       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3870000, episode_reward=50.28 +/- 5.91\n",
      "Episode length: 82.20 +/- 11.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 82.2        |\n",
      "|    mean_reward          | 50.3        |\n",
      "|    std_reward           | 5.91        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3870000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015140747 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00693    |\n",
      "|    n_updates            | 9440        |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    value_loss           | 0.0877      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.9     |\n",
      "|    ep_rew_mean     | 49.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 945      |\n",
      "|    time_elapsed    | 9592     |\n",
      "|    total_timesteps | 3870720  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 80          |\n",
      "|    ep_rew_mean          | 49.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 946         |\n",
      "|    time_elapsed         | 9602        |\n",
      "|    total_timesteps      | 3874816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013122793 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00391    |\n",
      "|    n_updates            | 9450        |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    value_loss           | 0.114       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.4        |\n",
      "|    ep_rew_mean          | 50.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 947         |\n",
      "|    time_elapsed         | 9611        |\n",
      "|    total_timesteps      | 3878912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013727263 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00309     |\n",
      "|    n_updates            | 9460        |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    value_loss           | 0.103       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3880000, episode_reward=52.28 +/- 3.21\n",
      "Episode length: 76.60 +/- 9.75\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 76.6        |\n",
      "|    mean_reward          | 52.3        |\n",
      "|    std_reward           | 3.21        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3880000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015255747 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0113     |\n",
      "|    n_updates            | 9470        |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    value_loss           | 0.101       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.1     |\n",
      "|    ep_rew_mean     | 50.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 948      |\n",
      "|    time_elapsed    | 9622     |\n",
      "|    total_timesteps | 3883008  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.8        |\n",
      "|    ep_rew_mean          | 50.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 949         |\n",
      "|    time_elapsed         | 9632        |\n",
      "|    total_timesteps      | 3887104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020158457 |\n",
      "|    clip_fraction        | 0.324       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00339    |\n",
      "|    n_updates            | 9480        |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    value_loss           | 0.0838      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3890000, episode_reward=52.37 +/- 3.27\n",
      "Episode length: 76.90 +/- 10.79\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 76.9       |\n",
      "|    mean_reward          | 52.4       |\n",
      "|    std_reward           | 3.27       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3890000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01512672 |\n",
      "|    clip_fraction        | 0.31       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.26      |\n",
      "|    explained_variance   | 0.997      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -1.32e-05  |\n",
      "|    n_updates            | 9490       |\n",
      "|    policy_gradient_loss | -0.0135    |\n",
      "|    value_loss           | 0.0984     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79       |\n",
      "|    ep_rew_mean     | 50.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 950      |\n",
      "|    time_elapsed    | 9643     |\n",
      "|    total_timesteps | 3891200  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 76.6         |\n",
      "|    ep_rew_mean          | 51.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 403          |\n",
      "|    iterations           | 951          |\n",
      "|    time_elapsed         | 9653         |\n",
      "|    total_timesteps      | 3895296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0121669825 |\n",
      "|    clip_fraction        | 0.286        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.24        |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0186       |\n",
      "|    n_updates            | 9500         |\n",
      "|    policy_gradient_loss | -0.0123      |\n",
      "|    value_loss           | 0.123        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.1        |\n",
      "|    ep_rew_mean          | 51.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 952         |\n",
      "|    time_elapsed         | 9662        |\n",
      "|    total_timesteps      | 3899392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013874884 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00885    |\n",
      "|    n_updates            | 9510        |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    value_loss           | 0.111       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3900000, episode_reward=52.60 +/- 3.37\n",
      "Episode length: 75.60 +/- 10.18\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 75.6        |\n",
      "|    mean_reward          | 52.6        |\n",
      "|    std_reward           | 3.37        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3900000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015530499 |\n",
      "|    clip_fraction        | 0.315       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.000557    |\n",
      "|    n_updates            | 9520        |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    value_loss           | 0.0953      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.5     |\n",
      "|    ep_rew_mean     | 51.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 953      |\n",
      "|    time_elapsed    | 9673     |\n",
      "|    total_timesteps | 3903488  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.6        |\n",
      "|    ep_rew_mean          | 51.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 954         |\n",
      "|    time_elapsed         | 9683        |\n",
      "|    total_timesteps      | 3907584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018272644 |\n",
      "|    clip_fraction        | 0.307       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00529     |\n",
      "|    n_updates            | 9530        |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    value_loss           | 0.0892      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3910000, episode_reward=52.70 +/- 4.36\n",
      "Episode length: 78.70 +/- 8.44\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 78.7        |\n",
      "|    mean_reward          | 52.7        |\n",
      "|    std_reward           | 4.36        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3910000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014840626 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.000188   |\n",
      "|    n_updates            | 9540        |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    value_loss           | 0.0954      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 76.5     |\n",
      "|    ep_rew_mean     | 52.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 955      |\n",
      "|    time_elapsed    | 9694     |\n",
      "|    total_timesteps | 3911680  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.2        |\n",
      "|    ep_rew_mean          | 51.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 956         |\n",
      "|    time_elapsed         | 9703        |\n",
      "|    total_timesteps      | 3915776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017716244 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00721    |\n",
      "|    n_updates            | 9550        |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    value_loss           | 0.107       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77          |\n",
      "|    ep_rew_mean          | 51.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 957         |\n",
      "|    time_elapsed         | 9713        |\n",
      "|    total_timesteps      | 3919872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016931904 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.006      |\n",
      "|    n_updates            | 9560        |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    value_loss           | 0.123       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3920000, episode_reward=51.93 +/- 4.63\n",
      "Episode length: 79.60 +/- 13.17\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 79.6        |\n",
      "|    mean_reward          | 51.9        |\n",
      "|    std_reward           | 4.63        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3920000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014746285 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00773    |\n",
      "|    n_updates            | 9570        |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    value_loss           | 0.103       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.2     |\n",
      "|    ep_rew_mean     | 50.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 958      |\n",
      "|    time_elapsed    | 9724     |\n",
      "|    total_timesteps | 3923968  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.8        |\n",
      "|    ep_rew_mean          | 50.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 959         |\n",
      "|    time_elapsed         | 9733        |\n",
      "|    total_timesteps      | 3928064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014488933 |\n",
      "|    clip_fraction        | 0.336       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.017      |\n",
      "|    n_updates            | 9580        |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    value_loss           | 0.0796      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3930000, episode_reward=56.55 +/- 3.02\n",
      "Episode length: 71.00 +/- 5.88\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 71           |\n",
      "|    mean_reward          | 56.6         |\n",
      "|    std_reward           | 3.02         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3930000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0154377865 |\n",
      "|    clip_fraction        | 0.325        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.28        |\n",
      "|    explained_variance   | 0.998        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0159      |\n",
      "|    n_updates            | 9590         |\n",
      "|    policy_gradient_loss | -0.0164      |\n",
      "|    value_loss           | 0.0796       |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.5     |\n",
      "|    ep_rew_mean     | 50.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 960      |\n",
      "|    time_elapsed    | 9744     |\n",
      "|    total_timesteps | 3932160  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 80.2        |\n",
      "|    ep_rew_mean          | 50.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 961         |\n",
      "|    time_elapsed         | 9754        |\n",
      "|    total_timesteps      | 3936256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017991817 |\n",
      "|    clip_fraction        | 0.313       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0131     |\n",
      "|    n_updates            | 9600        |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    value_loss           | 0.0837      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3940000, episode_reward=52.39 +/- 3.11\n",
      "Episode length: 77.70 +/- 10.03\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 77.7        |\n",
      "|    mean_reward          | 52.4        |\n",
      "|    std_reward           | 3.11        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3940000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014459155 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00824    |\n",
      "|    n_updates            | 9610        |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    value_loss           | 0.083       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.3     |\n",
      "|    ep_rew_mean     | 50.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 962      |\n",
      "|    time_elapsed    | 9765     |\n",
      "|    total_timesteps | 3940352  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.3        |\n",
      "|    ep_rew_mean          | 51.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 963         |\n",
      "|    time_elapsed         | 9774        |\n",
      "|    total_timesteps      | 3944448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012344805 |\n",
      "|    clip_fraction        | 0.287       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0182     |\n",
      "|    n_updates            | 9620        |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    value_loss           | 0.129       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79          |\n",
      "|    ep_rew_mean          | 51.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 964         |\n",
      "|    time_elapsed         | 9784        |\n",
      "|    total_timesteps      | 3948544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017181695 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0127     |\n",
      "|    n_updates            | 9630        |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    value_loss           | 0.0985      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3950000, episode_reward=50.47 +/- 4.31\n",
      "Episode length: 84.10 +/- 8.88\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 84.1        |\n",
      "|    mean_reward          | 50.5        |\n",
      "|    std_reward           | 4.31        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3950000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015640326 |\n",
      "|    clip_fraction        | 0.317       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00611    |\n",
      "|    n_updates            | 9640        |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    value_loss           | 0.127       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.2     |\n",
      "|    ep_rew_mean     | 50.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 965      |\n",
      "|    time_elapsed    | 9795     |\n",
      "|    total_timesteps | 3952640  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.9        |\n",
      "|    ep_rew_mean          | 50.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 966         |\n",
      "|    time_elapsed         | 9805        |\n",
      "|    total_timesteps      | 3956736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015055934 |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00719    |\n",
      "|    n_updates            | 9650        |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    value_loss           | 0.0918      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3960000, episode_reward=51.58 +/- 3.84\n",
      "Episode length: 79.60 +/- 12.97\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 79.6        |\n",
      "|    mean_reward          | 51.6        |\n",
      "|    std_reward           | 3.84        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3960000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012329711 |\n",
      "|    clip_fraction        | 0.309       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0125     |\n",
      "|    n_updates            | 9660        |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    value_loss           | 0.0932      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.2     |\n",
      "|    ep_rew_mean     | 50.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 967      |\n",
      "|    time_elapsed    | 9815     |\n",
      "|    total_timesteps | 3960832  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.9        |\n",
      "|    ep_rew_mean          | 50.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 968         |\n",
      "|    time_elapsed         | 9825        |\n",
      "|    total_timesteps      | 3964928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015799474 |\n",
      "|    clip_fraction        | 0.323       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00431    |\n",
      "|    n_updates            | 9670        |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    value_loss           | 0.0879      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.9        |\n",
      "|    ep_rew_mean          | 50.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 969         |\n",
      "|    time_elapsed         | 9835        |\n",
      "|    total_timesteps      | 3969024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014752089 |\n",
      "|    clip_fraction        | 0.307       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0162     |\n",
      "|    n_updates            | 9680        |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    value_loss           | 0.0836      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3970000, episode_reward=52.50 +/- 2.70\n",
      "Episode length: 76.20 +/- 9.10\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 76.2        |\n",
      "|    mean_reward          | 52.5        |\n",
      "|    std_reward           | 2.7         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3970000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015445298 |\n",
      "|    clip_fraction        | 0.318       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00759    |\n",
      "|    n_updates            | 9690        |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    value_loss           | 0.102       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.5     |\n",
      "|    ep_rew_mean     | 51.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 970      |\n",
      "|    time_elapsed    | 9846     |\n",
      "|    total_timesteps | 3973120  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.5        |\n",
      "|    ep_rew_mean          | 51.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 971         |\n",
      "|    time_elapsed         | 9856        |\n",
      "|    total_timesteps      | 3977216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016112901 |\n",
      "|    clip_fraction        | 0.317       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0114     |\n",
      "|    n_updates            | 9700        |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    value_loss           | 0.0945      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3980000, episode_reward=52.51 +/- 2.78\n",
      "Episode length: 79.60 +/- 10.87\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 79.6        |\n",
      "|    mean_reward          | 52.5        |\n",
      "|    std_reward           | 2.78        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3980000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014505218 |\n",
      "|    clip_fraction        | 0.302       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00224     |\n",
      "|    n_updates            | 9710        |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    value_loss           | 0.0903      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.7     |\n",
      "|    ep_rew_mean     | 51.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 972      |\n",
      "|    time_elapsed    | 9866     |\n",
      "|    total_timesteps | 3981312  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.8        |\n",
      "|    ep_rew_mean          | 51.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 973         |\n",
      "|    time_elapsed         | 9876        |\n",
      "|    total_timesteps      | 3985408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013918096 |\n",
      "|    clip_fraction        | 0.302       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00217    |\n",
      "|    n_updates            | 9720        |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    value_loss           | 0.0967      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 77.5       |\n",
      "|    ep_rew_mean          | 51         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 403        |\n",
      "|    iterations           | 974        |\n",
      "|    time_elapsed         | 9886       |\n",
      "|    total_timesteps      | 3989504    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01635795 |\n",
      "|    clip_fraction        | 0.307      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.3       |\n",
      "|    explained_variance   | 0.997      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.00417   |\n",
      "|    n_updates            | 9730       |\n",
      "|    policy_gradient_loss | -0.0131    |\n",
      "|    value_loss           | 0.11       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3990000, episode_reward=52.40 +/- 5.70\n",
      "Episode length: 78.70 +/- 11.05\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 78.7        |\n",
      "|    mean_reward          | 52.4        |\n",
      "|    std_reward           | 5.7         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3990000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016328095 |\n",
      "|    clip_fraction        | 0.319       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00604     |\n",
      "|    n_updates            | 9740        |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    value_loss           | 0.101       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.2     |\n",
      "|    ep_rew_mean     | 50.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 975      |\n",
      "|    time_elapsed    | 9897     |\n",
      "|    total_timesteps | 3993600  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.8        |\n",
      "|    ep_rew_mean          | 50.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 976         |\n",
      "|    time_elapsed         | 9907        |\n",
      "|    total_timesteps      | 3997696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013217272 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00915     |\n",
      "|    n_updates            | 9750        |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    value_loss           | 0.0915      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4000000, episode_reward=53.06 +/- 4.10\n",
      "Episode length: 78.60 +/- 9.36\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 78.6        |\n",
      "|    mean_reward          | 53.1        |\n",
      "|    std_reward           | 4.1         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4000000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016525324 |\n",
      "|    clip_fraction        | 0.318       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.000434   |\n",
      "|    n_updates            | 9760        |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    value_loss           | 0.0831      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.9     |\n",
      "|    ep_rew_mean     | 50.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 403      |\n",
      "|    iterations      | 977      |\n",
      "|    time_elapsed    | 9918     |\n",
      "|    total_timesteps | 4001792  |\n",
      "---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sb3_contrib.ppo_mask.ppo_mask.MaskablePPO at 0x30c875dd0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.set_logger(new_logger)\n",
    "model.learn(4_000_000, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fed43278-4c08-43e8-b0a2-1c7d99f1a836",
   "metadata": {},
   "outputs": [],
   "source": [
    "env1 = make_env(repeat, SchedulingEnv, test_mode=True)\n",
    "env2 = make_env(repeat, SchedulingEnv, test_mode=False)\n",
    "\n",
    "custom_env = [env1, env2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edc3e45c-7063-4825-8a07-6b6341725294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Repeats\t\t\t:\t[3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Goal reached! Final score\t:\t48.15\n",
      "Total revenue\t\t\t:\t1680.00 - 871.00 = 809.00\n",
      "Sum of Costs\t\t\t:\t871.00\n",
      "Cost Deadline\t\t\t:\t275.00\n",
      "Cost Hole\t\t\t:\t10.00\n",
      "Cost Processing\t\t\t:\t336.00\n",
      "Cost Makespan\t\t\t:\t250.00\n",
      "Finish Time / Target Time\t:\t2500 / 2100\n",
      "Average Tardiness:\t143.33\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Repeats\t\t\t:\t[4, 3, 2, 2, 2, 4, 4, 2, 3, 2]\n",
      "Goal reached! Final score\t:\t44.91\n",
      "Total revenue\t\t\t:\t1590.00 - 876.00 = 714.00\n",
      "Sum of Costs\t\t\t:\t876.00\n",
      "Cost Deadline\t\t\t:\t260.00\n",
      "Cost Hole\t\t\t:\t28.00\n",
      "Cost Processing\t\t\t:\t318.00\n",
      "Cost Makespan\t\t\t:\t270.00\n",
      "Finish Time / Target Time\t:\t2700 / 1987\n",
      "Average Tardiness:\t103.57\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for env in custom_env:\n",
    "    obs, info = env.reset()\n",
    "    while True:\n",
    "        action, _ = model.predict(obs, deterministic = True, action_masks = env.action_masks())\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        if done:\n",
    "            # print(\"Goal reached!\", \"final score=\", reward)\n",
    "            # print('job_deadline', info['job_deadline'])\n",
    "            # print('job_time_exceeded', info['job_time_exceeded'])\n",
    "            # print('current_repeats', info['current_repeats'])\n",
    "            # print(env.target_time)\n",
    "            info[\"reward\"] = reward\n",
    "            info[\"env\"] = env\n",
    "            info[\"profit_ratio\"] = env.profit_per_time\n",
    "            env.print_result(info, detail_mode = False)\n",
    "            env.render()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49c7ff0d-5b39-414a-872b-ddacaeef12a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(log_path + \"/final_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0305f6f2-b736-4c75-a9ce-025a0fe7b6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 80.3        |\n",
      "|    ep_rew_mean          | 49.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 511         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018289924 |\n",
      "|    clip_fraction        | 0.328       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.013      |\n",
      "|    n_updates            | 9770        |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    value_loss           | 0.0823      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.9        |\n",
      "|    ep_rew_mean          | 49.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 462         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015572505 |\n",
      "|    clip_fraction        | 0.331       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00776    |\n",
      "|    n_updates            | 9780        |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    value_loss           | 0.0763      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=8208, episode_reward=53.55 +/- 2.77\n",
      "Episode length: 80.10 +/- 11.21\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 80.1        |\n",
      "|    mean_reward          | 53.5        |\n",
      "|    std_reward           | 2.77        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 8208        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011624675 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00766    |\n",
      "|    n_updates            | 9790        |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    value_loss           | 0.106       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 76.5     |\n",
      "|    ep_rew_mean     | 50.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 418      |\n",
      "|    iterations      | 3        |\n",
      "|    time_elapsed    | 29       |\n",
      "|    total_timesteps | 12288    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.5        |\n",
      "|    ep_rew_mean          | 50.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 410         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015260387 |\n",
      "|    clip_fraction        | 0.303       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00988    |\n",
      "|    n_updates            | 9800        |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    value_loss           | 0.1         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=18208, episode_reward=47.16 +/- 6.01\n",
      "Episode length: 83.70 +/- 12.64\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 83.7        |\n",
      "|    mean_reward          | 47.2        |\n",
      "|    std_reward           | 6.01        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 18208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013248407 |\n",
      "|    clip_fraction        | 0.326       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0176     |\n",
      "|    n_updates            | 9810        |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    value_loss           | 0.0688      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 80       |\n",
      "|    ep_rew_mean     | 50.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 397      |\n",
      "|    iterations      | 5        |\n",
      "|    time_elapsed    | 51       |\n",
      "|    total_timesteps | 20480    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.6        |\n",
      "|    ep_rew_mean          | 50.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 399         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 61          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013068494 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00134    |\n",
      "|    n_updates            | 9820        |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    value_loss           | 0.0936      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=28208, episode_reward=53.07 +/- 3.92\n",
      "Episode length: 79.90 +/- 7.87\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 79.9       |\n",
      "|    mean_reward          | 53.1       |\n",
      "|    std_reward           | 3.92       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 28208      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01885204 |\n",
      "|    clip_fraction        | 0.309      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.27      |\n",
      "|    explained_variance   | 0.997      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | 0.00106    |\n",
      "|    n_updates            | 9830       |\n",
      "|    policy_gradient_loss | -0.0145    |\n",
      "|    value_loss           | 0.114      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.8     |\n",
      "|    ep_rew_mean     | 51       |\n",
      "| time/              |          |\n",
      "|    fps             | 393      |\n",
      "|    iterations      | 7        |\n",
      "|    time_elapsed    | 72       |\n",
      "|    total_timesteps | 28672    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.6        |\n",
      "|    ep_rew_mean          | 51.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 394         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 82          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016643494 |\n",
      "|    clip_fraction        | 0.331       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0119     |\n",
      "|    n_updates            | 9840        |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    value_loss           | 0.0869      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.5        |\n",
      "|    ep_rew_mean          | 50.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 396         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 92          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014676716 |\n",
      "|    clip_fraction        | 0.331       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00417    |\n",
      "|    n_updates            | 9850        |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    value_loss           | 0.0831      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=38208, episode_reward=52.24 +/- 3.89\n",
      "Episode length: 78.90 +/- 7.88\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 78.9        |\n",
      "|    mean_reward          | 52.2        |\n",
      "|    std_reward           | 3.89        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 38208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014362138 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00209    |\n",
      "|    n_updates            | 9860        |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    value_loss           | 0.0971      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.4     |\n",
      "|    ep_rew_mean     | 50.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 393      |\n",
      "|    iterations      | 10       |\n",
      "|    time_elapsed    | 104      |\n",
      "|    total_timesteps | 40960    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.3        |\n",
      "|    ep_rew_mean          | 50.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 395         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 114         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014216541 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00451    |\n",
      "|    n_updates            | 9870        |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    value_loss           | 0.0917      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=48208, episode_reward=54.16 +/- 3.14\n",
      "Episode length: 73.50 +/- 11.76\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 73.5        |\n",
      "|    mean_reward          | 54.2        |\n",
      "|    std_reward           | 3.14        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 48208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015855655 |\n",
      "|    clip_fraction        | 0.334       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00326    |\n",
      "|    n_updates            | 9880        |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    value_loss           | 0.105       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.3     |\n",
      "|    ep_rew_mean     | 50.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 393      |\n",
      "|    iterations      | 12       |\n",
      "|    time_elapsed    | 124      |\n",
      "|    total_timesteps | 49152    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.9        |\n",
      "|    ep_rew_mean          | 50          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 396         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 134         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017827755 |\n",
      "|    clip_fraction        | 0.337       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0169     |\n",
      "|    n_updates            | 9890        |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    value_loss           | 0.08        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.4        |\n",
      "|    ep_rew_mean          | 50.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 399         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 143         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014892723 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0086      |\n",
      "|    n_updates            | 9900        |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 0.0907      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=58208, episode_reward=53.09 +/- 3.54\n",
      "Episode length: 73.20 +/- 12.65\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 73.2       |\n",
      "|    mean_reward          | 53.1       |\n",
      "|    std_reward           | 3.54       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 58208      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01643926 |\n",
      "|    clip_fraction        | 0.304      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.26      |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.0131    |\n",
      "|    n_updates            | 9910       |\n",
      "|    policy_gradient_loss | -0.0169    |\n",
      "|    value_loss           | 0.102      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78       |\n",
      "|    ep_rew_mean     | 50.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 397      |\n",
      "|    iterations      | 15       |\n",
      "|    time_elapsed    | 154      |\n",
      "|    total_timesteps | 61440    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.7        |\n",
      "|    ep_rew_mean          | 50.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 398         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 164         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012322599 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.014      |\n",
      "|    n_updates            | 9920        |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    value_loss           | 0.105       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=68208, episode_reward=53.06 +/- 3.03\n",
      "Episode length: 76.00 +/- 7.14\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 76          |\n",
      "|    mean_reward          | 53.1        |\n",
      "|    std_reward           | 3.03        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 68208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016149897 |\n",
      "|    clip_fraction        | 0.32        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0159     |\n",
      "|    n_updates            | 9930        |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    value_loss           | 0.101       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 76.8     |\n",
      "|    ep_rew_mean     | 51.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 395      |\n",
      "|    iterations      | 17       |\n",
      "|    time_elapsed    | 176      |\n",
      "|    total_timesteps | 69632    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.2        |\n",
      "|    ep_rew_mean          | 51.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 396         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 185         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018635035 |\n",
      "|    clip_fraction        | 0.325       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.011      |\n",
      "|    n_updates            | 9940        |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    value_loss           | 0.114       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.9        |\n",
      "|    ep_rew_mean          | 50.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 396         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 196         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017621629 |\n",
      "|    clip_fraction        | 0.341       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0155     |\n",
      "|    n_updates            | 9950        |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    value_loss           | 0.0915      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=78208, episode_reward=54.35 +/- 4.20\n",
      "Episode length: 75.20 +/- 14.81\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 75.2        |\n",
      "|    mean_reward          | 54.4        |\n",
      "|    std_reward           | 4.2         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 78208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013531677 |\n",
      "|    clip_fraction        | 0.314       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00471    |\n",
      "|    n_updates            | 9960        |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 0.0894      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.6     |\n",
      "|    ep_rew_mean     | 50.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 396      |\n",
      "|    iterations      | 20       |\n",
      "|    time_elapsed    | 206      |\n",
      "|    total_timesteps | 81920    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78          |\n",
      "|    ep_rew_mean          | 50.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 397         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 216         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014138254 |\n",
      "|    clip_fraction        | 0.318       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0173     |\n",
      "|    n_updates            | 9970        |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    value_loss           | 0.0812      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=88208, episode_reward=53.93 +/- 2.88\n",
      "Episode length: 79.00 +/- 6.42\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 79          |\n",
      "|    mean_reward          | 53.9        |\n",
      "|    std_reward           | 2.88        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 88208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014402293 |\n",
      "|    clip_fraction        | 0.305       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0117     |\n",
      "|    n_updates            | 9980        |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    value_loss           | 0.0817      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 80.5     |\n",
      "|    ep_rew_mean     | 50.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 396      |\n",
      "|    iterations      | 22       |\n",
      "|    time_elapsed    | 227      |\n",
      "|    total_timesteps | 90112    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 82.4        |\n",
      "|    ep_rew_mean          | 49.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 397         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 236         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014233973 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0114     |\n",
      "|    n_updates            | 9990        |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    value_loss           | 0.0966      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=98208, episode_reward=53.90 +/- 2.73\n",
      "Episode length: 75.50 +/- 10.32\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 75.5        |\n",
      "|    mean_reward          | 53.9        |\n",
      "|    std_reward           | 2.73        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 98208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013691768 |\n",
      "|    clip_fraction        | 0.301       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.01       |\n",
      "|    n_updates            | 10000       |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    value_loss           | 0.0872      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 80       |\n",
      "|    ep_rew_mean     | 50.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 397      |\n",
      "|    iterations      | 24       |\n",
      "|    time_elapsed    | 247      |\n",
      "|    total_timesteps | 98304    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.4        |\n",
      "|    ep_rew_mean          | 51.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 398         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 256         |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019187208 |\n",
      "|    clip_fraction        | 0.32        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.000405    |\n",
      "|    n_updates            | 10010       |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    value_loss           | 0.087       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 77.2      |\n",
      "|    ep_rew_mean          | 51.8      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 400       |\n",
      "|    iterations           | 26        |\n",
      "|    time_elapsed         | 266       |\n",
      "|    total_timesteps      | 106496    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0143339 |\n",
      "|    clip_fraction        | 0.305     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -1.25     |\n",
      "|    explained_variance   | 0.998     |\n",
      "|    learning_rate        | 5e-05     |\n",
      "|    loss                 | -0.0136   |\n",
      "|    n_updates            | 10020     |\n",
      "|    policy_gradient_loss | -0.0136   |\n",
      "|    value_loss           | 0.0997    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=108208, episode_reward=52.24 +/- 4.49\n",
      "Episode length: 79.60 +/- 10.79\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 79.6        |\n",
      "|    mean_reward          | 52.2        |\n",
      "|    std_reward           | 4.49        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 108208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013139948 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00852    |\n",
      "|    n_updates            | 10030       |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    value_loss           | 0.103       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.4     |\n",
      "|    ep_rew_mean     | 51.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 399      |\n",
      "|    iterations      | 27       |\n",
      "|    time_elapsed    | 277      |\n",
      "|    total_timesteps | 110592   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.5        |\n",
      "|    ep_rew_mean          | 50.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 399         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 286         |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012606731 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00655    |\n",
      "|    n_updates            | 10040       |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    value_loss           | 0.0961      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=118208, episode_reward=53.52 +/- 2.06\n",
      "Episode length: 77.70 +/- 10.37\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 77.7        |\n",
      "|    mean_reward          | 53.5        |\n",
      "|    std_reward           | 2.06        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 118208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012216992 |\n",
      "|    clip_fraction        | 0.294       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0166     |\n",
      "|    n_updates            | 10050       |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    value_loss           | 0.0964      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.2     |\n",
      "|    ep_rew_mean     | 50.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 399      |\n",
      "|    iterations      | 29       |\n",
      "|    time_elapsed    | 297      |\n",
      "|    total_timesteps | 118784   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.9        |\n",
      "|    ep_rew_mean          | 51.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 399         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 307         |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013232252 |\n",
      "|    clip_fraction        | 0.317       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.011      |\n",
      "|    n_updates            | 10060       |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    value_loss           | 0.0887      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.2        |\n",
      "|    ep_rew_mean          | 51.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 400         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 316         |\n",
      "|    total_timesteps      | 126976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014672549 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00481    |\n",
      "|    n_updates            | 10070       |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    value_loss           | 0.108       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=128208, episode_reward=53.40 +/- 4.20\n",
      "Episode length: 79.30 +/- 9.22\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 79.3       |\n",
      "|    mean_reward          | 53.4       |\n",
      "|    std_reward           | 4.2        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 128208     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01598489 |\n",
      "|    clip_fraction        | 0.338      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.25      |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.00943   |\n",
      "|    n_updates            | 10080      |\n",
      "|    policy_gradient_loss | -0.0137    |\n",
      "|    value_loss           | 0.0858     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.1     |\n",
      "|    ep_rew_mean     | 51.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 400      |\n",
      "|    iterations      | 32       |\n",
      "|    time_elapsed    | 327      |\n",
      "|    total_timesteps | 131072   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.3        |\n",
      "|    ep_rew_mean          | 51.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 401         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 337         |\n",
      "|    total_timesteps      | 135168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015472514 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00639    |\n",
      "|    n_updates            | 10090       |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    value_loss           | 0.0814      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=138208, episode_reward=52.51 +/- 3.05\n",
      "Episode length: 76.60 +/- 9.41\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 76.6        |\n",
      "|    mean_reward          | 52.5        |\n",
      "|    std_reward           | 3.05        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 138208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018132966 |\n",
      "|    clip_fraction        | 0.323       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00751     |\n",
      "|    n_updates            | 10100       |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 0.097       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.2     |\n",
      "|    ep_rew_mean     | 51.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 400      |\n",
      "|    iterations      | 34       |\n",
      "|    time_elapsed    | 347      |\n",
      "|    total_timesteps | 139264   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.8        |\n",
      "|    ep_rew_mean          | 51          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 401         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 357         |\n",
      "|    total_timesteps      | 143360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018779602 |\n",
      "|    clip_fraction        | 0.333       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0132     |\n",
      "|    n_updates            | 10110       |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    value_loss           | 0.0761      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.6        |\n",
      "|    ep_rew_mean          | 50.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 401         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 367         |\n",
      "|    total_timesteps      | 147456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015762383 |\n",
      "|    clip_fraction        | 0.289       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0134     |\n",
      "|    n_updates            | 10120       |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    value_loss           | 0.092       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=148208, episode_reward=50.79 +/- 5.80\n",
      "Episode length: 82.30 +/- 10.06\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 82.3        |\n",
      "|    mean_reward          | 50.8        |\n",
      "|    std_reward           | 5.8         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 148208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016920116 |\n",
      "|    clip_fraction        | 0.326       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00901    |\n",
      "|    n_updates            | 10130       |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    value_loss           | 0.0868      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.3     |\n",
      "|    ep_rew_mean     | 51.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 401      |\n",
      "|    iterations      | 37       |\n",
      "|    time_elapsed    | 377      |\n",
      "|    total_timesteps | 151552   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78          |\n",
      "|    ep_rew_mean          | 51.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 401         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 387         |\n",
      "|    total_timesteps      | 155648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015134243 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00986    |\n",
      "|    n_updates            | 10140       |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    value_loss           | 0.102       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=158208, episode_reward=55.01 +/- 2.22\n",
      "Episode length: 77.20 +/- 8.57\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 77.2        |\n",
      "|    mean_reward          | 55          |\n",
      "|    std_reward           | 2.22        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 158208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015928533 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00399    |\n",
      "|    n_updates            | 10150       |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    value_loss           | 0.12        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.3     |\n",
      "|    ep_rew_mean     | 51.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 401      |\n",
      "|    iterations      | 39       |\n",
      "|    time_elapsed    | 398      |\n",
      "|    total_timesteps | 159744   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.1        |\n",
      "|    ep_rew_mean          | 51.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 401         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 407         |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012614521 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00958     |\n",
      "|    n_updates            | 10160       |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    value_loss           | 0.151       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.7        |\n",
      "|    ep_rew_mean          | 51.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 402         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 417         |\n",
      "|    total_timesteps      | 167936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012731422 |\n",
      "|    clip_fraction        | 0.309       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0158     |\n",
      "|    n_updates            | 10170       |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    value_loss           | 0.101       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=168208, episode_reward=53.08 +/- 4.06\n",
      "Episode length: 77.80 +/- 11.15\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 77.8        |\n",
      "|    mean_reward          | 53.1        |\n",
      "|    std_reward           | 4.06        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 168208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017853618 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00394    |\n",
      "|    n_updates            | 10180       |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    value_loss           | 0.126       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.3     |\n",
      "|    ep_rew_mean     | 51.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 401      |\n",
      "|    iterations      | 42       |\n",
      "|    time_elapsed    | 428      |\n",
      "|    total_timesteps | 172032   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.7        |\n",
      "|    ep_rew_mean          | 50.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 402         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 437         |\n",
      "|    total_timesteps      | 176128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015695645 |\n",
      "|    clip_fraction        | 0.301       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00541     |\n",
      "|    n_updates            | 10190       |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    value_loss           | 0.0942      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=178208, episode_reward=53.26 +/- 3.95\n",
      "Episode length: 77.20 +/- 7.47\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 77.2        |\n",
      "|    mean_reward          | 53.3        |\n",
      "|    std_reward           | 3.95        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 178208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013727022 |\n",
      "|    clip_fraction        | 0.307       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00116    |\n",
      "|    n_updates            | 10200       |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    value_loss           | 0.107       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 76.5     |\n",
      "|    ep_rew_mean     | 50.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 402      |\n",
      "|    iterations      | 44       |\n",
      "|    time_elapsed    | 448      |\n",
      "|    total_timesteps | 180224   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 77.3      |\n",
      "|    ep_rew_mean          | 50.3      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 402       |\n",
      "|    iterations           | 45        |\n",
      "|    time_elapsed         | 457       |\n",
      "|    total_timesteps      | 184320    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0147695 |\n",
      "|    clip_fraction        | 0.303     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -1.24     |\n",
      "|    explained_variance   | 0.998     |\n",
      "|    learning_rate        | 5e-05     |\n",
      "|    loss                 | -0.00583  |\n",
      "|    n_updates            | 10210     |\n",
      "|    policy_gradient_loss | -0.0144   |\n",
      "|    value_loss           | 0.106     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=188208, episode_reward=52.10 +/- 5.33\n",
      "Episode length: 82.30 +/- 10.84\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 82.3       |\n",
      "|    mean_reward          | 52.1       |\n",
      "|    std_reward           | 5.33       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 188208     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01935573 |\n",
      "|    clip_fraction        | 0.319      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.22      |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | 0.00997    |\n",
      "|    n_updates            | 10220      |\n",
      "|    policy_gradient_loss | -0.0147    |\n",
      "|    value_loss           | 0.0959     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.4     |\n",
      "|    ep_rew_mean     | 50.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 402      |\n",
      "|    iterations      | 46       |\n",
      "|    time_elapsed    | 468      |\n",
      "|    total_timesteps | 188416   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.7        |\n",
      "|    ep_rew_mean          | 51.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 402         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 478         |\n",
      "|    total_timesteps      | 192512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015380904 |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0154     |\n",
      "|    n_updates            | 10230       |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    value_loss           | 0.0905      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.4        |\n",
      "|    ep_rew_mean          | 51.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 402         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 487         |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015480249 |\n",
      "|    clip_fraction        | 0.302       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0101     |\n",
      "|    n_updates            | 10240       |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    value_loss           | 0.0854      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=198208, episode_reward=53.24 +/- 2.33\n",
      "Episode length: 76.90 +/- 7.52\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 76.9        |\n",
      "|    mean_reward          | 53.2        |\n",
      "|    std_reward           | 2.33        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 198208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015678257 |\n",
      "|    clip_fraction        | 0.287       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0108     |\n",
      "|    n_updates            | 10250       |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 0.0827      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.2     |\n",
      "|    ep_rew_mean     | 50.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 402      |\n",
      "|    iterations      | 49       |\n",
      "|    time_elapsed    | 498      |\n",
      "|    total_timesteps | 200704   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 78.7       |\n",
      "|    ep_rew_mean          | 50.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 402        |\n",
      "|    iterations           | 50         |\n",
      "|    time_elapsed         | 508        |\n",
      "|    total_timesteps      | 204800     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01655534 |\n",
      "|    clip_fraction        | 0.322      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.2       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.0145    |\n",
      "|    n_updates            | 10260      |\n",
      "|    policy_gradient_loss | -0.0134    |\n",
      "|    value_loss           | 0.0812     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=208208, episode_reward=53.82 +/- 3.54\n",
      "Episode length: 70.90 +/- 8.51\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 70.9        |\n",
      "|    mean_reward          | 53.8        |\n",
      "|    std_reward           | 3.54        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 208208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018801153 |\n",
      "|    clip_fraction        | 0.324       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00561     |\n",
      "|    n_updates            | 10270       |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    value_loss           | 0.079       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.2     |\n",
      "|    ep_rew_mean     | 51.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 402      |\n",
      "|    iterations      | 51       |\n",
      "|    time_elapsed    | 518      |\n",
      "|    total_timesteps | 208896   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78          |\n",
      "|    ep_rew_mean          | 51.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 402         |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 528         |\n",
      "|    total_timesteps      | 212992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015360267 |\n",
      "|    clip_fraction        | 0.317       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0174     |\n",
      "|    n_updates            | 10280       |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    value_loss           | 0.0787      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.2        |\n",
      "|    ep_rew_mean          | 51          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 538         |\n",
      "|    total_timesteps      | 217088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016008422 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00206    |\n",
      "|    n_updates            | 10290       |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 0.0723      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=218208, episode_reward=53.82 +/- 2.83\n",
      "Episode length: 74.60 +/- 5.80\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 74.6        |\n",
      "|    mean_reward          | 53.8        |\n",
      "|    std_reward           | 2.83        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 218208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016190488 |\n",
      "|    clip_fraction        | 0.289       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00956    |\n",
      "|    n_updates            | 10300       |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    value_loss           | 0.0883      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 76.9     |\n",
      "|    ep_rew_mean     | 51.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 402      |\n",
      "|    iterations      | 54       |\n",
      "|    time_elapsed    | 549      |\n",
      "|    total_timesteps | 221184   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.1        |\n",
      "|    ep_rew_mean          | 51.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 558         |\n",
      "|    total_timesteps      | 225280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016745081 |\n",
      "|    clip_fraction        | 0.323       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0102     |\n",
      "|    n_updates            | 10310       |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    value_loss           | 0.0803      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=228208, episode_reward=53.42 +/- 3.75\n",
      "Episode length: 79.00 +/- 8.04\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 79          |\n",
      "|    mean_reward          | 53.4        |\n",
      "|    std_reward           | 3.75        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 228208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013307843 |\n",
      "|    clip_fraction        | 0.307       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0106     |\n",
      "|    n_updates            | 10320       |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    value_loss           | 0.0796      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 76.5     |\n",
      "|    ep_rew_mean     | 51.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 402      |\n",
      "|    iterations      | 56       |\n",
      "|    time_elapsed    | 569      |\n",
      "|    total_timesteps | 229376   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.5        |\n",
      "|    ep_rew_mean          | 51.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 402         |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 579         |\n",
      "|    total_timesteps      | 233472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017281521 |\n",
      "|    clip_fraction        | 0.293       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00498    |\n",
      "|    n_updates            | 10330       |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    value_loss           | 0.0879      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.8        |\n",
      "|    ep_rew_mean          | 52.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 589         |\n",
      "|    total_timesteps      | 237568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015192656 |\n",
      "|    clip_fraction        | 0.309       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00817    |\n",
      "|    n_updates            | 10340       |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    value_loss           | 0.0844      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=238208, episode_reward=53.33 +/- 4.11\n",
      "Episode length: 77.70 +/- 11.29\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 77.7       |\n",
      "|    mean_reward          | 53.3       |\n",
      "|    std_reward           | 4.11       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 238208     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01513443 |\n",
      "|    clip_fraction        | 0.297      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.18      |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.00995   |\n",
      "|    n_updates            | 10350      |\n",
      "|    policy_gradient_loss | -0.0138    |\n",
      "|    value_loss           | 0.0854     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.7     |\n",
      "|    ep_rew_mean     | 51.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 402      |\n",
      "|    iterations      | 59       |\n",
      "|    time_elapsed    | 599      |\n",
      "|    total_timesteps | 241664   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.9        |\n",
      "|    ep_rew_mean          | 51.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 609         |\n",
      "|    total_timesteps      | 245760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014813564 |\n",
      "|    clip_fraction        | 0.305       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0213     |\n",
      "|    n_updates            | 10360       |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    value_loss           | 0.0838      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=248208, episode_reward=54.66 +/- 3.50\n",
      "Episode length: 76.40 +/- 11.95\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 76.4        |\n",
      "|    mean_reward          | 54.7        |\n",
      "|    std_reward           | 3.5         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 248208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018254206 |\n",
      "|    clip_fraction        | 0.314       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0138     |\n",
      "|    n_updates            | 10370       |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    value_loss           | 0.0722      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.5     |\n",
      "|    ep_rew_mean     | 51.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 402      |\n",
      "|    iterations      | 61       |\n",
      "|    time_elapsed    | 620      |\n",
      "|    total_timesteps | 249856   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78.8         |\n",
      "|    ep_rew_mean          | 52.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 402          |\n",
      "|    iterations           | 62           |\n",
      "|    time_elapsed         | 630          |\n",
      "|    total_timesteps      | 253952       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0138751045 |\n",
      "|    clip_fraction        | 0.304        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.17        |\n",
      "|    explained_variance   | 0.998        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0114      |\n",
      "|    n_updates            | 10380        |\n",
      "|    policy_gradient_loss | -0.0167      |\n",
      "|    value_loss           | 0.0724       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78.2         |\n",
      "|    ep_rew_mean          | 52           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 403          |\n",
      "|    iterations           | 63           |\n",
      "|    time_elapsed         | 640          |\n",
      "|    total_timesteps      | 258048       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0126114935 |\n",
      "|    clip_fraction        | 0.291        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.16        |\n",
      "|    explained_variance   | 0.999        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.00123      |\n",
      "|    n_updates            | 10390        |\n",
      "|    policy_gradient_loss | -0.0139      |\n",
      "|    value_loss           | 0.0762       |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=258208, episode_reward=52.77 +/- 2.82\n",
      "Episode length: 76.30 +/- 10.92\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 76.3        |\n",
      "|    mean_reward          | 52.8        |\n",
      "|    std_reward           | 2.82        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 258208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016935922 |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.17       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.015      |\n",
      "|    n_updates            | 10400       |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    value_loss           | 0.0849      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.1     |\n",
      "|    ep_rew_mean     | 50.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 402      |\n",
      "|    iterations      | 64       |\n",
      "|    time_elapsed    | 651      |\n",
      "|    total_timesteps | 262144   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.4        |\n",
      "|    ep_rew_mean          | 51.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 660         |\n",
      "|    total_timesteps      | 266240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016408976 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00417    |\n",
      "|    n_updates            | 10410       |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 0.0909      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=268208, episode_reward=54.97 +/- 3.08\n",
      "Episode length: 76.10 +/- 8.94\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 76.1        |\n",
      "|    mean_reward          | 55          |\n",
      "|    std_reward           | 3.08        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 268208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017981343 |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0108     |\n",
      "|    n_updates            | 10420       |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    value_loss           | 0.0993      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.3     |\n",
      "|    ep_rew_mean     | 51.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 402      |\n",
      "|    iterations      | 66       |\n",
      "|    time_elapsed    | 671      |\n",
      "|    total_timesteps | 270336   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.8        |\n",
      "|    ep_rew_mean          | 52          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 402         |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 681         |\n",
      "|    total_timesteps      | 274432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013839603 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.16       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.000781   |\n",
      "|    n_updates            | 10430       |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    value_loss           | 0.0983      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=278208, episode_reward=54.01 +/- 2.52\n",
      "Episode length: 80.10 +/- 10.74\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 80.1        |\n",
      "|    mean_reward          | 54          |\n",
      "|    std_reward           | 2.52        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 278208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015371126 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0369      |\n",
      "|    n_updates            | 10440       |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    value_loss           | 0.0955      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.2     |\n",
      "|    ep_rew_mean     | 52.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 402      |\n",
      "|    iterations      | 68       |\n",
      "|    time_elapsed    | 692      |\n",
      "|    total_timesteps | 278528   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.4        |\n",
      "|    ep_rew_mean          | 52.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 402         |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 701         |\n",
      "|    total_timesteps      | 282624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016663514 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.17       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00419    |\n",
      "|    n_updates            | 10450       |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    value_loss           | 0.0791      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.9        |\n",
      "|    ep_rew_mean          | 52.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 402         |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 711         |\n",
      "|    total_timesteps      | 286720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015359012 |\n",
      "|    clip_fraction        | 0.317       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0134     |\n",
      "|    n_updates            | 10460       |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    value_loss           | 0.0752      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=288208, episode_reward=55.10 +/- 2.50\n",
      "Episode length: 80.30 +/- 7.01\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 80.3        |\n",
      "|    mean_reward          | 55.1        |\n",
      "|    std_reward           | 2.5         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 288208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011684725 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.16       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.012      |\n",
      "|    n_updates            | 10470       |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    value_loss           | 0.0891      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 76.2     |\n",
      "|    ep_rew_mean     | 51.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 402      |\n",
      "|    iterations      | 71       |\n",
      "|    time_elapsed    | 722      |\n",
      "|    total_timesteps | 290816   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.7        |\n",
      "|    ep_rew_mean          | 51.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 402         |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 731         |\n",
      "|    total_timesteps      | 294912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015282572 |\n",
      "|    clip_fraction        | 0.307       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0124     |\n",
      "|    n_updates            | 10480       |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 0.0876      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=298208, episode_reward=51.20 +/- 4.58\n",
      "Episode length: 83.90 +/- 11.85\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 83.9        |\n",
      "|    mean_reward          | 51.2        |\n",
      "|    std_reward           | 4.58        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 298208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016135538 |\n",
      "|    clip_fraction        | 0.303       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0153     |\n",
      "|    n_updates            | 10490       |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    value_loss           | 0.086       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.3     |\n",
      "|    ep_rew_mean     | 51.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 402      |\n",
      "|    iterations      | 73       |\n",
      "|    time_elapsed    | 743      |\n",
      "|    total_timesteps | 299008   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78          |\n",
      "|    ep_rew_mean          | 51.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 402         |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 752         |\n",
      "|    total_timesteps      | 303104      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015735066 |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0071     |\n",
      "|    n_updates            | 10500       |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 0.0854      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.5        |\n",
      "|    ep_rew_mean          | 51.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 402         |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 762         |\n",
      "|    total_timesteps      | 307200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016621029 |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.16       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00389    |\n",
      "|    n_updates            | 10510       |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    value_loss           | 0.0751      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=308208, episode_reward=55.02 +/- 2.97\n",
      "Episode length: 75.60 +/- 12.17\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 75.6        |\n",
      "|    mean_reward          | 55          |\n",
      "|    std_reward           | 2.97        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 308208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012955315 |\n",
      "|    clip_fraction        | 0.284       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00702     |\n",
      "|    n_updates            | 10520       |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    value_loss           | 0.0885      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.2     |\n",
      "|    ep_rew_mean     | 52.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 402      |\n",
      "|    iterations      | 76       |\n",
      "|    time_elapsed    | 773      |\n",
      "|    total_timesteps | 311296   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.2        |\n",
      "|    ep_rew_mean          | 51.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 402         |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 782         |\n",
      "|    total_timesteps      | 315392      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016121987 |\n",
      "|    clip_fraction        | 0.303       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.12       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00471     |\n",
      "|    n_updates            | 10530       |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    value_loss           | 0.0922      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=318208, episode_reward=54.85 +/- 2.74\n",
      "Episode length: 75.50 +/- 4.06\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 75.5        |\n",
      "|    mean_reward          | 54.9        |\n",
      "|    std_reward           | 2.74        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 318208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015589966 |\n",
      "|    clip_fraction        | 0.294       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0075     |\n",
      "|    n_updates            | 10540       |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 0.0844      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.8     |\n",
      "|    ep_rew_mean     | 51.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 402      |\n",
      "|    iterations      | 78       |\n",
      "|    time_elapsed    | 793      |\n",
      "|    total_timesteps | 319488   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 79.1         |\n",
      "|    ep_rew_mean          | 51.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 402          |\n",
      "|    iterations           | 79           |\n",
      "|    time_elapsed         | 803          |\n",
      "|    total_timesteps      | 323584       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0136600435 |\n",
      "|    clip_fraction        | 0.297        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.17        |\n",
      "|    explained_variance   | 0.998        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0136      |\n",
      "|    n_updates            | 10550        |\n",
      "|    policy_gradient_loss | -0.015       |\n",
      "|    value_loss           | 0.0819       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.1        |\n",
      "|    ep_rew_mean          | 51.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 402         |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 813         |\n",
      "|    total_timesteps      | 327680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012914175 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00753    |\n",
      "|    n_updates            | 10560       |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    value_loss           | 0.105       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=328208, episode_reward=52.34 +/- 3.80\n",
      "Episode length: 79.70 +/- 9.95\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 79.7        |\n",
      "|    mean_reward          | 52.3        |\n",
      "|    std_reward           | 3.8         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 328208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016013637 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.16       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00571    |\n",
      "|    n_updates            | 10570       |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 0.0898      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78       |\n",
      "|    ep_rew_mean     | 51       |\n",
      "| time/              |          |\n",
      "|    fps             | 402      |\n",
      "|    iterations      | 81       |\n",
      "|    time_elapsed    | 824      |\n",
      "|    total_timesteps | 331776   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.7        |\n",
      "|    ep_rew_mean          | 51          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 402         |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 833         |\n",
      "|    total_timesteps      | 335872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016270544 |\n",
      "|    clip_fraction        | 0.301       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00627    |\n",
      "|    n_updates            | 10580       |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    value_loss           | 0.101       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=338208, episode_reward=53.49 +/- 3.97\n",
      "Episode length: 79.60 +/- 8.01\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 79.6        |\n",
      "|    mean_reward          | 53.5        |\n",
      "|    std_reward           | 3.97        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 338208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013903237 |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.16       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0207     |\n",
      "|    n_updates            | 10590       |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    value_loss           | 0.1         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 80.4     |\n",
      "|    ep_rew_mean     | 50.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 402      |\n",
      "|    iterations      | 83       |\n",
      "|    time_elapsed    | 844      |\n",
      "|    total_timesteps | 339968   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.5        |\n",
      "|    ep_rew_mean          | 50.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 402         |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 854         |\n",
      "|    total_timesteps      | 344064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015463747 |\n",
      "|    clip_fraction        | 0.317       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.16       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0141     |\n",
      "|    n_updates            | 10600       |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    value_loss           | 0.0681      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79          |\n",
      "|    ep_rew_mean          | 50.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 402         |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 864         |\n",
      "|    total_timesteps      | 348160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015189752 |\n",
      "|    clip_fraction        | 0.33        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.16       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0177     |\n",
      "|    n_updates            | 10610       |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    value_loss           | 0.103       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=348208, episode_reward=53.01 +/- 2.85\n",
      "Episode length: 77.90 +/- 9.66\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 77.9        |\n",
      "|    mean_reward          | 53          |\n",
      "|    std_reward           | 2.85        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 348208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014496215 |\n",
      "|    clip_fraction        | 0.284       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.17       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0081     |\n",
      "|    n_updates            | 10620       |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    value_loss           | 0.0843      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79       |\n",
      "|    ep_rew_mean     | 51.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 402      |\n",
      "|    iterations      | 86       |\n",
      "|    time_elapsed    | 875      |\n",
      "|    total_timesteps | 352256   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78          |\n",
      "|    ep_rew_mean          | 52.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 402         |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 885         |\n",
      "|    total_timesteps      | 356352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014511911 |\n",
      "|    clip_fraction        | 0.301       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00428    |\n",
      "|    n_updates            | 10630       |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    value_loss           | 0.0754      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=358208, episode_reward=55.53 +/- 1.82\n",
      "Episode length: 72.90 +/- 8.98\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 72.9        |\n",
      "|    mean_reward          | 55.5        |\n",
      "|    std_reward           | 1.82        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 358208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013760123 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00173     |\n",
      "|    n_updates            | 10640       |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    value_loss           | 0.0987      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77       |\n",
      "|    ep_rew_mean     | 51.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 402      |\n",
      "|    iterations      | 88       |\n",
      "|    time_elapsed    | 896      |\n",
      "|    total_timesteps | 360448   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.3        |\n",
      "|    ep_rew_mean          | 51.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 402         |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 905         |\n",
      "|    total_timesteps      | 364544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015802812 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.16       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00171     |\n",
      "|    n_updates            | 10650       |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 0.0898      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=368208, episode_reward=56.11 +/- 2.30\n",
      "Episode length: 72.90 +/- 9.10\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 72.9        |\n",
      "|    mean_reward          | 56.1        |\n",
      "|    std_reward           | 2.3         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 368208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015906494 |\n",
      "|    clip_fraction        | 0.303       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.16       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00501    |\n",
      "|    n_updates            | 10660       |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    value_loss           | 0.0688      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78       |\n",
      "|    ep_rew_mean     | 52.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 402      |\n",
      "|    iterations      | 90       |\n",
      "|    time_elapsed    | 916      |\n",
      "|    total_timesteps | 368640   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 77         |\n",
      "|    ep_rew_mean          | 52.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 402        |\n",
      "|    iterations           | 91         |\n",
      "|    time_elapsed         | 926        |\n",
      "|    total_timesteps      | 372736     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01726269 |\n",
      "|    clip_fraction        | 0.284      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.15      |\n",
      "|    explained_variance   | 0.999      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | 0.00682    |\n",
      "|    n_updates            | 10670      |\n",
      "|    policy_gradient_loss | -0.0131    |\n",
      "|    value_loss           | 0.0824     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.7        |\n",
      "|    ep_rew_mean          | 51.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 402         |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 936         |\n",
      "|    total_timesteps      | 376832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013008192 |\n",
      "|    clip_fraction        | 0.31        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0109     |\n",
      "|    n_updates            | 10680       |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    value_loss           | 0.0694      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=378208, episode_reward=52.70 +/- 4.29\n",
      "Episode length: 75.60 +/- 10.45\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 75.6        |\n",
      "|    mean_reward          | 52.7        |\n",
      "|    std_reward           | 4.29        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 378208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016716115 |\n",
      "|    clip_fraction        | 0.307       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0114     |\n",
      "|    n_updates            | 10690       |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    value_loss           | 0.0826      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 80.5     |\n",
      "|    ep_rew_mean     | 51.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 402      |\n",
      "|    iterations      | 93       |\n",
      "|    time_elapsed    | 947      |\n",
      "|    total_timesteps | 380928   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 78.9       |\n",
      "|    ep_rew_mean          | 51.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 402        |\n",
      "|    iterations           | 94         |\n",
      "|    time_elapsed         | 956        |\n",
      "|    total_timesteps      | 385024     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01758214 |\n",
      "|    clip_fraction        | 0.316      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.18      |\n",
      "|    explained_variance   | 0.999      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.0101    |\n",
      "|    n_updates            | 10700      |\n",
      "|    policy_gradient_loss | -0.0135    |\n",
      "|    value_loss           | 0.0617     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=388208, episode_reward=53.93 +/- 2.27\n",
      "Episode length: 79.90 +/- 9.02\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 79.9        |\n",
      "|    mean_reward          | 53.9        |\n",
      "|    std_reward           | 2.27        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 388208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015579337 |\n",
      "|    clip_fraction        | 0.302       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00996    |\n",
      "|    n_updates            | 10710       |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    value_loss           | 0.0803      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.2     |\n",
      "|    ep_rew_mean     | 51.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 402      |\n",
      "|    iterations      | 95       |\n",
      "|    time_elapsed    | 967      |\n",
      "|    total_timesteps | 389120   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78.9         |\n",
      "|    ep_rew_mean          | 50.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 402          |\n",
      "|    iterations           | 96           |\n",
      "|    time_elapsed         | 977          |\n",
      "|    total_timesteps      | 393216       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0135067385 |\n",
      "|    clip_fraction        | 0.275        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.18        |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0128      |\n",
      "|    n_updates            | 10720        |\n",
      "|    policy_gradient_loss | -0.0134      |\n",
      "|    value_loss           | 0.118        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.9        |\n",
      "|    ep_rew_mean          | 50.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 402         |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 987         |\n",
      "|    total_timesteps      | 397312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014733084 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.17       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00844    |\n",
      "|    n_updates            | 10730       |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    value_loss           | 0.091       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=398208, episode_reward=55.35 +/- 2.98\n",
      "Episode length: 73.00 +/- 10.39\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 73          |\n",
      "|    mean_reward          | 55.3        |\n",
      "|    std_reward           | 2.98        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 398208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014559811 |\n",
      "|    clip_fraction        | 0.312       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00991    |\n",
      "|    n_updates            | 10740       |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 0.0803      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.5     |\n",
      "|    ep_rew_mean     | 50.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 402      |\n",
      "|    iterations      | 98       |\n",
      "|    time_elapsed    | 998      |\n",
      "|    total_timesteps | 401408   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.6        |\n",
      "|    ep_rew_mean          | 51.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 402         |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 1007        |\n",
      "|    total_timesteps      | 405504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017558731 |\n",
      "|    clip_fraction        | 0.315       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00751    |\n",
      "|    n_updates            | 10750       |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    value_loss           | 0.0794      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=408208, episode_reward=53.19 +/- 4.27\n",
      "Episode length: 76.80 +/- 10.84\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 76.8        |\n",
      "|    mean_reward          | 53.2        |\n",
      "|    std_reward           | 4.27        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 408208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016086554 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.16       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00729    |\n",
      "|    n_updates            | 10760       |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    value_loss           | 0.103       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.5     |\n",
      "|    ep_rew_mean     | 52       |\n",
      "| time/              |          |\n",
      "|    fps             | 402      |\n",
      "|    iterations      | 100      |\n",
      "|    time_elapsed    | 1018     |\n",
      "|    total_timesteps | 409600   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.9        |\n",
      "|    ep_rew_mean          | 51.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 402         |\n",
      "|    iterations           | 101         |\n",
      "|    time_elapsed         | 1028        |\n",
      "|    total_timesteps      | 413696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013756329 |\n",
      "|    clip_fraction        | 0.312       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00691    |\n",
      "|    n_updates            | 10770       |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    value_loss           | 0.0934      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 78.3       |\n",
      "|    ep_rew_mean          | 51.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 402        |\n",
      "|    iterations           | 102        |\n",
      "|    time_elapsed         | 1038       |\n",
      "|    total_timesteps      | 417792     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01524106 |\n",
      "|    clip_fraction        | 0.287      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.16      |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.00512   |\n",
      "|    n_updates            | 10780      |\n",
      "|    policy_gradient_loss | -0.0138    |\n",
      "|    value_loss           | 0.104      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=418208, episode_reward=53.18 +/- 5.26\n",
      "Episode length: 79.40 +/- 14.53\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 79.4       |\n",
      "|    mean_reward          | 53.2       |\n",
      "|    std_reward           | 5.26       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 418208     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01978359 |\n",
      "|    clip_fraction        | 0.318      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.18      |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.00231   |\n",
      "|    n_updates            | 10790      |\n",
      "|    policy_gradient_loss | -0.0143    |\n",
      "|    value_loss           | 0.0986     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.1     |\n",
      "|    ep_rew_mean     | 50.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 402      |\n",
      "|    iterations      | 103      |\n",
      "|    time_elapsed    | 1049     |\n",
      "|    total_timesteps | 421888   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.5        |\n",
      "|    ep_rew_mean          | 50.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 402         |\n",
      "|    iterations           | 104         |\n",
      "|    time_elapsed         | 1058        |\n",
      "|    total_timesteps      | 425984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015967362 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0155     |\n",
      "|    n_updates            | 10800       |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    value_loss           | 0.0826      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=428208, episode_reward=52.59 +/- 3.56\n",
      "Episode length: 79.30 +/- 8.32\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 79.3        |\n",
      "|    mean_reward          | 52.6        |\n",
      "|    std_reward           | 3.56        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 428208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014935959 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00578    |\n",
      "|    n_updates            | 10810       |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    value_loss           | 0.098       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.8     |\n",
      "|    ep_rew_mean     | 51.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 402      |\n",
      "|    iterations      | 105      |\n",
      "|    time_elapsed    | 1069     |\n",
      "|    total_timesteps | 430080   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.8        |\n",
      "|    ep_rew_mean          | 52.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 402         |\n",
      "|    iterations           | 106         |\n",
      "|    time_elapsed         | 1079        |\n",
      "|    total_timesteps      | 434176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014392186 |\n",
      "|    clip_fraction        | 0.335       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00147    |\n",
      "|    n_updates            | 10820       |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    value_loss           | 0.0817      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=438208, episode_reward=52.93 +/- 4.57\n",
      "Episode length: 80.40 +/- 8.43\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 80.4        |\n",
      "|    mean_reward          | 52.9        |\n",
      "|    std_reward           | 4.57        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 438208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018613175 |\n",
      "|    clip_fraction        | 0.327       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.16       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0149     |\n",
      "|    n_updates            | 10830       |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    value_loss           | 0.0814      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.7     |\n",
      "|    ep_rew_mean     | 52.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 402      |\n",
      "|    iterations      | 107      |\n",
      "|    time_elapsed    | 1090     |\n",
      "|    total_timesteps | 438272   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.8        |\n",
      "|    ep_rew_mean          | 51.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 402         |\n",
      "|    iterations           | 108         |\n",
      "|    time_elapsed         | 1099        |\n",
      "|    total_timesteps      | 442368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016288131 |\n",
      "|    clip_fraction        | 0.307       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0184     |\n",
      "|    n_updates            | 10840       |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    value_loss           | 0.0808      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.9        |\n",
      "|    ep_rew_mean          | 51.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 402         |\n",
      "|    iterations           | 109         |\n",
      "|    time_elapsed         | 1109        |\n",
      "|    total_timesteps      | 446464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016463999 |\n",
      "|    clip_fraction        | 0.302       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00788    |\n",
      "|    n_updates            | 10850       |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    value_loss           | 0.102       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=448208, episode_reward=52.88 +/- 2.51\n",
      "Episode length: 73.60 +/- 5.41\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 73.6        |\n",
      "|    mean_reward          | 52.9        |\n",
      "|    std_reward           | 2.51        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 448208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015118483 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0121      |\n",
      "|    n_updates            | 10860       |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    value_loss           | 0.0984      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.7     |\n",
      "|    ep_rew_mean     | 51.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 402      |\n",
      "|    iterations      | 110      |\n",
      "|    time_elapsed    | 1120     |\n",
      "|    total_timesteps | 450560   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.9        |\n",
      "|    ep_rew_mean          | 51.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 402         |\n",
      "|    iterations           | 111         |\n",
      "|    time_elapsed         | 1130        |\n",
      "|    total_timesteps      | 454656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013421586 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00303    |\n",
      "|    n_updates            | 10870       |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    value_loss           | 0.0683      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=458208, episode_reward=53.97 +/- 3.09\n",
      "Episode length: 74.10 +/- 6.22\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 74.1        |\n",
      "|    mean_reward          | 54          |\n",
      "|    std_reward           | 3.09        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 458208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018070137 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.17       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0152     |\n",
      "|    n_updates            | 10880       |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    value_loss           | 0.0817      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.9     |\n",
      "|    ep_rew_mean     | 51.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 402      |\n",
      "|    iterations      | 112      |\n",
      "|    time_elapsed    | 1140     |\n",
      "|    total_timesteps | 458752   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.4        |\n",
      "|    ep_rew_mean          | 52          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 402         |\n",
      "|    iterations           | 113         |\n",
      "|    time_elapsed         | 1150        |\n",
      "|    total_timesteps      | 462848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013413603 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0129     |\n",
      "|    n_updates            | 10890       |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    value_loss           | 0.0846      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.9        |\n",
      "|    ep_rew_mean          | 50.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 402         |\n",
      "|    iterations           | 114         |\n",
      "|    time_elapsed         | 1160        |\n",
      "|    total_timesteps      | 466944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014629966 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.16       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00426    |\n",
      "|    n_updates            | 10900       |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    value_loss           | 0.109       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=468208, episode_reward=52.01 +/- 4.12\n",
      "Episode length: 80.30 +/- 13.65\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 80.3        |\n",
      "|    mean_reward          | 52          |\n",
      "|    std_reward           | 4.12        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 468208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013566773 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.16       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00847     |\n",
      "|    n_updates            | 10910       |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    value_loss           | 0.0955      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.6     |\n",
      "|    ep_rew_mean     | 51.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 402      |\n",
      "|    iterations      | 115      |\n",
      "|    time_elapsed    | 1170     |\n",
      "|    total_timesteps | 471040   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 77.7       |\n",
      "|    ep_rew_mean          | 51.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 402        |\n",
      "|    iterations           | 116        |\n",
      "|    time_elapsed         | 1180       |\n",
      "|    total_timesteps      | 475136     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01466582 |\n",
      "|    clip_fraction        | 0.313      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.15      |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.0179    |\n",
      "|    n_updates            | 10920      |\n",
      "|    policy_gradient_loss | -0.0135    |\n",
      "|    value_loss           | 0.0974     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=478208, episode_reward=52.92 +/- 3.22\n",
      "Episode length: 78.40 +/- 8.32\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 78.4        |\n",
      "|    mean_reward          | 52.9        |\n",
      "|    std_reward           | 3.22        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 478208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015961988 |\n",
      "|    clip_fraction        | 0.305       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.16       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00918    |\n",
      "|    n_updates            | 10930       |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    value_loss           | 0.0868      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.9     |\n",
      "|    ep_rew_mean     | 51.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 402      |\n",
      "|    iterations      | 117      |\n",
      "|    time_elapsed    | 1191     |\n",
      "|    total_timesteps | 479232   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76          |\n",
      "|    ep_rew_mean          | 52.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 402         |\n",
      "|    iterations           | 118         |\n",
      "|    time_elapsed         | 1201        |\n",
      "|    total_timesteps      | 483328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015187021 |\n",
      "|    clip_fraction        | 0.303       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00118     |\n",
      "|    n_updates            | 10940       |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    value_loss           | 0.0912      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.2        |\n",
      "|    ep_rew_mean          | 52.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 402         |\n",
      "|    iterations           | 119         |\n",
      "|    time_elapsed         | 1210        |\n",
      "|    total_timesteps      | 487424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017966904 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.12       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00196     |\n",
      "|    n_updates            | 10950       |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 0.0969      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=488208, episode_reward=51.74 +/- 2.78\n",
      "Episode length: 84.60 +/- 8.56\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 84.6        |\n",
      "|    mean_reward          | 51.7        |\n",
      "|    std_reward           | 2.78        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 488208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014131803 |\n",
      "|    clip_fraction        | 0.31        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.16       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0138     |\n",
      "|    n_updates            | 10960       |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    value_loss           | 0.0782      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.5     |\n",
      "|    ep_rew_mean     | 51.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 402      |\n",
      "|    iterations      | 120      |\n",
      "|    time_elapsed    | 1221     |\n",
      "|    total_timesteps | 491520   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 77.4       |\n",
      "|    ep_rew_mean          | 51.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 402        |\n",
      "|    iterations           | 121        |\n",
      "|    time_elapsed         | 1231       |\n",
      "|    total_timesteps      | 495616     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01627092 |\n",
      "|    clip_fraction        | 0.303      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.15      |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | 0.0128     |\n",
      "|    n_updates            | 10970      |\n",
      "|    policy_gradient_loss | -0.0131    |\n",
      "|    value_loss           | 0.0981     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=498208, episode_reward=53.33 +/- 3.03\n",
      "Episode length: 77.90 +/- 7.38\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 77.9        |\n",
      "|    mean_reward          | 53.3        |\n",
      "|    std_reward           | 3.03        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 498208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017858665 |\n",
      "|    clip_fraction        | 0.32        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0018     |\n",
      "|    n_updates            | 10980       |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    value_loss           | 0.0927      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.7     |\n",
      "|    ep_rew_mean     | 51.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 402      |\n",
      "|    iterations      | 122      |\n",
      "|    time_elapsed    | 1242     |\n",
      "|    total_timesteps | 499712   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 77.1       |\n",
      "|    ep_rew_mean          | 50.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 402        |\n",
      "|    iterations           | 123        |\n",
      "|    time_elapsed         | 1251       |\n",
      "|    total_timesteps      | 503808     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01697313 |\n",
      "|    clip_fraction        | 0.284      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.14      |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.0121    |\n",
      "|    n_updates            | 10990      |\n",
      "|    policy_gradient_loss | -0.015     |\n",
      "|    value_loss           | 0.0899     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 76.8      |\n",
      "|    ep_rew_mean          | 51.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 402       |\n",
      "|    iterations           | 124       |\n",
      "|    time_elapsed         | 1261      |\n",
      "|    total_timesteps      | 507904    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0136475 |\n",
      "|    clip_fraction        | 0.292     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -1.14     |\n",
      "|    explained_variance   | 0.997     |\n",
      "|    learning_rate        | 5e-05     |\n",
      "|    loss                 | 0.00828   |\n",
      "|    n_updates            | 11000     |\n",
      "|    policy_gradient_loss | -0.014    |\n",
      "|    value_loss           | 0.108     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=508208, episode_reward=53.58 +/- 2.95\n",
      "Episode length: 78.70 +/- 9.51\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 78.7        |\n",
      "|    mean_reward          | 53.6        |\n",
      "|    std_reward           | 2.95        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 508208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014291493 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.12       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00668    |\n",
      "|    n_updates            | 11010       |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 0.105       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77       |\n",
      "|    ep_rew_mean     | 51.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 402      |\n",
      "|    iterations      | 125      |\n",
      "|    time_elapsed    | 1272     |\n",
      "|    total_timesteps | 512000   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 77.2       |\n",
      "|    ep_rew_mean          | 51         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 402        |\n",
      "|    iterations           | 126        |\n",
      "|    time_elapsed         | 1281       |\n",
      "|    total_timesteps      | 516096     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01576217 |\n",
      "|    clip_fraction        | 0.279      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.15      |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | 0.00548    |\n",
      "|    n_updates            | 11020      |\n",
      "|    policy_gradient_loss | -0.0134    |\n",
      "|    value_loss           | 0.111      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=518208, episode_reward=54.11 +/- 3.19\n",
      "Episode length: 71.20 +/- 9.63\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 71.2        |\n",
      "|    mean_reward          | 54.1        |\n",
      "|    std_reward           | 3.19        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 518208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015124296 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00605    |\n",
      "|    n_updates            | 11030       |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    value_loss           | 0.107       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.2     |\n",
      "|    ep_rew_mean     | 51.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 402      |\n",
      "|    iterations      | 127      |\n",
      "|    time_elapsed    | 1292     |\n",
      "|    total_timesteps | 520192   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 77.7       |\n",
      "|    ep_rew_mean          | 51.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 402        |\n",
      "|    iterations           | 128        |\n",
      "|    time_elapsed         | 1302       |\n",
      "|    total_timesteps      | 524288     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01418454 |\n",
      "|    clip_fraction        | 0.29       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.13      |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.0107    |\n",
      "|    n_updates            | 11040      |\n",
      "|    policy_gradient_loss | -0.0158    |\n",
      "|    value_loss           | 0.108      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=528208, episode_reward=55.27 +/- 2.47\n",
      "Episode length: 75.10 +/- 9.14\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 75.1        |\n",
      "|    mean_reward          | 55.3        |\n",
      "|    std_reward           | 2.47        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 528208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017275352 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.12       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00945    |\n",
      "|    n_updates            | 11050       |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    value_loss           | 0.0784      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.7     |\n",
      "|    ep_rew_mean     | 51.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 402      |\n",
      "|    iterations      | 129      |\n",
      "|    time_elapsed    | 1313     |\n",
      "|    total_timesteps | 528384   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 79.4       |\n",
      "|    ep_rew_mean          | 51.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 402        |\n",
      "|    iterations           | 130        |\n",
      "|    time_elapsed         | 1322       |\n",
      "|    total_timesteps      | 532480     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01480344 |\n",
      "|    clip_fraction        | 0.299      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.13      |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | 0.000353   |\n",
      "|    n_updates            | 11060      |\n",
      "|    policy_gradient_loss | -0.0142    |\n",
      "|    value_loss           | 0.0995     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78          |\n",
      "|    ep_rew_mean          | 52          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 402         |\n",
      "|    iterations           | 131         |\n",
      "|    time_elapsed         | 1332        |\n",
      "|    total_timesteps      | 536576      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016519696 |\n",
      "|    clip_fraction        | 0.319       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0112     |\n",
      "|    n_updates            | 11070       |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    value_loss           | 0.0778      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=538208, episode_reward=53.34 +/- 4.03\n",
      "Episode length: 74.70 +/- 11.93\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 74.7       |\n",
      "|    mean_reward          | 53.3       |\n",
      "|    std_reward           | 4.03       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 538208     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01628673 |\n",
      "|    clip_fraction        | 0.309      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.14      |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.0134    |\n",
      "|    n_updates            | 11080      |\n",
      "|    policy_gradient_loss | -0.0152    |\n",
      "|    value_loss           | 0.0818     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.7     |\n",
      "|    ep_rew_mean     | 51.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 402      |\n",
      "|    iterations      | 132      |\n",
      "|    time_elapsed    | 1342     |\n",
      "|    total_timesteps | 540672   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.7        |\n",
      "|    ep_rew_mean          | 51.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 402         |\n",
      "|    iterations           | 133         |\n",
      "|    time_elapsed         | 1352        |\n",
      "|    total_timesteps      | 544768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014153993 |\n",
      "|    clip_fraction        | 0.314       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0159     |\n",
      "|    n_updates            | 11090       |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    value_loss           | 0.0732      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=548208, episode_reward=52.12 +/- 4.69\n",
      "Episode length: 82.40 +/- 6.20\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 82.4        |\n",
      "|    mean_reward          | 52.1        |\n",
      "|    std_reward           | 4.69        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 548208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017951585 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.11       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.000898   |\n",
      "|    n_updates            | 11100       |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    value_loss           | 0.0648      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.9     |\n",
      "|    ep_rew_mean     | 51.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 402      |\n",
      "|    iterations      | 134      |\n",
      "|    time_elapsed    | 1363     |\n",
      "|    total_timesteps | 548864   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.6        |\n",
      "|    ep_rew_mean          | 52.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 402         |\n",
      "|    iterations           | 135         |\n",
      "|    time_elapsed         | 1373        |\n",
      "|    total_timesteps      | 552960      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017533552 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0144     |\n",
      "|    n_updates            | 11110       |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    value_loss           | 0.0881      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 77           |\n",
      "|    ep_rew_mean          | 52.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 402          |\n",
      "|    iterations           | 136          |\n",
      "|    time_elapsed         | 1382         |\n",
      "|    total_timesteps      | 557056       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0149249025 |\n",
      "|    clip_fraction        | 0.283        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | 0.998        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0179      |\n",
      "|    n_updates            | 11120        |\n",
      "|    policy_gradient_loss | -0.015       |\n",
      "|    value_loss           | 0.0819       |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=558208, episode_reward=54.56 +/- 2.38\n",
      "Episode length: 74.40 +/- 10.23\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 74.4        |\n",
      "|    mean_reward          | 54.6        |\n",
      "|    std_reward           | 2.38        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 558208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017977245 |\n",
      "|    clip_fraction        | 0.323       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.12       |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00451    |\n",
      "|    n_updates            | 11130       |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    value_loss           | 0.0675      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.8     |\n",
      "|    ep_rew_mean     | 52.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 402      |\n",
      "|    iterations      | 137      |\n",
      "|    time_elapsed    | 1393     |\n",
      "|    total_timesteps | 561152   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 76.8      |\n",
      "|    ep_rew_mean          | 52.3      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 402       |\n",
      "|    iterations           | 138       |\n",
      "|    time_elapsed         | 1403      |\n",
      "|    total_timesteps      | 565248    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0142471 |\n",
      "|    clip_fraction        | 0.304     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -1.13     |\n",
      "|    explained_variance   | 0.999     |\n",
      "|    learning_rate        | 5e-05     |\n",
      "|    loss                 | -0.00955  |\n",
      "|    n_updates            | 11140     |\n",
      "|    policy_gradient_loss | -0.0166   |\n",
      "|    value_loss           | 0.0677    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=568208, episode_reward=54.58 +/- 5.00\n",
      "Episode length: 76.50 +/- 7.07\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 76.5        |\n",
      "|    mean_reward          | 54.6        |\n",
      "|    std_reward           | 5           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 568208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015940309 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0112     |\n",
      "|    n_updates            | 11150       |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    value_loss           | 0.124       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 76.9     |\n",
      "|    ep_rew_mean     | 52.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 402      |\n",
      "|    iterations      | 139      |\n",
      "|    time_elapsed    | 1413     |\n",
      "|    total_timesteps | 569344   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 78.7       |\n",
      "|    ep_rew_mean          | 51.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 402        |\n",
      "|    iterations           | 140        |\n",
      "|    time_elapsed         | 1423       |\n",
      "|    total_timesteps      | 573440     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01901586 |\n",
      "|    clip_fraction        | 0.318      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.12      |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | 0.00808    |\n",
      "|    n_updates            | 11160      |\n",
      "|    policy_gradient_loss | -0.0123    |\n",
      "|    value_loss           | 0.0979     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 79         |\n",
      "|    ep_rew_mean          | 51.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 402        |\n",
      "|    iterations           | 141        |\n",
      "|    time_elapsed         | 1433       |\n",
      "|    total_timesteps      | 577536     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01698216 |\n",
      "|    clip_fraction        | 0.305      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.13      |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.0248    |\n",
      "|    n_updates            | 11170      |\n",
      "|    policy_gradient_loss | -0.0128    |\n",
      "|    value_loss           | 0.0859     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=578208, episode_reward=52.48 +/- 4.27\n",
      "Episode length: 80.70 +/- 11.31\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 80.7        |\n",
      "|    mean_reward          | 52.5        |\n",
      "|    std_reward           | 4.27        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 578208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015722048 |\n",
      "|    clip_fraction        | 0.294       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00823    |\n",
      "|    n_updates            | 11180       |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    value_loss           | 0.0845      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.9     |\n",
      "|    ep_rew_mean     | 52.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 402      |\n",
      "|    iterations      | 142      |\n",
      "|    time_elapsed    | 1444     |\n",
      "|    total_timesteps | 581632   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.9        |\n",
      "|    ep_rew_mean          | 51.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 402         |\n",
      "|    iterations           | 143         |\n",
      "|    time_elapsed         | 1453        |\n",
      "|    total_timesteps      | 585728      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016097648 |\n",
      "|    clip_fraction        | 0.305       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0178     |\n",
      "|    n_updates            | 11190       |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    value_loss           | 0.0674      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=588208, episode_reward=49.98 +/- 4.44\n",
      "Episode length: 86.30 +/- 8.10\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 86.3        |\n",
      "|    mean_reward          | 50          |\n",
      "|    std_reward           | 4.44        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 588208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015982155 |\n",
      "|    clip_fraction        | 0.305       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00501    |\n",
      "|    n_updates            | 11200       |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    value_loss           | 0.0812      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.4     |\n",
      "|    ep_rew_mean     | 50.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 402      |\n",
      "|    iterations      | 144      |\n",
      "|    time_elapsed    | 1464     |\n",
      "|    total_timesteps | 589824   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.3        |\n",
      "|    ep_rew_mean          | 51.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 402         |\n",
      "|    iterations           | 145         |\n",
      "|    time_elapsed         | 1474        |\n",
      "|    total_timesteps      | 593920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012911072 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00415    |\n",
      "|    n_updates            | 11210       |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 0.0851      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.5        |\n",
      "|    ep_rew_mean          | 52.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 402         |\n",
      "|    iterations           | 146         |\n",
      "|    time_elapsed         | 1484        |\n",
      "|    total_timesteps      | 598016      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014517769 |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.12       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0155     |\n",
      "|    n_updates            | 11220       |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 0.0811      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=598208, episode_reward=52.85 +/- 4.56\n",
      "Episode length: 80.60 +/- 13.91\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 80.6       |\n",
      "|    mean_reward          | 52.9       |\n",
      "|    std_reward           | 4.56       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 598208     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01662599 |\n",
      "|    clip_fraction        | 0.301      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.14      |\n",
      "|    explained_variance   | 0.999      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.0109    |\n",
      "|    n_updates            | 11230      |\n",
      "|    policy_gradient_loss | -0.0131    |\n",
      "|    value_loss           | 0.0809     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 76.6     |\n",
      "|    ep_rew_mean     | 52.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 402      |\n",
      "|    iterations      | 147      |\n",
      "|    time_elapsed    | 1495     |\n",
      "|    total_timesteps | 602112   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 78         |\n",
      "|    ep_rew_mean          | 51.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 402        |\n",
      "|    iterations           | 148        |\n",
      "|    time_elapsed         | 1504       |\n",
      "|    total_timesteps      | 606208     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01612226 |\n",
      "|    clip_fraction        | 0.298      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.14      |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.0043    |\n",
      "|    n_updates            | 11240      |\n",
      "|    policy_gradient_loss | -0.0157    |\n",
      "|    value_loss           | 0.0712     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=608208, episode_reward=51.76 +/- 3.85\n",
      "Episode length: 80.00 +/- 10.68\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 80          |\n",
      "|    mean_reward          | 51.8        |\n",
      "|    std_reward           | 3.85        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 608208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015079742 |\n",
      "|    clip_fraction        | 0.303       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0114      |\n",
      "|    n_updates            | 11250       |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    value_loss           | 0.0814      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.8     |\n",
      "|    ep_rew_mean     | 51.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 402      |\n",
      "|    iterations      | 149      |\n",
      "|    time_elapsed    | 1515     |\n",
      "|    total_timesteps | 610304   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77          |\n",
      "|    ep_rew_mean          | 51.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 402         |\n",
      "|    iterations           | 150         |\n",
      "|    time_elapsed         | 1525        |\n",
      "|    total_timesteps      | 614400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017991627 |\n",
      "|    clip_fraction        | 0.301       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0107     |\n",
      "|    n_updates            | 11260       |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    value_loss           | 0.0861      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=618208, episode_reward=54.13 +/- 3.86\n",
      "Episode length: 72.90 +/- 10.47\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 72.9        |\n",
      "|    mean_reward          | 54.1        |\n",
      "|    std_reward           | 3.86        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 618208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014984564 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.12       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00278    |\n",
      "|    n_updates            | 11270       |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 0.0945      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.8     |\n",
      "|    ep_rew_mean     | 51.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 402      |\n",
      "|    iterations      | 151      |\n",
      "|    time_elapsed    | 1536     |\n",
      "|    total_timesteps | 618496   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 77.8       |\n",
      "|    ep_rew_mean          | 52.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 402        |\n",
      "|    iterations           | 152        |\n",
      "|    time_elapsed         | 1545       |\n",
      "|    total_timesteps      | 622592     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01575111 |\n",
      "|    clip_fraction        | 0.314      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.13      |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | 0.00403    |\n",
      "|    n_updates            | 11280      |\n",
      "|    policy_gradient_loss | -0.0128    |\n",
      "|    value_loss           | 0.0764     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.4        |\n",
      "|    ep_rew_mean          | 52.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 402         |\n",
      "|    iterations           | 153         |\n",
      "|    time_elapsed         | 1555        |\n",
      "|    total_timesteps      | 626688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016367113 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0031      |\n",
      "|    n_updates            | 11290       |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 0.0766      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=628208, episode_reward=54.55 +/- 2.88\n",
      "Episode length: 72.60 +/- 10.20\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 72.6        |\n",
      "|    mean_reward          | 54.6        |\n",
      "|    std_reward           | 2.88        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 628208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016085263 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0102     |\n",
      "|    n_updates            | 11300       |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    value_loss           | 0.0833      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.6     |\n",
      "|    ep_rew_mean     | 52.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 402      |\n",
      "|    iterations      | 154      |\n",
      "|    time_elapsed    | 1566     |\n",
      "|    total_timesteps | 630784   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 76.9       |\n",
      "|    ep_rew_mean          | 52.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 402        |\n",
      "|    iterations           | 155        |\n",
      "|    time_elapsed         | 1576       |\n",
      "|    total_timesteps      | 634880     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01840662 |\n",
      "|    clip_fraction        | 0.321      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.13      |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.00215   |\n",
      "|    n_updates            | 11310      |\n",
      "|    policy_gradient_loss | -0.0137    |\n",
      "|    value_loss           | 0.0716     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=638208, episode_reward=52.83 +/- 3.36\n",
      "Episode length: 80.00 +/- 9.79\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 80          |\n",
      "|    mean_reward          | 52.8        |\n",
      "|    std_reward           | 3.36        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 638208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017685145 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.12       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00438     |\n",
      "|    n_updates            | 11320       |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    value_loss           | 0.0741      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.4     |\n",
      "|    ep_rew_mean     | 51.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 402      |\n",
      "|    iterations      | 156      |\n",
      "|    time_elapsed    | 1587     |\n",
      "|    total_timesteps | 638976   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.9        |\n",
      "|    ep_rew_mean          | 51.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 402         |\n",
      "|    iterations           | 157         |\n",
      "|    time_elapsed         | 1596        |\n",
      "|    total_timesteps      | 643072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015504867 |\n",
      "|    clip_fraction        | 0.305       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00468    |\n",
      "|    n_updates            | 11330       |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 0.0849      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.1        |\n",
      "|    ep_rew_mean          | 51.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 402         |\n",
      "|    iterations           | 158         |\n",
      "|    time_elapsed         | 1606        |\n",
      "|    total_timesteps      | 647168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015931528 |\n",
      "|    clip_fraction        | 0.302       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00752    |\n",
      "|    n_updates            | 11340       |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    value_loss           | 0.0724      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=648208, episode_reward=54.88 +/- 2.73\n",
      "Episode length: 78.10 +/- 8.09\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 78.1       |\n",
      "|    mean_reward          | 54.9       |\n",
      "|    std_reward           | 2.73       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 648208     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01609896 |\n",
      "|    clip_fraction        | 0.3        |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.14      |\n",
      "|    explained_variance   | 0.997      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.000948  |\n",
      "|    n_updates            | 11350      |\n",
      "|    policy_gradient_loss | -0.0141    |\n",
      "|    value_loss           | 0.102      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.2     |\n",
      "|    ep_rew_mean     | 52       |\n",
      "| time/              |          |\n",
      "|    fps             | 402      |\n",
      "|    iterations      | 159      |\n",
      "|    time_elapsed    | 1617     |\n",
      "|    total_timesteps | 651264   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.9        |\n",
      "|    ep_rew_mean          | 51.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 402         |\n",
      "|    iterations           | 160         |\n",
      "|    time_elapsed         | 1626        |\n",
      "|    total_timesteps      | 655360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016756186 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.12       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00832    |\n",
      "|    n_updates            | 11360       |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    value_loss           | 0.0889      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=658208, episode_reward=51.52 +/- 4.26\n",
      "Episode length: 82.30 +/- 12.01\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 82.3        |\n",
      "|    mean_reward          | 51.5        |\n",
      "|    std_reward           | 4.26        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 658208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016967457 |\n",
      "|    clip_fraction        | 0.302       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0229     |\n",
      "|    n_updates            | 11370       |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    value_loss           | 0.0913      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.8     |\n",
      "|    ep_rew_mean     | 51       |\n",
      "| time/              |          |\n",
      "|    fps             | 402      |\n",
      "|    iterations      | 161      |\n",
      "|    time_elapsed    | 1637     |\n",
      "|    total_timesteps | 659456   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78          |\n",
      "|    ep_rew_mean          | 52          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 402         |\n",
      "|    iterations           | 162         |\n",
      "|    time_elapsed         | 1647        |\n",
      "|    total_timesteps      | 663552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016976086 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.16       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00387    |\n",
      "|    n_updates            | 11380       |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    value_loss           | 0.105       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.9        |\n",
      "|    ep_rew_mean          | 52.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 402         |\n",
      "|    iterations           | 163         |\n",
      "|    time_elapsed         | 1657        |\n",
      "|    total_timesteps      | 667648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014639755 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.11       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0147     |\n",
      "|    n_updates            | 11390       |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    value_loss           | 0.0953      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=668208, episode_reward=52.08 +/- 2.14\n",
      "Episode length: 79.90 +/- 7.85\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 79.9        |\n",
      "|    mean_reward          | 52.1        |\n",
      "|    std_reward           | 2.14        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 668208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019737504 |\n",
      "|    clip_fraction        | 0.332       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0198     |\n",
      "|    n_updates            | 11400       |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 0.0673      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.5     |\n",
      "|    ep_rew_mean     | 51.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 402      |\n",
      "|    iterations      | 164      |\n",
      "|    time_elapsed    | 1668     |\n",
      "|    total_timesteps | 671744   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.9        |\n",
      "|    ep_rew_mean          | 51.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 402         |\n",
      "|    iterations           | 165         |\n",
      "|    time_elapsed         | 1678        |\n",
      "|    total_timesteps      | 675840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018299572 |\n",
      "|    clip_fraction        | 0.301       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0107     |\n",
      "|    n_updates            | 11410       |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 0.0858      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=678208, episode_reward=53.39 +/- 3.89\n",
      "Episode length: 74.00 +/- 6.78\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 74          |\n",
      "|    mean_reward          | 53.4        |\n",
      "|    std_reward           | 3.89        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 678208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015245508 |\n",
      "|    clip_fraction        | 0.301       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0073     |\n",
      "|    n_updates            | 11420       |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    value_loss           | 0.0918      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.3     |\n",
      "|    ep_rew_mean     | 51.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 402      |\n",
      "|    iterations      | 166      |\n",
      "|    time_elapsed    | 1690     |\n",
      "|    total_timesteps | 679936   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 79.7       |\n",
      "|    ep_rew_mean          | 51.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 402        |\n",
      "|    iterations           | 167        |\n",
      "|    time_elapsed         | 1700       |\n",
      "|    total_timesteps      | 684032     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01733515 |\n",
      "|    clip_fraction        | 0.296      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.14      |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.00993   |\n",
      "|    n_updates            | 11430      |\n",
      "|    policy_gradient_loss | -0.0139    |\n",
      "|    value_loss           | 0.0779     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.9        |\n",
      "|    ep_rew_mean          | 51.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 402         |\n",
      "|    iterations           | 168         |\n",
      "|    time_elapsed         | 1710        |\n",
      "|    total_timesteps      | 688128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015157403 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.000186    |\n",
      "|    n_updates            | 11440       |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    value_loss           | 0.101       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=688208, episode_reward=52.97 +/- 2.28\n",
      "Episode length: 75.70 +/- 7.59\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 75.7       |\n",
      "|    mean_reward          | 53         |\n",
      "|    std_reward           | 2.28       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 688208     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01779248 |\n",
      "|    clip_fraction        | 0.308      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.14      |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.0128    |\n",
      "|    n_updates            | 11450      |\n",
      "|    policy_gradient_loss | -0.0133    |\n",
      "|    value_loss           | 0.0794     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.8     |\n",
      "|    ep_rew_mean     | 51.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 401      |\n",
      "|    iterations      | 169      |\n",
      "|    time_elapsed    | 1722     |\n",
      "|    total_timesteps | 692224   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.8        |\n",
      "|    ep_rew_mean          | 52.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 402         |\n",
      "|    iterations           | 170         |\n",
      "|    time_elapsed         | 1732        |\n",
      "|    total_timesteps      | 696320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017381959 |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.12       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.024      |\n",
      "|    n_updates            | 11460       |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    value_loss           | 0.0835      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=698208, episode_reward=53.88 +/- 4.05\n",
      "Episode length: 76.60 +/- 11.04\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 76.6        |\n",
      "|    mean_reward          | 53.9        |\n",
      "|    std_reward           | 4.05        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 698208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017483445 |\n",
      "|    clip_fraction        | 0.314       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0198     |\n",
      "|    n_updates            | 11470       |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    value_loss           | 0.0731      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78       |\n",
      "|    ep_rew_mean     | 52.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 401      |\n",
      "|    iterations      | 171      |\n",
      "|    time_elapsed    | 1743     |\n",
      "|    total_timesteps | 700416   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.7        |\n",
      "|    ep_rew_mean          | 52.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 401         |\n",
      "|    iterations           | 172         |\n",
      "|    time_elapsed         | 1753        |\n",
      "|    total_timesteps      | 704512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015764512 |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0193     |\n",
      "|    n_updates            | 11480       |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    value_loss           | 0.0765      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=708208, episode_reward=54.15 +/- 3.87\n",
      "Episode length: 74.50 +/- 9.68\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 74.5       |\n",
      "|    mean_reward          | 54.2       |\n",
      "|    std_reward           | 3.87       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 708208     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01863689 |\n",
      "|    clip_fraction        | 0.314      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.15      |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -3.46e-05  |\n",
      "|    n_updates            | 11490      |\n",
      "|    policy_gradient_loss | -0.0155    |\n",
      "|    value_loss           | 0.0769     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78       |\n",
      "|    ep_rew_mean     | 51.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 401      |\n",
      "|    iterations      | 173      |\n",
      "|    time_elapsed    | 1764     |\n",
      "|    total_timesteps | 708608   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.3        |\n",
      "|    ep_rew_mean          | 52.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 401         |\n",
      "|    iterations           | 174         |\n",
      "|    time_elapsed         | 1773        |\n",
      "|    total_timesteps      | 712704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016330048 |\n",
      "|    clip_fraction        | 0.321       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00257    |\n",
      "|    n_updates            | 11500       |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    value_loss           | 0.0753      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.8        |\n",
      "|    ep_rew_mean          | 52.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 401         |\n",
      "|    iterations           | 175         |\n",
      "|    time_elapsed         | 1783        |\n",
      "|    total_timesteps      | 716800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015257313 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0094     |\n",
      "|    n_updates            | 11510       |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    value_loss           | 0.0796      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=718208, episode_reward=55.22 +/- 1.74\n",
      "Episode length: 76.00 +/- 8.32\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 76         |\n",
      "|    mean_reward          | 55.2       |\n",
      "|    std_reward           | 1.74       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 718208     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01719971 |\n",
      "|    clip_fraction        | 0.304      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.14      |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | 0.0043     |\n",
      "|    n_updates            | 11520      |\n",
      "|    policy_gradient_loss | -0.0129    |\n",
      "|    value_loss           | 0.0764     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.1     |\n",
      "|    ep_rew_mean     | 52.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 401      |\n",
      "|    iterations      | 176      |\n",
      "|    time_elapsed    | 1794     |\n",
      "|    total_timesteps | 720896   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 80.5        |\n",
      "|    ep_rew_mean          | 51.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 401         |\n",
      "|    iterations           | 177         |\n",
      "|    time_elapsed         | 1803        |\n",
      "|    total_timesteps      | 724992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015925586 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00616     |\n",
      "|    n_updates            | 11530       |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    value_loss           | 0.0837      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=728208, episode_reward=53.15 +/- 5.49\n",
      "Episode length: 80.40 +/- 10.75\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 80.4        |\n",
      "|    mean_reward          | 53.1        |\n",
      "|    std_reward           | 5.49        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 728208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013607036 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0172      |\n",
      "|    n_updates            | 11540       |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    value_loss           | 0.0862      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.5     |\n",
      "|    ep_rew_mean     | 52.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 401      |\n",
      "|    iterations      | 178      |\n",
      "|    time_elapsed    | 1814     |\n",
      "|    total_timesteps | 729088   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78          |\n",
      "|    ep_rew_mean          | 52.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 401         |\n",
      "|    iterations           | 179         |\n",
      "|    time_elapsed         | 1824        |\n",
      "|    total_timesteps      | 733184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014952719 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00899    |\n",
      "|    n_updates            | 11550       |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    value_loss           | 0.103       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.4        |\n",
      "|    ep_rew_mean          | 51.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 401         |\n",
      "|    iterations           | 180         |\n",
      "|    time_elapsed         | 1834        |\n",
      "|    total_timesteps      | 737280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018411916 |\n",
      "|    clip_fraction        | 0.32        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0195     |\n",
      "|    n_updates            | 11560       |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    value_loss           | 0.0721      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=738208, episode_reward=53.50 +/- 4.31\n",
      "Episode length: 76.50 +/- 8.51\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 76.5        |\n",
      "|    mean_reward          | 53.5        |\n",
      "|    std_reward           | 4.31        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 738208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015897986 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0048     |\n",
      "|    n_updates            | 11570       |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 0.0953      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.7     |\n",
      "|    ep_rew_mean     | 51.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 401      |\n",
      "|    iterations      | 181      |\n",
      "|    time_elapsed    | 1845     |\n",
      "|    total_timesteps | 741376   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.3        |\n",
      "|    ep_rew_mean          | 51.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 401         |\n",
      "|    iterations           | 182         |\n",
      "|    time_elapsed         | 1855        |\n",
      "|    total_timesteps      | 745472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013299577 |\n",
      "|    clip_fraction        | 0.303       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00963    |\n",
      "|    n_updates            | 11580       |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    value_loss           | 0.0991      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=748208, episode_reward=52.84 +/- 1.66\n",
      "Episode length: 77.70 +/- 4.34\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 77.7        |\n",
      "|    mean_reward          | 52.8        |\n",
      "|    std_reward           | 1.66        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 748208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015858443 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00441    |\n",
      "|    n_updates            | 11590       |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    value_loss           | 0.0835      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 76.8     |\n",
      "|    ep_rew_mean     | 52.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 401      |\n",
      "|    iterations      | 183      |\n",
      "|    time_elapsed    | 1866     |\n",
      "|    total_timesteps | 749568   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.9        |\n",
      "|    ep_rew_mean          | 52.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 401         |\n",
      "|    iterations           | 184         |\n",
      "|    time_elapsed         | 1875        |\n",
      "|    total_timesteps      | 753664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015225392 |\n",
      "|    clip_fraction        | 0.309       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0164     |\n",
      "|    n_updates            | 11600       |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    value_loss           | 0.1         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.2        |\n",
      "|    ep_rew_mean          | 52          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 401         |\n",
      "|    iterations           | 185         |\n",
      "|    time_elapsed         | 1885        |\n",
      "|    total_timesteps      | 757760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016201327 |\n",
      "|    clip_fraction        | 0.324       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00452    |\n",
      "|    n_updates            | 11610       |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    value_loss           | 0.0793      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=758208, episode_reward=53.68 +/- 2.43\n",
      "Episode length: 80.70 +/- 8.78\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 80.7        |\n",
      "|    mean_reward          | 53.7        |\n",
      "|    std_reward           | 2.43        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 758208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012632629 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.17       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0179     |\n",
      "|    n_updates            | 11620       |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    value_loss           | 0.127       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.3     |\n",
      "|    ep_rew_mean     | 51.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 401      |\n",
      "|    iterations      | 186      |\n",
      "|    time_elapsed    | 1896     |\n",
      "|    total_timesteps | 761856   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.2        |\n",
      "|    ep_rew_mean          | 52.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 401         |\n",
      "|    iterations           | 187         |\n",
      "|    time_elapsed         | 1906        |\n",
      "|    total_timesteps      | 765952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014083726 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.16       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.000695   |\n",
      "|    n_updates            | 11630       |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    value_loss           | 0.0884      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=768208, episode_reward=52.82 +/- 4.60\n",
      "Episode length: 79.90 +/- 11.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 79.9        |\n",
      "|    mean_reward          | 52.8        |\n",
      "|    std_reward           | 4.6         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 768208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018866718 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00144     |\n",
      "|    n_updates            | 11640       |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    value_loss           | 0.113       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.5     |\n",
      "|    ep_rew_mean     | 51.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 401      |\n",
      "|    iterations      | 188      |\n",
      "|    time_elapsed    | 1917     |\n",
      "|    total_timesteps | 770048   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78          |\n",
      "|    ep_rew_mean          | 51.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 401         |\n",
      "|    iterations           | 189         |\n",
      "|    time_elapsed         | 1926        |\n",
      "|    total_timesteps      | 774144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017190982 |\n",
      "|    clip_fraction        | 0.312       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.16       |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00143    |\n",
      "|    n_updates            | 11650       |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    value_loss           | 0.0689      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=778208, episode_reward=52.21 +/- 2.51\n",
      "Episode length: 79.60 +/- 8.94\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 79.6        |\n",
      "|    mean_reward          | 52.2        |\n",
      "|    std_reward           | 2.51        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 778208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019239891 |\n",
      "|    clip_fraction        | 0.326       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00992    |\n",
      "|    n_updates            | 11660       |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    value_loss           | 0.0947      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.3     |\n",
      "|    ep_rew_mean     | 51.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 401      |\n",
      "|    iterations      | 190      |\n",
      "|    time_elapsed    | 1937     |\n",
      "|    total_timesteps | 778240   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78          |\n",
      "|    ep_rew_mean          | 51.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 401         |\n",
      "|    iterations           | 191         |\n",
      "|    time_elapsed         | 1947        |\n",
      "|    total_timesteps      | 782336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015717592 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00138    |\n",
      "|    n_updates            | 11670       |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    value_loss           | 0.101       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.1        |\n",
      "|    ep_rew_mean          | 51.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 401         |\n",
      "|    iterations           | 192         |\n",
      "|    time_elapsed         | 1956        |\n",
      "|    total_timesteps      | 786432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017651565 |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00486    |\n",
      "|    n_updates            | 11680       |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    value_loss           | 0.0992      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=788208, episode_reward=50.92 +/- 3.70\n",
      "Episode length: 83.20 +/- 9.68\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 83.2        |\n",
      "|    mean_reward          | 50.9        |\n",
      "|    std_reward           | 3.7         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 788208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016597437 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.16       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0105     |\n",
      "|    n_updates            | 11690       |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    value_loss           | 0.0902      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.2     |\n",
      "|    ep_rew_mean     | 51.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 401      |\n",
      "|    iterations      | 193      |\n",
      "|    time_elapsed    | 1967     |\n",
      "|    total_timesteps | 790528   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 77.4       |\n",
      "|    ep_rew_mean          | 52.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 401        |\n",
      "|    iterations           | 194        |\n",
      "|    time_elapsed         | 1977       |\n",
      "|    total_timesteps      | 794624     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01585371 |\n",
      "|    clip_fraction        | 0.277      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.17      |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.00503   |\n",
      "|    n_updates            | 11700      |\n",
      "|    policy_gradient_loss | -0.0143    |\n",
      "|    value_loss           | 0.121      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=798208, episode_reward=54.46 +/- 3.12\n",
      "Episode length: 75.90 +/- 8.54\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 75.9        |\n",
      "|    mean_reward          | 54.5        |\n",
      "|    std_reward           | 3.12        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 798208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015358206 |\n",
      "|    clip_fraction        | 0.31        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0135     |\n",
      "|    n_updates            | 11710       |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    value_loss           | 0.0854      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.7     |\n",
      "|    ep_rew_mean     | 51.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 401      |\n",
      "|    iterations      | 195      |\n",
      "|    time_elapsed    | 1988     |\n",
      "|    total_timesteps | 798720   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 78         |\n",
      "|    ep_rew_mean          | 51.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 401        |\n",
      "|    iterations           | 196        |\n",
      "|    time_elapsed         | 1997       |\n",
      "|    total_timesteps      | 802816     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01901632 |\n",
      "|    clip_fraction        | 0.333      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.17      |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.0189    |\n",
      "|    n_updates            | 11720      |\n",
      "|    policy_gradient_loss | -0.0159    |\n",
      "|    value_loss           | 0.0873     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.2        |\n",
      "|    ep_rew_mean          | 51.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 401         |\n",
      "|    iterations           | 197         |\n",
      "|    time_elapsed         | 2007        |\n",
      "|    total_timesteps      | 806912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018673688 |\n",
      "|    clip_fraction        | 0.318       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.17       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00705    |\n",
      "|    n_updates            | 11730       |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    value_loss           | 0.091       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=808208, episode_reward=52.93 +/- 2.94\n",
      "Episode length: 75.10 +/- 8.86\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 75.1       |\n",
      "|    mean_reward          | 52.9       |\n",
      "|    std_reward           | 2.94       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 808208     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01861785 |\n",
      "|    clip_fraction        | 0.306      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.18      |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.00849   |\n",
      "|    n_updates            | 11740      |\n",
      "|    policy_gradient_loss | -0.0153    |\n",
      "|    value_loss           | 0.105      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.3     |\n",
      "|    ep_rew_mean     | 51.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 401      |\n",
      "|    iterations      | 198      |\n",
      "|    time_elapsed    | 2018     |\n",
      "|    total_timesteps | 811008   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.3        |\n",
      "|    ep_rew_mean          | 51.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 401         |\n",
      "|    iterations           | 199         |\n",
      "|    time_elapsed         | 2027        |\n",
      "|    total_timesteps      | 815104      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018112235 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.17       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00722     |\n",
      "|    n_updates            | 11750       |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    value_loss           | 0.089       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=818208, episode_reward=53.67 +/- 2.54\n",
      "Episode length: 77.70 +/- 11.26\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 77.7        |\n",
      "|    mean_reward          | 53.7        |\n",
      "|    std_reward           | 2.54        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 818208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017752897 |\n",
      "|    clip_fraction        | 0.323       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0031     |\n",
      "|    n_updates            | 11760       |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 0.0958      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.5     |\n",
      "|    ep_rew_mean     | 51.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 401      |\n",
      "|    iterations      | 200      |\n",
      "|    time_elapsed    | 2038     |\n",
      "|    total_timesteps | 819200   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.3        |\n",
      "|    ep_rew_mean          | 51.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 401         |\n",
      "|    iterations           | 201         |\n",
      "|    time_elapsed         | 2048        |\n",
      "|    total_timesteps      | 823296      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016473908 |\n",
      "|    clip_fraction        | 0.319       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00707    |\n",
      "|    n_updates            | 11770       |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 0.0743      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 77.6         |\n",
      "|    ep_rew_mean          | 51.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 401          |\n",
      "|    iterations           | 202          |\n",
      "|    time_elapsed         | 2058         |\n",
      "|    total_timesteps      | 827392       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0151341455 |\n",
      "|    clip_fraction        | 0.308        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.18        |\n",
      "|    explained_variance   | 0.998        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0033      |\n",
      "|    n_updates            | 11780        |\n",
      "|    policy_gradient_loss | -0.0163      |\n",
      "|    value_loss           | 0.0901       |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=828208, episode_reward=53.02 +/- 3.33\n",
      "Episode length: 79.60 +/- 9.15\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 79.6         |\n",
      "|    mean_reward          | 53           |\n",
      "|    std_reward           | 3.33         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 828208       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0144864395 |\n",
      "|    clip_fraction        | 0.304        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.16        |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.000398     |\n",
      "|    n_updates            | 11790        |\n",
      "|    policy_gradient_loss | -0.0142      |\n",
      "|    value_loss           | 0.106        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.3     |\n",
      "|    ep_rew_mean     | 51.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 401      |\n",
      "|    iterations      | 203      |\n",
      "|    time_elapsed    | 2069     |\n",
      "|    total_timesteps | 831488   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.7        |\n",
      "|    ep_rew_mean          | 51.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 401         |\n",
      "|    iterations           | 204         |\n",
      "|    time_elapsed         | 2078        |\n",
      "|    total_timesteps      | 835584      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019698873 |\n",
      "|    clip_fraction        | 0.334       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00518     |\n",
      "|    n_updates            | 11800       |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 0.0932      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=838208, episode_reward=52.61 +/- 3.37\n",
      "Episode length: 76.10 +/- 7.62\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 76.1       |\n",
      "|    mean_reward          | 52.6       |\n",
      "|    std_reward           | 3.37       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 838208     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01571186 |\n",
      "|    clip_fraction        | 0.317      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.2       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.0129    |\n",
      "|    n_updates            | 11810      |\n",
      "|    policy_gradient_loss | -0.0151    |\n",
      "|    value_loss           | 0.0903     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.1     |\n",
      "|    ep_rew_mean     | 51       |\n",
      "| time/              |          |\n",
      "|    fps             | 401      |\n",
      "|    iterations      | 205      |\n",
      "|    time_elapsed    | 2089     |\n",
      "|    total_timesteps | 839680   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.2        |\n",
      "|    ep_rew_mean          | 51.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 401         |\n",
      "|    iterations           | 206         |\n",
      "|    time_elapsed         | 2099        |\n",
      "|    total_timesteps      | 843776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019872487 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0148     |\n",
      "|    n_updates            | 11820       |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    value_loss           | 0.11        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.7        |\n",
      "|    ep_rew_mean          | 52.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 401         |\n",
      "|    iterations           | 207         |\n",
      "|    time_elapsed         | 2109        |\n",
      "|    total_timesteps      | 847872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015341217 |\n",
      "|    clip_fraction        | 0.3         |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00583    |\n",
      "|    n_updates            | 11830       |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 0.0984      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=848208, episode_reward=52.36 +/- 4.13\n",
      "Episode length: 74.60 +/- 7.28\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 74.6       |\n",
      "|    mean_reward          | 52.4       |\n",
      "|    std_reward           | 4.13       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 848208     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01782321 |\n",
      "|    clip_fraction        | 0.327      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.16      |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.0132    |\n",
      "|    n_updates            | 11840      |\n",
      "|    policy_gradient_loss | -0.0139    |\n",
      "|    value_loss           | 0.0725     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 80       |\n",
      "|    ep_rew_mean     | 52       |\n",
      "| time/              |          |\n",
      "|    fps             | 401      |\n",
      "|    iterations      | 208      |\n",
      "|    time_elapsed    | 2120     |\n",
      "|    total_timesteps | 851968   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 81         |\n",
      "|    ep_rew_mean          | 50.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 401        |\n",
      "|    iterations           | 209        |\n",
      "|    time_elapsed         | 2130       |\n",
      "|    total_timesteps      | 856064     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01871569 |\n",
      "|    clip_fraction        | 0.331      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.18      |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.0063    |\n",
      "|    n_updates            | 11850      |\n",
      "|    policy_gradient_loss | -0.013     |\n",
      "|    value_loss           | 0.0743     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=858208, episode_reward=52.09 +/- 7.69\n",
      "Episode length: 76.80 +/- 8.70\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 76.8        |\n",
      "|    mean_reward          | 52.1        |\n",
      "|    std_reward           | 7.69        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 858208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016892964 |\n",
      "|    clip_fraction        | 0.336       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.000191    |\n",
      "|    n_updates            | 11860       |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    value_loss           | 0.0848      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.2     |\n",
      "|    ep_rew_mean     | 50.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 401      |\n",
      "|    iterations      | 210      |\n",
      "|    time_elapsed    | 2141     |\n",
      "|    total_timesteps | 860160   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.9        |\n",
      "|    ep_rew_mean          | 51.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 401         |\n",
      "|    iterations           | 211         |\n",
      "|    time_elapsed         | 2151        |\n",
      "|    total_timesteps      | 864256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018235676 |\n",
      "|    clip_fraction        | 0.323       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.000681    |\n",
      "|    n_updates            | 11870       |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    value_loss           | 0.0861      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=868208, episode_reward=53.16 +/- 3.09\n",
      "Episode length: 77.60 +/- 7.70\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 77.6        |\n",
      "|    mean_reward          | 53.2        |\n",
      "|    std_reward           | 3.09        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 868208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013988318 |\n",
      "|    clip_fraction        | 0.289       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00104    |\n",
      "|    n_updates            | 11880       |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    value_loss           | 0.102       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 76.6     |\n",
      "|    ep_rew_mean     | 51.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 401      |\n",
      "|    iterations      | 212      |\n",
      "|    time_elapsed    | 2161     |\n",
      "|    total_timesteps | 868352   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 75.7        |\n",
      "|    ep_rew_mean          | 51.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 401         |\n",
      "|    iterations           | 213         |\n",
      "|    time_elapsed         | 2171        |\n",
      "|    total_timesteps      | 872448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013930839 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00628     |\n",
      "|    n_updates            | 11890       |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    value_loss           | 0.151       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.6        |\n",
      "|    ep_rew_mean          | 51.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 401         |\n",
      "|    iterations           | 214         |\n",
      "|    time_elapsed         | 2180        |\n",
      "|    total_timesteps      | 876544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018778196 |\n",
      "|    clip_fraction        | 0.336       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00373    |\n",
      "|    n_updates            | 11900       |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    value_loss           | 0.0925      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=878208, episode_reward=52.43 +/- 3.91\n",
      "Episode length: 76.50 +/- 12.21\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 76.5        |\n",
      "|    mean_reward          | 52.4        |\n",
      "|    std_reward           | 3.91        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 878208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018499777 |\n",
      "|    clip_fraction        | 0.35        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0156     |\n",
      "|    n_updates            | 11910       |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    value_loss           | 0.0802      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 76.7     |\n",
      "|    ep_rew_mean     | 52       |\n",
      "| time/              |          |\n",
      "|    fps             | 401      |\n",
      "|    iterations      | 215      |\n",
      "|    time_elapsed    | 2191     |\n",
      "|    total_timesteps | 880640   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.4        |\n",
      "|    ep_rew_mean          | 52.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 401         |\n",
      "|    iterations           | 216         |\n",
      "|    time_elapsed         | 2201        |\n",
      "|    total_timesteps      | 884736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014178057 |\n",
      "|    clip_fraction        | 0.319       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0168     |\n",
      "|    n_updates            | 11920       |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 0.0805      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=888208, episode_reward=55.87 +/- 2.54\n",
      "Episode length: 71.20 +/- 9.33\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 71.2         |\n",
      "|    mean_reward          | 55.9         |\n",
      "|    std_reward           | 2.54         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 888208       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0150783565 |\n",
      "|    clip_fraction        | 0.294        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.19        |\n",
      "|    explained_variance   | 0.998        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0167      |\n",
      "|    n_updates            | 11930        |\n",
      "|    policy_gradient_loss | -0.0145      |\n",
      "|    value_loss           | 0.095        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.9     |\n",
      "|    ep_rew_mean     | 52       |\n",
      "| time/              |          |\n",
      "|    fps             | 401      |\n",
      "|    iterations      | 217      |\n",
      "|    time_elapsed    | 2212     |\n",
      "|    total_timesteps | 888832   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.7        |\n",
      "|    ep_rew_mean          | 51.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 401         |\n",
      "|    iterations           | 218         |\n",
      "|    time_elapsed         | 2222        |\n",
      "|    total_timesteps      | 892928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018280255 |\n",
      "|    clip_fraction        | 0.319       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.17       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0101     |\n",
      "|    n_updates            | 11940       |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    value_loss           | 0.0919      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.9        |\n",
      "|    ep_rew_mean          | 51.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 401         |\n",
      "|    iterations           | 219         |\n",
      "|    time_elapsed         | 2231        |\n",
      "|    total_timesteps      | 897024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016690182 |\n",
      "|    clip_fraction        | 0.309       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00146     |\n",
      "|    n_updates            | 11950       |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    value_loss           | 0.0947      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=898208, episode_reward=51.76 +/- 3.58\n",
      "Episode length: 86.00 +/- 6.43\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 86          |\n",
      "|    mean_reward          | 51.8        |\n",
      "|    std_reward           | 3.58        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 898208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019580266 |\n",
      "|    clip_fraction        | 0.325       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00673    |\n",
      "|    n_updates            | 11960       |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    value_loss           | 0.0987      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.4     |\n",
      "|    ep_rew_mean     | 52       |\n",
      "| time/              |          |\n",
      "|    fps             | 401      |\n",
      "|    iterations      | 220      |\n",
      "|    time_elapsed    | 2242     |\n",
      "|    total_timesteps | 901120   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.2        |\n",
      "|    ep_rew_mean          | 52.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 401         |\n",
      "|    iterations           | 221         |\n",
      "|    time_elapsed         | 2252        |\n",
      "|    total_timesteps      | 905216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016269302 |\n",
      "|    clip_fraction        | 0.318       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.000568   |\n",
      "|    n_updates            | 11970       |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    value_loss           | 0.0942      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=908208, episode_reward=53.18 +/- 5.80\n",
      "Episode length: 77.20 +/- 11.44\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 77.2        |\n",
      "|    mean_reward          | 53.2        |\n",
      "|    std_reward           | 5.8         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 908208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016596014 |\n",
      "|    clip_fraction        | 0.327       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.16       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0102     |\n",
      "|    n_updates            | 11980       |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    value_loss           | 0.078       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.9     |\n",
      "|    ep_rew_mean     | 51.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 401      |\n",
      "|    iterations      | 222      |\n",
      "|    time_elapsed    | 2263     |\n",
      "|    total_timesteps | 909312   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.9        |\n",
      "|    ep_rew_mean          | 51.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 401         |\n",
      "|    iterations           | 223         |\n",
      "|    time_elapsed         | 2272        |\n",
      "|    total_timesteps      | 913408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021666888 |\n",
      "|    clip_fraction        | 0.331       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00822    |\n",
      "|    n_updates            | 11990       |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    value_loss           | 0.0928      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 75.8        |\n",
      "|    ep_rew_mean          | 52.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 401         |\n",
      "|    iterations           | 224         |\n",
      "|    time_elapsed         | 2282        |\n",
      "|    total_timesteps      | 917504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016565677 |\n",
      "|    clip_fraction        | 0.327       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0264     |\n",
      "|    n_updates            | 12000       |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    value_loss           | 0.0762      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=918208, episode_reward=50.47 +/- 5.13\n",
      "Episode length: 78.70 +/- 14.90\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 78.7         |\n",
      "|    mean_reward          | 50.5         |\n",
      "|    std_reward           | 5.13         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 918208       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0109649515 |\n",
      "|    clip_fraction        | 0.242        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.19        |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.00627      |\n",
      "|    n_updates            | 12010        |\n",
      "|    policy_gradient_loss | -0.0143      |\n",
      "|    value_loss           | 0.167        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.6     |\n",
      "|    ep_rew_mean     | 51.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 401      |\n",
      "|    iterations      | 225      |\n",
      "|    time_elapsed    | 2293     |\n",
      "|    total_timesteps | 921600   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 80.7        |\n",
      "|    ep_rew_mean          | 49.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 401         |\n",
      "|    iterations           | 226         |\n",
      "|    time_elapsed         | 2303        |\n",
      "|    total_timesteps      | 925696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016623251 |\n",
      "|    clip_fraction        | 0.342       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00468    |\n",
      "|    n_updates            | 12020       |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 0.0809      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=928208, episode_reward=54.20 +/- 2.20\n",
      "Episode length: 80.60 +/- 3.17\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 80.6        |\n",
      "|    mean_reward          | 54.2        |\n",
      "|    std_reward           | 2.2         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 928208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014779986 |\n",
      "|    clip_fraction        | 0.312       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.016      |\n",
      "|    n_updates            | 12030       |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    value_loss           | 0.0934      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.4     |\n",
      "|    ep_rew_mean     | 50.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 401      |\n",
      "|    iterations      | 227      |\n",
      "|    time_elapsed    | 2314     |\n",
      "|    total_timesteps | 929792   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.2        |\n",
      "|    ep_rew_mean          | 50.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 401         |\n",
      "|    iterations           | 228         |\n",
      "|    time_elapsed         | 2324        |\n",
      "|    total_timesteps      | 933888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014331914 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.17       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00469    |\n",
      "|    n_updates            | 12040       |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 0.115       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.9        |\n",
      "|    ep_rew_mean          | 50.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 401         |\n",
      "|    iterations           | 229         |\n",
      "|    time_elapsed         | 2334        |\n",
      "|    total_timesteps      | 937984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014360189 |\n",
      "|    clip_fraction        | 0.309       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.17       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.000951   |\n",
      "|    n_updates            | 12050       |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    value_loss           | 0.106       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=938208, episode_reward=53.80 +/- 3.08\n",
      "Episode length: 76.90 +/- 8.13\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 76.9        |\n",
      "|    mean_reward          | 53.8        |\n",
      "|    std_reward           | 3.08        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 938208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017284611 |\n",
      "|    clip_fraction        | 0.333       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00647    |\n",
      "|    n_updates            | 12060       |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    value_loss           | 0.0842      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 80.4     |\n",
      "|    ep_rew_mean     | 50.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 401      |\n",
      "|    iterations      | 230      |\n",
      "|    time_elapsed    | 2345     |\n",
      "|    total_timesteps | 942080   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.2        |\n",
      "|    ep_rew_mean          | 51.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 401         |\n",
      "|    iterations           | 231         |\n",
      "|    time_elapsed         | 2354        |\n",
      "|    total_timesteps      | 946176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015814297 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0278      |\n",
      "|    n_updates            | 12070       |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    value_loss           | 0.107       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=948208, episode_reward=55.13 +/- 4.47\n",
      "Episode length: 73.50 +/- 9.60\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 73.5        |\n",
      "|    mean_reward          | 55.1        |\n",
      "|    std_reward           | 4.47        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 948208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017762795 |\n",
      "|    clip_fraction        | 0.354       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.17       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.000738   |\n",
      "|    n_updates            | 12080       |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    value_loss           | 0.0826      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.6     |\n",
      "|    ep_rew_mean     | 52.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 401      |\n",
      "|    iterations      | 232      |\n",
      "|    time_elapsed    | 2365     |\n",
      "|    total_timesteps | 950272   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.2        |\n",
      "|    ep_rew_mean          | 51.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 401         |\n",
      "|    iterations           | 233         |\n",
      "|    time_elapsed         | 2375        |\n",
      "|    total_timesteps      | 954368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014182824 |\n",
      "|    clip_fraction        | 0.319       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.16       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.000216    |\n",
      "|    n_updates            | 12090       |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    value_loss           | 0.0799      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=958208, episode_reward=53.86 +/- 3.81\n",
      "Episode length: 78.80 +/- 7.39\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 78.8         |\n",
      "|    mean_reward          | 53.9         |\n",
      "|    std_reward           | 3.81         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 958208       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0155274235 |\n",
      "|    clip_fraction        | 0.321        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.18        |\n",
      "|    explained_variance   | 0.998        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00498     |\n",
      "|    n_updates            | 12100        |\n",
      "|    policy_gradient_loss | -0.0149      |\n",
      "|    value_loss           | 0.0969       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 75.7     |\n",
      "|    ep_rew_mean     | 52.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 401      |\n",
      "|    iterations      | 234      |\n",
      "|    time_elapsed    | 2385     |\n",
      "|    total_timesteps | 958464   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 75.4        |\n",
      "|    ep_rew_mean          | 52.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 401         |\n",
      "|    iterations           | 235         |\n",
      "|    time_elapsed         | 2395        |\n",
      "|    total_timesteps      | 962560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015489282 |\n",
      "|    clip_fraction        | 0.309       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00715     |\n",
      "|    n_updates            | 12110       |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 0.0899      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.2        |\n",
      "|    ep_rew_mean          | 52.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 401         |\n",
      "|    iterations           | 236         |\n",
      "|    time_elapsed         | 2405        |\n",
      "|    total_timesteps      | 966656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015417671 |\n",
      "|    clip_fraction        | 0.35        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.16       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0146     |\n",
      "|    n_updates            | 12120       |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 0.0758      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=968208, episode_reward=52.91 +/- 2.88\n",
      "Episode length: 76.60 +/- 10.66\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 76.6       |\n",
      "|    mean_reward          | 52.9       |\n",
      "|    std_reward           | 2.88       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 968208     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01705065 |\n",
      "|    clip_fraction        | 0.348      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.19      |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.00635   |\n",
      "|    n_updates            | 12130      |\n",
      "|    policy_gradient_loss | -0.0155    |\n",
      "|    value_loss           | 0.0896     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79       |\n",
      "|    ep_rew_mean     | 52.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 401      |\n",
      "|    iterations      | 237      |\n",
      "|    time_elapsed    | 2416     |\n",
      "|    total_timesteps | 970752   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.8        |\n",
      "|    ep_rew_mean          | 52          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 401         |\n",
      "|    iterations           | 238         |\n",
      "|    time_elapsed         | 2425        |\n",
      "|    total_timesteps      | 974848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013892974 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.16       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.000846    |\n",
      "|    n_updates            | 12140       |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 0.0782      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=978208, episode_reward=52.74 +/- 3.55\n",
      "Episode length: 75.70 +/- 10.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 75.7        |\n",
      "|    mean_reward          | 52.7        |\n",
      "|    std_reward           | 3.55        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 978208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014662944 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00856    |\n",
      "|    n_updates            | 12150       |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    value_loss           | 0.0897      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.1     |\n",
      "|    ep_rew_mean     | 52.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 401      |\n",
      "|    iterations      | 239      |\n",
      "|    time_elapsed    | 2436     |\n",
      "|    total_timesteps | 978944   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.8        |\n",
      "|    ep_rew_mean          | 52.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 401         |\n",
      "|    iterations           | 240         |\n",
      "|    time_elapsed         | 2446        |\n",
      "|    total_timesteps      | 983040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016209148 |\n",
      "|    clip_fraction        | 0.324       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.17       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.009      |\n",
      "|    n_updates            | 12160       |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    value_loss           | 0.0912      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.8        |\n",
      "|    ep_rew_mean          | 51.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 401         |\n",
      "|    iterations           | 241         |\n",
      "|    time_elapsed         | 2456        |\n",
      "|    total_timesteps      | 987136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016186433 |\n",
      "|    clip_fraction        | 0.305       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.17       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0088     |\n",
      "|    n_updates            | 12170       |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    value_loss           | 0.0858      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=988208, episode_reward=53.67 +/- 2.76\n",
      "Episode length: 74.90 +/- 9.54\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 74.9        |\n",
      "|    mean_reward          | 53.7        |\n",
      "|    std_reward           | 2.76        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 988208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014573252 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0162     |\n",
      "|    n_updates            | 12180       |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    value_loss           | 0.0863      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.9     |\n",
      "|    ep_rew_mean     | 51.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 401      |\n",
      "|    iterations      | 242      |\n",
      "|    time_elapsed    | 2467     |\n",
      "|    total_timesteps | 991232   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.7        |\n",
      "|    ep_rew_mean          | 51.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 401         |\n",
      "|    iterations           | 243         |\n",
      "|    time_elapsed         | 2478        |\n",
      "|    total_timesteps      | 995328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015759718 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00685    |\n",
      "|    n_updates            | 12190       |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    value_loss           | 0.0821      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=998208, episode_reward=53.60 +/- 2.66\n",
      "Episode length: 77.10 +/- 6.64\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 77.1       |\n",
      "|    mean_reward          | 53.6       |\n",
      "|    std_reward           | 2.66       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 998208     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01645116 |\n",
      "|    clip_fraction        | 0.328      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.16      |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.0124    |\n",
      "|    n_updates            | 12200      |\n",
      "|    policy_gradient_loss | -0.0148    |\n",
      "|    value_loss           | 0.0871     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78       |\n",
      "|    ep_rew_mean     | 51.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 401      |\n",
      "|    iterations      | 244      |\n",
      "|    time_elapsed    | 2488     |\n",
      "|    total_timesteps | 999424   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.7        |\n",
      "|    ep_rew_mean          | 52.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 401         |\n",
      "|    iterations           | 245         |\n",
      "|    time_elapsed         | 2498        |\n",
      "|    total_timesteps      | 1003520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015729524 |\n",
      "|    clip_fraction        | 0.315       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00204    |\n",
      "|    n_updates            | 12210       |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    value_loss           | 0.105       |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# # # # Additional Training\n",
    "\n",
    "model.learn(1_000_000, callback=eval_callback)\n",
    "model.save(log_path + \"/final_model2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
